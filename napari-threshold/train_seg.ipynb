{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from numpy import random\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    "    Dataset,\n",
    "    SubsetRandomSampler,\n",
    "    TensorDataset,\n",
    ")\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from Unet_training.models import Unet\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class facemapdataset(Dataset):\n",
    "    def __init__(self, data_file=\"data/facemap_softlabels.pt\", transform=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.transform = transform\n",
    "        self.data, _, self.targets = torch.load(data_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.data[index].clone(), self.targets[index].clone()\n",
    "        if (self.transform is not None) and (torch.rand(1) > 0.5):\n",
    "            image = image.flip([2])\n",
    "            label = label.flip([2])\n",
    "        return image, label\n",
    "\n",
    "\n",
    "### Make dataset\n",
    "dataset = facemapdataset(transform=\"flip\")\n",
    "\n",
    "x = dataset[0][0]\n",
    "dim = x.shape[-1]\n",
    "print(\"Using %d size of images\" % dim)\n",
    "N = len(dataset)\n",
    "train_sampler = SubsetRandomSampler(np.arange(int(0.6 * N)))\n",
    "valid_sampler = SubsetRandomSampler(np.arange(int(0.6 * N), int(0.8 * N)))\n",
    "test_sampler = SubsetRandomSampler(np.arange(int(0.8 * N), N))\n",
    "batch_size = 4\n",
    "# Initialize loss and metrics\n",
    "loss_fun = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "# Initiliaze input dimensions\n",
    "num_train = len(train_sampler)\n",
    "num_valid = len(valid_sampler)\n",
    "num_test = len(test_sampler)\n",
    "print(\n",
    "    \"Num. train = %d, Num. val = %d, Num. test = %d\"\n",
    "    % (num_train, num_valid, num_test)\n",
    ")\n",
    "\n",
    "# Initialize dataloaders\n",
    "loader_train = DataLoader(\n",
    "    dataset=dataset,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    "    sampler=train_sampler,\n",
    ")\n",
    "loader_valid = DataLoader(\n",
    "    dataset=dataset,\n",
    "    drop_last=True,\n",
    "    num_workers=0,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    "    sampler=valid_sampler,\n",
    ")\n",
    "loader_test = DataLoader(\n",
    "    dataset=dataset,\n",
    "    drop_last=True,\n",
    "    num_workers=0,\n",
    "    batch_size=1,\n",
    "    pin_memory=True,\n",
    "    sampler=test_sampler,\n",
    ")\n",
    "\n",
    "nValid = len(loader_valid)\n",
    "nTrain = len(loader_train)\n",
    "nTest = len(loader_test)\n",
    "\n",
    "### hyperparam\n",
    "lr = 5e-4\n",
    "num_epochs = 5\n",
    "\n",
    "# num_input_channels = 1  # Change this to the desired number of input channels\n",
    "# num_output_classes = 24  # Change this to the desired number of output classes\n",
    "\n",
    "\n",
    "model = Unet()\n",
    "# timm.create_model('vit_base_patch8_224',\n",
    "#        pretrained=True,in_chans=1,num_classes=num_output_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "nParam = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters:%2f M\" % (nParam / 1e6))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "minLoss = 1e6\n",
    "convIter = 0\n",
    "patience = 5\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    tr_loss = 0\n",
    "    for i, (inputs, labels) in enumerate(loader_train):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        scores, _ = model(inputs)\n",
    "\n",
    "        loss = loss_fun((scores), ((labels)))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\n",
    "            \"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}\".format(\n",
    "                epoch + 1, num_epochs, i + 1, nTrain, loss.item()\n",
    "            )\n",
    "        )\n",
    "        tr_loss += loss.item()\n",
    "    train_loss.append(tr_loss / (i + 1))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for i, (inputs, labels) in enumerate(loader_valid):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            scores, fmap = model(inputs)\n",
    "            loss = loss_fun((scores), ((labels)))\n",
    "            val_loss += loss.item()\n",
    "        val_loss = val_loss / (i + 1)\n",
    "\n",
    "        valid_loss.append(val_loss)\n",
    "\n",
    "        print(\"Val. loss :%.4f\" % val_loss)\n",
    "\n",
    "        labels = labels.squeeze().detach().cpu().numpy()\n",
    "        scores = scores.squeeze().detach().cpu().numpy()\n",
    "        img = inputs.squeeze().detach().cpu().numpy()\n",
    "        fmap = inputs.mean(1).squeeze().detach().cpu().numpy()\n",
    "\n",
    "        plt.clf()\n",
    "        plt.figure(figsize=(16, 12))\n",
    "        for i in range(batch_size):\n",
    "            plt.subplot(batch_size, 3, 3 * i + 1)\n",
    "            plt.imshow(labels[i])\n",
    "            plt.subplot(batch_size, 3, 3 * i + 2)\n",
    "            plt.imshow(scores[i] * img[i])\n",
    "            plt.subplot(batch_size, 3, 3 * i + 3)\n",
    "            plt.imshow(fmap[i])\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.savefig(\"logs/epoch_%03d.jpg\" % epoch)\n",
    "\n",
    "        if minLoss > val_loss:\n",
    "            convEpoch = epoch\n",
    "            minLoss = val_loss\n",
    "            convIter = 0\n",
    "            # torch.save(model.state_dict(),'models/best_model.pt')\n",
    "        else:\n",
    "            convIter += 1\n",
    "\n",
    "        if convIter == patience:\n",
    "            print(\n",
    "                \"Converged at epoch %d with val. loss %.4f\"\n",
    "                % (convEpoch + 1, minLoss)\n",
    "            )\n",
    "            break\n",
    "plt.clf()\n",
    "plt.plot(train_loss, label=\"Training\")\n",
    "plt.plot(valid_loss, label=\"Valid\")\n",
    "plt.plot(convEpoch, valid_loss[convEpoch], \"x\", label=\"Final Model\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"loss_curve.pdf\")\n",
    "\n",
    "### Load best model for inference\n",
    "with torch.no_grad():\n",
    "    val_loss = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(loader_test):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        scores, fmap = model(inputs)\n",
    "        loss = loss_fun((scores), ((labels)))\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        img = inputs.squeeze().detach().cpu().numpy()\n",
    "        pred = scores.squeeze().detach().cpu().numpy()\n",
    "        labels = labels.squeeze().cpu().numpy()\n",
    "        fmap = fmap.mean(1).squeeze().cpu().numpy()\n",
    "\n",
    "        plt.clf()\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(141)\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "        plt.subplot(142)\n",
    "        plt.imshow(labels)\n",
    "        plt.subplot(143)\n",
    "        plt.imshow(pred)\n",
    "        plt.subplot(144)\n",
    "        plt.imshow(fmap)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"preds/test_%03d.jpg\" % i)\n",
    "\n",
    "    val_loss = val_loss / (i + 1)\n",
    "\n",
    "    print(\"Test. loss :%.4f\" % val_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
