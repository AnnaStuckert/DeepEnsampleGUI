{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 388 size of images\n",
      "Num. train = 222, Num. val = 74, Num. test = 74\n",
      "Number of parameters:0.029289 M\n",
      "Epoch [1/100], Step [1/56], Loss: 126.1236\n",
      "Epoch [1/100], Step [2/56], Loss: 76.4727\n",
      "Epoch [1/100], Step [3/56], Loss: 57.7516\n",
      "Epoch [1/100], Step [4/56], Loss: 47.6388\n",
      "Epoch [1/100], Step [5/56], Loss: 42.9207\n",
      "Epoch [1/100], Step [6/56], Loss: 39.7305\n",
      "Epoch [1/100], Step [7/56], Loss: 22.6739\n",
      "Epoch [1/100], Step [8/56], Loss: 22.4541\n",
      "Epoch [1/100], Step [9/56], Loss: 18.1246\n",
      "Epoch [1/100], Step [10/56], Loss: 19.1811\n",
      "Epoch [1/100], Step [11/56], Loss: 11.6707\n",
      "Epoch [1/100], Step [12/56], Loss: 12.8377\n",
      "Epoch [1/100], Step [13/56], Loss: 8.0796\n",
      "Epoch [1/100], Step [14/56], Loss: 12.6915\n",
      "Epoch [1/100], Step [15/56], Loss: 12.9605\n",
      "Epoch [1/100], Step [16/56], Loss: 8.3367\n",
      "Epoch [1/100], Step [17/56], Loss: 7.8125\n",
      "Epoch [1/100], Step [18/56], Loss: 9.0811\n",
      "Epoch [1/100], Step [19/56], Loss: 5.6609\n",
      "Epoch [1/100], Step [20/56], Loss: 5.0839\n",
      "Epoch [1/100], Step [21/56], Loss: 6.0564\n",
      "Epoch [1/100], Step [22/56], Loss: 4.3890\n",
      "Epoch [1/100], Step [23/56], Loss: 4.5446\n",
      "Epoch [1/100], Step [24/56], Loss: 6.1153\n",
      "Epoch [1/100], Step [25/56], Loss: 5.2213\n",
      "Epoch [1/100], Step [26/56], Loss: 4.6090\n",
      "Epoch [1/100], Step [27/56], Loss: 4.3214\n",
      "Epoch [1/100], Step [28/56], Loss: 4.0451\n",
      "Epoch [1/100], Step [29/56], Loss: 3.0824\n",
      "Epoch [1/100], Step [30/56], Loss: 2.9849\n",
      "Epoch [1/100], Step [31/56], Loss: 2.7246\n",
      "Epoch [1/100], Step [32/56], Loss: 3.1310\n",
      "Epoch [1/100], Step [33/56], Loss: 3.5791\n",
      "Epoch [1/100], Step [34/56], Loss: 4.1235\n",
      "Epoch [1/100], Step [35/56], Loss: 3.6046\n",
      "Epoch [1/100], Step [36/56], Loss: 2.6020\n",
      "Epoch [1/100], Step [37/56], Loss: 2.7660\n",
      "Epoch [1/100], Step [38/56], Loss: 2.9301\n",
      "Epoch [1/100], Step [39/56], Loss: 3.2173\n",
      "Epoch [1/100], Step [40/56], Loss: 3.0871\n",
      "Epoch [1/100], Step [41/56], Loss: 2.3233\n",
      "Epoch [1/100], Step [42/56], Loss: 2.4506\n",
      "Epoch [1/100], Step [43/56], Loss: 3.7987\n",
      "Epoch [1/100], Step [44/56], Loss: 2.6281\n",
      "Epoch [1/100], Step [45/56], Loss: 2.2739\n",
      "Epoch [1/100], Step [46/56], Loss: 2.9707\n",
      "Epoch [1/100], Step [47/56], Loss: 2.7716\n",
      "Epoch [1/100], Step [48/56], Loss: 1.9870\n",
      "Epoch [1/100], Step [49/56], Loss: 2.2203\n",
      "Epoch [1/100], Step [50/56], Loss: 2.2098\n",
      "Epoch [1/100], Step [51/56], Loss: 2.5467\n",
      "Epoch [1/100], Step [52/56], Loss: 1.5150\n",
      "Epoch [1/100], Step [53/56], Loss: 2.0478\n",
      "Epoch [1/100], Step [54/56], Loss: 2.4019\n",
      "Epoch [1/100], Step [55/56], Loss: 2.3793\n",
      "Epoch [1/100], Step [56/56], Loss: 1.2524\n",
      "Val. loss :1.7967\n",
      "Epoch [2/100], Step [1/56], Loss: 1.8323\n",
      "Epoch [2/100], Step [2/56], Loss: 2.1107\n",
      "Epoch [2/100], Step [3/56], Loss: 1.6055\n",
      "Epoch [2/100], Step [4/56], Loss: 1.9988\n",
      "Epoch [2/100], Step [5/56], Loss: 1.7919\n",
      "Epoch [2/100], Step [6/56], Loss: 1.7014\n",
      "Epoch [2/100], Step [7/56], Loss: 1.9237\n",
      "Epoch [2/100], Step [8/56], Loss: 2.2652\n",
      "Epoch [2/100], Step [9/56], Loss: 2.1238\n",
      "Epoch [2/100], Step [10/56], Loss: 2.3568\n",
      "Epoch [2/100], Step [11/56], Loss: 1.9453\n",
      "Epoch [2/100], Step [12/56], Loss: 1.4618\n",
      "Epoch [2/100], Step [13/56], Loss: 2.3212\n",
      "Epoch [2/100], Step [14/56], Loss: 1.8400\n",
      "Epoch [2/100], Step [15/56], Loss: 2.1531\n",
      "Epoch [2/100], Step [16/56], Loss: 1.7209\n",
      "Epoch [2/100], Step [17/56], Loss: 1.9711\n",
      "Epoch [2/100], Step [18/56], Loss: 1.9246\n",
      "Epoch [2/100], Step [19/56], Loss: 1.5824\n",
      "Epoch [2/100], Step [20/56], Loss: 1.6350\n",
      "Epoch [2/100], Step [21/56], Loss: 1.3915\n",
      "Epoch [2/100], Step [22/56], Loss: 1.5623\n",
      "Epoch [2/100], Step [23/56], Loss: 2.0679\n",
      "Epoch [2/100], Step [24/56], Loss: 1.5114\n",
      "Epoch [2/100], Step [25/56], Loss: 1.2048\n",
      "Epoch [2/100], Step [26/56], Loss: 1.7589\n",
      "Epoch [2/100], Step [27/56], Loss: 1.8418\n",
      "Epoch [2/100], Step [28/56], Loss: 1.3122\n",
      "Epoch [2/100], Step [29/56], Loss: 1.7043\n",
      "Epoch [2/100], Step [30/56], Loss: 1.9449\n",
      "Epoch [2/100], Step [31/56], Loss: 1.0882\n",
      "Epoch [2/100], Step [32/56], Loss: 1.6041\n",
      "Epoch [2/100], Step [33/56], Loss: 1.4320\n",
      "Epoch [2/100], Step [34/56], Loss: 1.5174\n",
      "Epoch [2/100], Step [35/56], Loss: 1.9439\n",
      "Epoch [2/100], Step [36/56], Loss: 1.5278\n",
      "Epoch [2/100], Step [37/56], Loss: 1.7266\n",
      "Epoch [2/100], Step [38/56], Loss: 1.6738\n",
      "Epoch [2/100], Step [39/56], Loss: 1.1964\n",
      "Epoch [2/100], Step [40/56], Loss: 1.6807\n",
      "Epoch [2/100], Step [41/56], Loss: 1.7925\n",
      "Epoch [2/100], Step [42/56], Loss: 1.3108\n",
      "Epoch [2/100], Step [43/56], Loss: 2.1637\n",
      "Epoch [2/100], Step [44/56], Loss: 1.1820\n",
      "Epoch [2/100], Step [45/56], Loss: 1.3337\n",
      "Epoch [2/100], Step [46/56], Loss: 1.5985\n",
      "Epoch [2/100], Step [47/56], Loss: 1.2528\n",
      "Epoch [2/100], Step [48/56], Loss: 1.3486\n",
      "Epoch [2/100], Step [49/56], Loss: 1.3686\n",
      "Epoch [2/100], Step [50/56], Loss: 1.4438\n",
      "Epoch [2/100], Step [51/56], Loss: 1.5457\n",
      "Epoch [2/100], Step [52/56], Loss: 1.2235\n",
      "Epoch [2/100], Step [53/56], Loss: 1.4571\n",
      "Epoch [2/100], Step [54/56], Loss: 1.1667\n",
      "Epoch [2/100], Step [55/56], Loss: 1.1847\n",
      "Epoch [2/100], Step [56/56], Loss: 0.5760\n",
      "Val. loss :1.1088\n",
      "Epoch [3/100], Step [1/56], Loss: 1.3945\n",
      "Epoch [3/100], Step [2/56], Loss: 1.0284\n",
      "Epoch [3/100], Step [3/56], Loss: 1.4162\n",
      "Epoch [3/100], Step [4/56], Loss: 1.3962\n",
      "Epoch [3/100], Step [5/56], Loss: 1.0520\n",
      "Epoch [3/100], Step [6/56], Loss: 1.3185\n",
      "Epoch [3/100], Step [7/56], Loss: 1.3803\n",
      "Epoch [3/100], Step [8/56], Loss: 1.3048\n",
      "Epoch [3/100], Step [9/56], Loss: 1.1450\n",
      "Epoch [3/100], Step [10/56], Loss: 1.2014\n",
      "Epoch [3/100], Step [11/56], Loss: 1.0778\n",
      "Epoch [3/100], Step [12/56], Loss: 1.4426\n",
      "Epoch [3/100], Step [13/56], Loss: 1.3935\n",
      "Epoch [3/100], Step [14/56], Loss: 1.2746\n",
      "Epoch [3/100], Step [15/56], Loss: 1.0705\n",
      "Epoch [3/100], Step [16/56], Loss: 1.6261\n",
      "Epoch [3/100], Step [17/56], Loss: 1.2956\n",
      "Epoch [3/100], Step [18/56], Loss: 0.9867\n",
      "Epoch [3/100], Step [19/56], Loss: 1.4081\n",
      "Epoch [3/100], Step [20/56], Loss: 1.3903\n",
      "Epoch [3/100], Step [21/56], Loss: 1.4289\n",
      "Epoch [3/100], Step [22/56], Loss: 1.3155\n",
      "Epoch [3/100], Step [23/56], Loss: 1.1816\n",
      "Epoch [3/100], Step [24/56], Loss: 1.0741\n",
      "Epoch [3/100], Step [25/56], Loss: 1.2470\n",
      "Epoch [3/100], Step [26/56], Loss: 1.0908\n",
      "Epoch [3/100], Step [27/56], Loss: 1.5150\n",
      "Epoch [3/100], Step [28/56], Loss: 1.5749\n",
      "Epoch [3/100], Step [29/56], Loss: 1.2277\n",
      "Epoch [3/100], Step [30/56], Loss: 1.1141\n",
      "Epoch [3/100], Step [31/56], Loss: 1.3892\n",
      "Epoch [3/100], Step [32/56], Loss: 1.2124\n",
      "Epoch [3/100], Step [33/56], Loss: 1.0199\n",
      "Epoch [3/100], Step [34/56], Loss: 0.8154\n",
      "Epoch [3/100], Step [35/56], Loss: 1.1492\n",
      "Epoch [3/100], Step [36/56], Loss: 1.1757\n",
      "Epoch [3/100], Step [37/56], Loss: 1.2641\n",
      "Epoch [3/100], Step [38/56], Loss: 1.2317\n",
      "Epoch [3/100], Step [39/56], Loss: 1.2078\n",
      "Epoch [3/100], Step [40/56], Loss: 1.1046\n",
      "Epoch [3/100], Step [41/56], Loss: 1.3806\n",
      "Epoch [3/100], Step [42/56], Loss: 1.3583\n",
      "Epoch [3/100], Step [43/56], Loss: 0.8481\n",
      "Epoch [3/100], Step [44/56], Loss: 0.9956\n",
      "Epoch [3/100], Step [45/56], Loss: 1.0476\n",
      "Epoch [3/100], Step [46/56], Loss: 0.9127\n",
      "Epoch [3/100], Step [47/56], Loss: 0.9840\n",
      "Epoch [3/100], Step [48/56], Loss: 1.3194\n",
      "Epoch [3/100], Step [49/56], Loss: 1.3792\n",
      "Epoch [3/100], Step [50/56], Loss: 1.0945\n",
      "Epoch [3/100], Step [51/56], Loss: 0.9920\n",
      "Epoch [3/100], Step [52/56], Loss: 1.1413\n",
      "Epoch [3/100], Step [53/56], Loss: 1.1579\n",
      "Epoch [3/100], Step [54/56], Loss: 1.3520\n",
      "Epoch [3/100], Step [55/56], Loss: 1.0939\n",
      "Epoch [3/100], Step [56/56], Loss: 0.6129\n",
      "Val. loss :0.8618\n",
      "Epoch [4/100], Step [1/56], Loss: 1.0622\n",
      "Epoch [4/100], Step [2/56], Loss: 1.1240\n",
      "Epoch [4/100], Step [3/56], Loss: 0.9544\n",
      "Epoch [4/100], Step [4/56], Loss: 1.0719\n",
      "Epoch [4/100], Step [5/56], Loss: 1.2635\n",
      "Epoch [4/100], Step [6/56], Loss: 1.0901\n",
      "Epoch [4/100], Step [7/56], Loss: 1.1680\n",
      "Epoch [4/100], Step [8/56], Loss: 1.1627\n",
      "Epoch [4/100], Step [9/56], Loss: 1.1770\n",
      "Epoch [4/100], Step [10/56], Loss: 0.8424\n",
      "Epoch [4/100], Step [11/56], Loss: 1.0834\n",
      "Epoch [4/100], Step [12/56], Loss: 0.9230\n",
      "Epoch [4/100], Step [13/56], Loss: 0.9940\n",
      "Epoch [4/100], Step [14/56], Loss: 0.8625\n",
      "Epoch [4/100], Step [15/56], Loss: 1.3078\n",
      "Epoch [4/100], Step [16/56], Loss: 0.8544\n",
      "Epoch [4/100], Step [17/56], Loss: 1.1129\n",
      "Epoch [4/100], Step [18/56], Loss: 1.2224\n",
      "Epoch [4/100], Step [19/56], Loss: 1.0494\n",
      "Epoch [4/100], Step [20/56], Loss: 0.9594\n",
      "Epoch [4/100], Step [21/56], Loss: 0.8920\n",
      "Epoch [4/100], Step [22/56], Loss: 0.9309\n",
      "Epoch [4/100], Step [23/56], Loss: 1.1000\n",
      "Epoch [4/100], Step [24/56], Loss: 1.3353\n",
      "Epoch [4/100], Step [25/56], Loss: 0.9488\n",
      "Epoch [4/100], Step [26/56], Loss: 1.0427\n",
      "Epoch [4/100], Step [27/56], Loss: 1.0479\n",
      "Epoch [4/100], Step [28/56], Loss: 0.9313\n",
      "Epoch [4/100], Step [29/56], Loss: 0.9000\n",
      "Epoch [4/100], Step [30/56], Loss: 0.9145\n",
      "Epoch [4/100], Step [31/56], Loss: 0.8871\n",
      "Epoch [4/100], Step [32/56], Loss: 0.9749\n",
      "Epoch [4/100], Step [33/56], Loss: 1.2159\n",
      "Epoch [4/100], Step [34/56], Loss: 0.9718\n",
      "Epoch [4/100], Step [35/56], Loss: 1.1987\n",
      "Epoch [4/100], Step [36/56], Loss: 1.0124\n",
      "Epoch [4/100], Step [37/56], Loss: 0.9593\n",
      "Epoch [4/100], Step [38/56], Loss: 0.8786\n",
      "Epoch [4/100], Step [39/56], Loss: 0.8288\n",
      "Epoch [4/100], Step [40/56], Loss: 0.8961\n",
      "Epoch [4/100], Step [41/56], Loss: 0.8290\n",
      "Epoch [4/100], Step [42/56], Loss: 1.1554\n",
      "Epoch [4/100], Step [43/56], Loss: 0.6993\n",
      "Epoch [4/100], Step [44/56], Loss: 1.0520\n",
      "Epoch [4/100], Step [45/56], Loss: 0.9504\n",
      "Epoch [4/100], Step [46/56], Loss: 1.1389\n",
      "Epoch [4/100], Step [47/56], Loss: 1.2632\n",
      "Epoch [4/100], Step [48/56], Loss: 1.0810\n",
      "Epoch [4/100], Step [49/56], Loss: 1.0958\n",
      "Epoch [4/100], Step [50/56], Loss: 0.7858\n",
      "Epoch [4/100], Step [51/56], Loss: 0.9144\n",
      "Epoch [4/100], Step [52/56], Loss: 0.8927\n",
      "Epoch [4/100], Step [53/56], Loss: 0.9744\n",
      "Epoch [4/100], Step [54/56], Loss: 1.0790\n",
      "Epoch [4/100], Step [55/56], Loss: 0.8508\n",
      "Epoch [4/100], Step [56/56], Loss: 0.4721\n",
      "Val. loss :0.8334\n",
      "Epoch [5/100], Step [1/56], Loss: 1.0588\n",
      "Epoch [5/100], Step [2/56], Loss: 0.8929\n",
      "Epoch [5/100], Step [3/56], Loss: 1.0015\n",
      "Epoch [5/100], Step [4/56], Loss: 0.9185\n",
      "Epoch [5/100], Step [5/56], Loss: 0.7315\n",
      "Epoch [5/100], Step [6/56], Loss: 1.3289\n",
      "Epoch [5/100], Step [7/56], Loss: 0.8696\n",
      "Epoch [5/100], Step [8/56], Loss: 1.0049\n",
      "Epoch [5/100], Step [9/56], Loss: 0.9905\n",
      "Epoch [5/100], Step [10/56], Loss: 0.8650\n",
      "Epoch [5/100], Step [11/56], Loss: 1.0212\n",
      "Epoch [5/100], Step [12/56], Loss: 1.4427\n",
      "Epoch [5/100], Step [13/56], Loss: 1.0618\n",
      "Epoch [5/100], Step [14/56], Loss: 0.9838\n",
      "Epoch [5/100], Step [15/56], Loss: 0.8974\n",
      "Epoch [5/100], Step [16/56], Loss: 0.8680\n",
      "Epoch [5/100], Step [17/56], Loss: 0.7813\n",
      "Epoch [5/100], Step [18/56], Loss: 0.6839\n",
      "Epoch [5/100], Step [19/56], Loss: 0.7997\n",
      "Epoch [5/100], Step [20/56], Loss: 0.7303\n",
      "Epoch [5/100], Step [21/56], Loss: 0.8160\n",
      "Epoch [5/100], Step [22/56], Loss: 0.9852\n",
      "Epoch [5/100], Step [23/56], Loss: 0.8303\n",
      "Epoch [5/100], Step [24/56], Loss: 1.1750\n",
      "Epoch [5/100], Step [25/56], Loss: 1.0371\n",
      "Epoch [5/100], Step [26/56], Loss: 1.0456\n",
      "Epoch [5/100], Step [27/56], Loss: 0.9012\n",
      "Epoch [5/100], Step [28/56], Loss: 1.0068\n",
      "Epoch [5/100], Step [29/56], Loss: 0.9371\n",
      "Epoch [5/100], Step [30/56], Loss: 0.9511\n",
      "Epoch [5/100], Step [31/56], Loss: 1.2476\n",
      "Epoch [5/100], Step [32/56], Loss: 0.8917\n",
      "Epoch [5/100], Step [33/56], Loss: 0.8818\n",
      "Epoch [5/100], Step [34/56], Loss: 0.7521\n",
      "Epoch [5/100], Step [35/56], Loss: 0.8668\n",
      "Epoch [5/100], Step [36/56], Loss: 0.8649\n",
      "Epoch [5/100], Step [37/56], Loss: 0.8236\n",
      "Epoch [5/100], Step [38/56], Loss: 0.8934\n",
      "Epoch [5/100], Step [39/56], Loss: 0.8503\n",
      "Epoch [5/100], Step [40/56], Loss: 0.9154\n",
      "Epoch [5/100], Step [41/56], Loss: 0.8749\n",
      "Epoch [5/100], Step [42/56], Loss: 0.7587\n",
      "Epoch [5/100], Step [43/56], Loss: 0.8335\n",
      "Epoch [5/100], Step [44/56], Loss: 0.8166\n",
      "Epoch [5/100], Step [45/56], Loss: 0.6295\n",
      "Epoch [5/100], Step [46/56], Loss: 0.8322\n",
      "Epoch [5/100], Step [47/56], Loss: 0.8099\n",
      "Epoch [5/100], Step [48/56], Loss: 0.8858\n",
      "Epoch [5/100], Step [49/56], Loss: 0.9424\n",
      "Epoch [5/100], Step [50/56], Loss: 0.7879\n",
      "Epoch [5/100], Step [51/56], Loss: 0.7684\n",
      "Epoch [5/100], Step [52/56], Loss: 0.9823\n",
      "Epoch [5/100], Step [53/56], Loss: 1.0277\n",
      "Epoch [5/100], Step [54/56], Loss: 1.0306\n",
      "Epoch [5/100], Step [55/56], Loss: 0.8465\n",
      "Epoch [5/100], Step [56/56], Loss: 0.3652\n",
      "Val. loss :0.7428\n",
      "Epoch [6/100], Step [1/56], Loss: 0.9442\n",
      "Epoch [6/100], Step [2/56], Loss: 0.6730\n",
      "Epoch [6/100], Step [3/56], Loss: 0.7877\n",
      "Epoch [6/100], Step [4/56], Loss: 1.1401\n",
      "Epoch [6/100], Step [5/56], Loss: 0.6961\n",
      "Epoch [6/100], Step [6/56], Loss: 0.9169\n",
      "Epoch [6/100], Step [7/56], Loss: 0.7456\n",
      "Epoch [6/100], Step [8/56], Loss: 0.7359\n",
      "Epoch [6/100], Step [9/56], Loss: 0.6537\n",
      "Epoch [6/100], Step [10/56], Loss: 0.5617\n",
      "Epoch [6/100], Step [11/56], Loss: 0.8870\n",
      "Epoch [6/100], Step [12/56], Loss: 0.9679\n",
      "Epoch [6/100], Step [13/56], Loss: 0.7102\n",
      "Epoch [6/100], Step [14/56], Loss: 0.8533\n",
      "Epoch [6/100], Step [15/56], Loss: 0.8340\n",
      "Epoch [6/100], Step [16/56], Loss: 0.8985\n",
      "Epoch [6/100], Step [17/56], Loss: 0.7754\n",
      "Epoch [6/100], Step [18/56], Loss: 0.7038\n",
      "Epoch [6/100], Step [19/56], Loss: 0.8939\n",
      "Epoch [6/100], Step [20/56], Loss: 1.1543\n",
      "Epoch [6/100], Step [21/56], Loss: 0.7525\n",
      "Epoch [6/100], Step [22/56], Loss: 0.7250\n",
      "Epoch [6/100], Step [23/56], Loss: 0.7581\n",
      "Epoch [6/100], Step [24/56], Loss: 0.7755\n",
      "Epoch [6/100], Step [25/56], Loss: 0.6560\n",
      "Epoch [6/100], Step [26/56], Loss: 0.8382\n",
      "Epoch [6/100], Step [27/56], Loss: 0.8044\n",
      "Epoch [6/100], Step [28/56], Loss: 0.8078\n",
      "Epoch [6/100], Step [29/56], Loss: 0.9062\n",
      "Epoch [6/100], Step [30/56], Loss: 0.7364\n",
      "Epoch [6/100], Step [31/56], Loss: 0.7039\n",
      "Epoch [6/100], Step [32/56], Loss: 0.8044\n",
      "Epoch [6/100], Step [33/56], Loss: 0.8012\n",
      "Epoch [6/100], Step [34/56], Loss: 0.7004\n",
      "Epoch [6/100], Step [35/56], Loss: 0.7966\n",
      "Epoch [6/100], Step [36/56], Loss: 0.6896\n",
      "Epoch [6/100], Step [37/56], Loss: 0.7701\n",
      "Epoch [6/100], Step [38/56], Loss: 0.7936\n",
      "Epoch [6/100], Step [39/56], Loss: 1.1142\n",
      "Epoch [6/100], Step [40/56], Loss: 0.8081\n",
      "Epoch [6/100], Step [41/56], Loss: 0.7659\n",
      "Epoch [6/100], Step [42/56], Loss: 0.9917\n",
      "Epoch [6/100], Step [43/56], Loss: 0.9057\n",
      "Epoch [6/100], Step [44/56], Loss: 0.5979\n",
      "Epoch [6/100], Step [45/56], Loss: 0.6106\n",
      "Epoch [6/100], Step [46/56], Loss: 0.5482\n",
      "Epoch [6/100], Step [47/56], Loss: 0.7823\n",
      "Epoch [6/100], Step [48/56], Loss: 0.8598\n",
      "Epoch [6/100], Step [49/56], Loss: 1.0934\n",
      "Epoch [6/100], Step [50/56], Loss: 0.7723\n",
      "Epoch [6/100], Step [51/56], Loss: 0.6446\n",
      "Epoch [6/100], Step [52/56], Loss: 1.0980\n",
      "Epoch [6/100], Step [53/56], Loss: 0.8483\n",
      "Epoch [6/100], Step [54/56], Loss: 0.8302\n",
      "Epoch [6/100], Step [55/56], Loss: 0.7456\n",
      "Epoch [6/100], Step [56/56], Loss: 0.4942\n",
      "Val. loss :0.6760\n",
      "Epoch [7/100], Step [1/56], Loss: 0.7468\n",
      "Epoch [7/100], Step [2/56], Loss: 0.8166\n",
      "Epoch [7/100], Step [3/56], Loss: 0.6758\n",
      "Epoch [7/100], Step [4/56], Loss: 0.6108\n",
      "Epoch [7/100], Step [5/56], Loss: 0.6779\n",
      "Epoch [7/100], Step [6/56], Loss: 0.7239\n",
      "Epoch [7/100], Step [7/56], Loss: 0.7514\n",
      "Epoch [7/100], Step [8/56], Loss: 0.6312\n",
      "Epoch [7/100], Step [9/56], Loss: 0.6891\n",
      "Epoch [7/100], Step [10/56], Loss: 0.6022\n",
      "Epoch [7/100], Step [11/56], Loss: 0.6122\n",
      "Epoch [7/100], Step [12/56], Loss: 0.5850\n",
      "Epoch [7/100], Step [13/56], Loss: 0.7129\n",
      "Epoch [7/100], Step [14/56], Loss: 0.9055\n",
      "Epoch [7/100], Step [15/56], Loss: 0.8263\n",
      "Epoch [7/100], Step [16/56], Loss: 0.5773\n",
      "Epoch [7/100], Step [17/56], Loss: 0.6362\n",
      "Epoch [7/100], Step [18/56], Loss: 0.7888\n",
      "Epoch [7/100], Step [19/56], Loss: 0.5453\n",
      "Epoch [7/100], Step [20/56], Loss: 0.7014\n",
      "Epoch [7/100], Step [21/56], Loss: 0.6852\n",
      "Epoch [7/100], Step [22/56], Loss: 0.7009\n",
      "Epoch [7/100], Step [23/56], Loss: 0.8346\n",
      "Epoch [7/100], Step [24/56], Loss: 0.5518\n",
      "Epoch [7/100], Step [25/56], Loss: 0.6747\n",
      "Epoch [7/100], Step [26/56], Loss: 0.6874\n",
      "Epoch [7/100], Step [27/56], Loss: 0.5275\n",
      "Epoch [7/100], Step [28/56], Loss: 0.6820\n",
      "Epoch [7/100], Step [29/56], Loss: 0.6927\n",
      "Epoch [7/100], Step [30/56], Loss: 0.5891\n",
      "Epoch [7/100], Step [31/56], Loss: 0.7702\n",
      "Epoch [7/100], Step [32/56], Loss: 0.6898\n",
      "Epoch [7/100], Step [33/56], Loss: 0.6549\n",
      "Epoch [7/100], Step [34/56], Loss: 0.8033\n",
      "Epoch [7/100], Step [35/56], Loss: 0.5844\n",
      "Epoch [7/100], Step [36/56], Loss: 0.7429\n",
      "Epoch [7/100], Step [37/56], Loss: 0.5865\n",
      "Epoch [7/100], Step [38/56], Loss: 0.6122\n",
      "Epoch [7/100], Step [39/56], Loss: 0.6566\n",
      "Epoch [7/100], Step [40/56], Loss: 0.6105\n",
      "Epoch [7/100], Step [41/56], Loss: 0.5218\n",
      "Epoch [7/100], Step [42/56], Loss: 0.5849\n",
      "Epoch [7/100], Step [43/56], Loss: 0.7431\n",
      "Epoch [7/100], Step [44/56], Loss: 0.7231\n",
      "Epoch [7/100], Step [45/56], Loss: 0.7653\n",
      "Epoch [7/100], Step [46/56], Loss: 0.6125\n",
      "Epoch [7/100], Step [47/56], Loss: 0.8991\n",
      "Epoch [7/100], Step [48/56], Loss: 0.6560\n",
      "Epoch [7/100], Step [49/56], Loss: 0.5553\n",
      "Epoch [7/100], Step [50/56], Loss: 0.5272\n",
      "Epoch [7/100], Step [51/56], Loss: 0.6990\n",
      "Epoch [7/100], Step [52/56], Loss: 0.9152\n",
      "Epoch [7/100], Step [53/56], Loss: 0.5677\n",
      "Epoch [7/100], Step [54/56], Loss: 0.5434\n",
      "Epoch [7/100], Step [55/56], Loss: 0.6116\n",
      "Epoch [7/100], Step [56/56], Loss: 0.3982\n",
      "Val. loss :0.5213\n",
      "Epoch [8/100], Step [1/56], Loss: 0.7616\n",
      "Epoch [8/100], Step [2/56], Loss: 0.6524\n",
      "Epoch [8/100], Step [3/56], Loss: 0.5115\n",
      "Epoch [8/100], Step [4/56], Loss: 0.6129\n",
      "Epoch [8/100], Step [5/56], Loss: 0.7211\n",
      "Epoch [8/100], Step [6/56], Loss: 0.6908\n",
      "Epoch [8/100], Step [7/56], Loss: 0.9376\n",
      "Epoch [8/100], Step [8/56], Loss: 0.5898\n",
      "Epoch [8/100], Step [9/56], Loss: 0.4858\n",
      "Epoch [8/100], Step [10/56], Loss: 0.7227\n",
      "Epoch [8/100], Step [11/56], Loss: 0.4798\n",
      "Epoch [8/100], Step [12/56], Loss: 0.8540\n",
      "Epoch [8/100], Step [13/56], Loss: 0.4566\n",
      "Epoch [8/100], Step [14/56], Loss: 0.6893\n",
      "Epoch [8/100], Step [15/56], Loss: 0.7545\n",
      "Epoch [8/100], Step [16/56], Loss: 0.9959\n",
      "Epoch [8/100], Step [17/56], Loss: 0.6037\n",
      "Epoch [8/100], Step [18/56], Loss: 0.4949\n",
      "Epoch [8/100], Step [19/56], Loss: 0.6337\n",
      "Epoch [8/100], Step [20/56], Loss: 0.7962\n",
      "Epoch [8/100], Step [21/56], Loss: 0.8225\n",
      "Epoch [8/100], Step [22/56], Loss: 0.5887\n",
      "Epoch [8/100], Step [23/56], Loss: 0.5466\n",
      "Epoch [8/100], Step [24/56], Loss: 0.5132\n",
      "Epoch [8/100], Step [25/56], Loss: 0.5427\n",
      "Epoch [8/100], Step [26/56], Loss: 0.8440\n",
      "Epoch [8/100], Step [27/56], Loss: 0.4675\n",
      "Epoch [8/100], Step [28/56], Loss: 0.6427\n",
      "Epoch [8/100], Step [29/56], Loss: 0.5934\n",
      "Epoch [8/100], Step [30/56], Loss: 0.6001\n",
      "Epoch [8/100], Step [31/56], Loss: 0.5727\n",
      "Epoch [8/100], Step [32/56], Loss: 0.7483\n",
      "Epoch [8/100], Step [33/56], Loss: 0.5883\n",
      "Epoch [8/100], Step [34/56], Loss: 0.7728\n",
      "Epoch [8/100], Step [35/56], Loss: 0.6994\n",
      "Epoch [8/100], Step [36/56], Loss: 0.7609\n",
      "Epoch [8/100], Step [37/56], Loss: 0.6258\n",
      "Epoch [8/100], Step [38/56], Loss: 0.6509\n",
      "Epoch [8/100], Step [39/56], Loss: 0.5442\n",
      "Epoch [8/100], Step [40/56], Loss: 0.5015\n",
      "Epoch [8/100], Step [41/56], Loss: 0.6785\n",
      "Epoch [8/100], Step [42/56], Loss: 0.5604\n",
      "Epoch [8/100], Step [43/56], Loss: 0.5247\n",
      "Epoch [8/100], Step [44/56], Loss: 0.4614\n",
      "Epoch [8/100], Step [45/56], Loss: 0.8395\n",
      "Epoch [8/100], Step [46/56], Loss: 0.6740\n",
      "Epoch [8/100], Step [47/56], Loss: 0.8498\n",
      "Epoch [8/100], Step [48/56], Loss: 0.5519\n",
      "Epoch [8/100], Step [49/56], Loss: 0.6548\n",
      "Epoch [8/100], Step [50/56], Loss: 0.5959\n",
      "Epoch [8/100], Step [51/56], Loss: 0.5203\n",
      "Epoch [8/100], Step [52/56], Loss: 0.4182\n",
      "Epoch [8/100], Step [53/56], Loss: 0.5620\n",
      "Epoch [8/100], Step [54/56], Loss: 0.6735\n",
      "Epoch [8/100], Step [55/56], Loss: 0.6126\n",
      "Epoch [8/100], Step [56/56], Loss: 0.3454\n",
      "Val. loss :0.5337\n",
      "Epoch [9/100], Step [1/56], Loss: 0.6352\n",
      "Epoch [9/100], Step [2/56], Loss: 1.1330\n",
      "Epoch [9/100], Step [3/56], Loss: 0.6851\n",
      "Epoch [9/100], Step [4/56], Loss: 0.4830\n",
      "Epoch [9/100], Step [5/56], Loss: 0.7351\n",
      "Epoch [9/100], Step [6/56], Loss: 0.4941\n",
      "Epoch [9/100], Step [7/56], Loss: 0.5542\n",
      "Epoch [9/100], Step [8/56], Loss: 0.5284\n",
      "Epoch [9/100], Step [9/56], Loss: 0.6121\n",
      "Epoch [9/100], Step [10/56], Loss: 0.5749\n",
      "Epoch [9/100], Step [11/56], Loss: 0.6761\n",
      "Epoch [9/100], Step [12/56], Loss: 0.5449\n",
      "Epoch [9/100], Step [13/56], Loss: 0.6659\n",
      "Epoch [9/100], Step [14/56], Loss: 0.6346\n",
      "Epoch [9/100], Step [15/56], Loss: 0.6700\n",
      "Epoch [9/100], Step [16/56], Loss: 0.4540\n",
      "Epoch [9/100], Step [17/56], Loss: 0.7231\n",
      "Epoch [9/100], Step [18/56], Loss: 0.5674\n",
      "Epoch [9/100], Step [19/56], Loss: 0.6749\n",
      "Epoch [9/100], Step [20/56], Loss: 0.6939\n",
      "Epoch [9/100], Step [21/56], Loss: 0.4196\n",
      "Epoch [9/100], Step [22/56], Loss: 0.5653\n",
      "Epoch [9/100], Step [23/56], Loss: 0.4594\n",
      "Epoch [9/100], Step [24/56], Loss: 0.6696\n",
      "Epoch [9/100], Step [25/56], Loss: 0.4403\n",
      "Epoch [9/100], Step [26/56], Loss: 0.3882\n",
      "Epoch [9/100], Step [27/56], Loss: 0.6193\n",
      "Epoch [9/100], Step [28/56], Loss: 0.5383\n",
      "Epoch [9/100], Step [29/56], Loss: 0.4437\n",
      "Epoch [9/100], Step [30/56], Loss: 0.5792\n",
      "Epoch [9/100], Step [31/56], Loss: 0.5769\n",
      "Epoch [9/100], Step [32/56], Loss: 0.4565\n",
      "Epoch [9/100], Step [33/56], Loss: 0.5672\n",
      "Epoch [9/100], Step [34/56], Loss: 0.5642\n",
      "Epoch [9/100], Step [35/56], Loss: 0.4261\n",
      "Epoch [9/100], Step [36/56], Loss: 0.3810\n",
      "Epoch [9/100], Step [37/56], Loss: 0.6979\n",
      "Epoch [9/100], Step [38/56], Loss: 0.8813\n",
      "Epoch [9/100], Step [39/56], Loss: 0.5179\n",
      "Epoch [9/100], Step [40/56], Loss: 0.6609\n",
      "Epoch [9/100], Step [41/56], Loss: 0.8322\n",
      "Epoch [9/100], Step [42/56], Loss: 0.7521\n",
      "Epoch [9/100], Step [43/56], Loss: 0.5111\n",
      "Epoch [9/100], Step [44/56], Loss: 0.9315\n",
      "Epoch [9/100], Step [45/56], Loss: 0.5489\n",
      "Epoch [9/100], Step [46/56], Loss: 0.6074\n",
      "Epoch [9/100], Step [47/56], Loss: 0.4513\n",
      "Epoch [9/100], Step [48/56], Loss: 0.5036\n",
      "Epoch [9/100], Step [49/56], Loss: 0.6784\n",
      "Epoch [9/100], Step [50/56], Loss: 0.5788\n",
      "Epoch [9/100], Step [51/56], Loss: 0.4696\n",
      "Epoch [9/100], Step [52/56], Loss: 0.5978\n",
      "Epoch [9/100], Step [53/56], Loss: 0.6837\n",
      "Epoch [9/100], Step [54/56], Loss: 0.6861\n",
      "Epoch [9/100], Step [55/56], Loss: 0.6423\n",
      "Epoch [9/100], Step [56/56], Loss: 0.2065\n",
      "Val. loss :0.4387\n",
      "Epoch [10/100], Step [1/56], Loss: 0.8146\n",
      "Epoch [10/100], Step [2/56], Loss: 0.4881\n",
      "Epoch [10/100], Step [3/56], Loss: 0.4038\n",
      "Epoch [10/100], Step [4/56], Loss: 0.5534\n",
      "Epoch [10/100], Step [5/56], Loss: 0.4792\n",
      "Epoch [10/100], Step [6/56], Loss: 0.3404\n",
      "Epoch [10/100], Step [7/56], Loss: 0.3789\n",
      "Epoch [10/100], Step [8/56], Loss: 0.3569\n",
      "Epoch [10/100], Step [9/56], Loss: 0.4108\n",
      "Epoch [10/100], Step [10/56], Loss: 0.7500\n",
      "Epoch [10/100], Step [11/56], Loss: 0.7816\n",
      "Epoch [10/100], Step [12/56], Loss: 0.5405\n",
      "Epoch [10/100], Step [13/56], Loss: 0.6781\n",
      "Epoch [10/100], Step [14/56], Loss: 0.3987\n",
      "Epoch [10/100], Step [15/56], Loss: 0.7720\n",
      "Epoch [10/100], Step [16/56], Loss: 0.5033\n",
      "Epoch [10/100], Step [17/56], Loss: 0.6420\n",
      "Epoch [10/100], Step [18/56], Loss: 0.5133\n",
      "Epoch [10/100], Step [19/56], Loss: 0.6150\n",
      "Epoch [10/100], Step [20/56], Loss: 0.6549\n",
      "Epoch [10/100], Step [21/56], Loss: 0.4103\n",
      "Epoch [10/100], Step [22/56], Loss: 0.6972\n",
      "Epoch [10/100], Step [23/56], Loss: 0.4903\n",
      "Epoch [10/100], Step [24/56], Loss: 0.5666\n",
      "Epoch [10/100], Step [25/56], Loss: 0.3184\n",
      "Epoch [10/100], Step [26/56], Loss: 0.3813\n",
      "Epoch [10/100], Step [27/56], Loss: 0.4965\n",
      "Epoch [10/100], Step [28/56], Loss: 0.6165\n",
      "Epoch [10/100], Step [29/56], Loss: 0.3605\n",
      "Epoch [10/100], Step [30/56], Loss: 0.7188\n",
      "Epoch [10/100], Step [31/56], Loss: 0.6520\n",
      "Epoch [10/100], Step [32/56], Loss: 0.5158\n",
      "Epoch [10/100], Step [33/56], Loss: 0.4798\n",
      "Epoch [10/100], Step [34/56], Loss: 0.5892\n",
      "Epoch [10/100], Step [35/56], Loss: 0.3926\n",
      "Epoch [10/100], Step [36/56], Loss: 0.4390\n",
      "Epoch [10/100], Step [37/56], Loss: 0.2916\n",
      "Epoch [10/100], Step [38/56], Loss: 0.4678\n",
      "Epoch [10/100], Step [39/56], Loss: 0.4009\n",
      "Epoch [10/100], Step [40/56], Loss: 0.6317\n",
      "Epoch [10/100], Step [41/56], Loss: 0.4142\n",
      "Epoch [10/100], Step [42/56], Loss: 0.4161\n",
      "Epoch [10/100], Step [43/56], Loss: 0.4501\n",
      "Epoch [10/100], Step [44/56], Loss: 0.7653\n",
      "Epoch [10/100], Step [45/56], Loss: 0.4571\n",
      "Epoch [10/100], Step [46/56], Loss: 0.5935\n",
      "Epoch [10/100], Step [47/56], Loss: 0.5557\n",
      "Epoch [10/100], Step [48/56], Loss: 0.5298\n",
      "Epoch [10/100], Step [49/56], Loss: 0.3683\n",
      "Epoch [10/100], Step [50/56], Loss: 0.5248\n",
      "Epoch [10/100], Step [51/56], Loss: 0.5558\n",
      "Epoch [10/100], Step [52/56], Loss: 0.4427\n",
      "Epoch [10/100], Step [53/56], Loss: 0.4702\n",
      "Epoch [10/100], Step [54/56], Loss: 0.6516\n",
      "Epoch [10/100], Step [55/56], Loss: 0.5346\n",
      "Epoch [10/100], Step [56/56], Loss: 0.2166\n",
      "Val. loss :0.3783\n",
      "Epoch [11/100], Step [1/56], Loss: 0.3266\n",
      "Epoch [11/100], Step [2/56], Loss: 0.3686\n",
      "Epoch [11/100], Step [3/56], Loss: 0.5315\n",
      "Epoch [11/100], Step [4/56], Loss: 0.5804\n",
      "Epoch [11/100], Step [5/56], Loss: 0.3998\n",
      "Epoch [11/100], Step [6/56], Loss: 0.3722\n",
      "Epoch [11/100], Step [7/56], Loss: 0.4257\n",
      "Epoch [11/100], Step [8/56], Loss: 0.3344\n",
      "Epoch [11/100], Step [9/56], Loss: 0.4330\n",
      "Epoch [11/100], Step [10/56], Loss: 0.4669\n",
      "Epoch [11/100], Step [11/56], Loss: 0.5865\n",
      "Epoch [11/100], Step [12/56], Loss: 0.4677\n",
      "Epoch [11/100], Step [13/56], Loss: 0.3878\n",
      "Epoch [11/100], Step [14/56], Loss: 0.5861\n",
      "Epoch [11/100], Step [15/56], Loss: 0.6105\n",
      "Epoch [11/100], Step [16/56], Loss: 0.6474\n",
      "Epoch [11/100], Step [17/56], Loss: 0.3652\n",
      "Epoch [11/100], Step [18/56], Loss: 0.7491\n",
      "Epoch [11/100], Step [19/56], Loss: 0.5474\n",
      "Epoch [11/100], Step [20/56], Loss: 0.5439\n",
      "Epoch [11/100], Step [21/56], Loss: 0.5953\n",
      "Epoch [11/100], Step [22/56], Loss: 0.6317\n",
      "Epoch [11/100], Step [23/56], Loss: 0.5350\n",
      "Epoch [11/100], Step [24/56], Loss: 0.5132\n",
      "Epoch [11/100], Step [25/56], Loss: 0.5331\n",
      "Epoch [11/100], Step [26/56], Loss: 0.5992\n",
      "Epoch [11/100], Step [27/56], Loss: 0.4777\n",
      "Epoch [11/100], Step [28/56], Loss: 0.3372\n",
      "Epoch [11/100], Step [29/56], Loss: 0.2965\n",
      "Epoch [11/100], Step [30/56], Loss: 0.5916\n",
      "Epoch [11/100], Step [31/56], Loss: 0.3076\n",
      "Epoch [11/100], Step [32/56], Loss: 0.4658\n",
      "Epoch [11/100], Step [33/56], Loss: 0.3891\n",
      "Epoch [11/100], Step [34/56], Loss: 0.4336\n",
      "Epoch [11/100], Step [35/56], Loss: 0.4688\n",
      "Epoch [11/100], Step [36/56], Loss: 0.6800\n",
      "Epoch [11/100], Step [37/56], Loss: 0.6645\n",
      "Epoch [11/100], Step [38/56], Loss: 0.3668\n",
      "Epoch [11/100], Step [39/56], Loss: 0.4312\n",
      "Epoch [11/100], Step [40/56], Loss: 0.3959\n",
      "Epoch [11/100], Step [41/56], Loss: 0.5358\n",
      "Epoch [11/100], Step [42/56], Loss: 0.5031\n",
      "Epoch [11/100], Step [43/56], Loss: 0.4000\n",
      "Epoch [11/100], Step [44/56], Loss: 0.4564\n",
      "Epoch [11/100], Step [45/56], Loss: 0.4287\n",
      "Epoch [11/100], Step [46/56], Loss: 0.5656\n",
      "Epoch [11/100], Step [47/56], Loss: 0.3486\n",
      "Epoch [11/100], Step [48/56], Loss: 0.2822\n",
      "Epoch [11/100], Step [49/56], Loss: 0.4927\n",
      "Epoch [11/100], Step [50/56], Loss: 0.4822\n",
      "Epoch [11/100], Step [51/56], Loss: 0.5041\n",
      "Epoch [11/100], Step [52/56], Loss: 0.5428\n",
      "Epoch [11/100], Step [53/56], Loss: 0.5339\n",
      "Epoch [11/100], Step [54/56], Loss: 0.4670\n",
      "Epoch [11/100], Step [55/56], Loss: 0.3843\n",
      "Epoch [11/100], Step [56/56], Loss: 0.2612\n",
      "Val. loss :0.3672\n",
      "Epoch [12/100], Step [1/56], Loss: 0.4316\n",
      "Epoch [12/100], Step [2/56], Loss: 0.6125\n",
      "Epoch [12/100], Step [3/56], Loss: 0.3583\n",
      "Epoch [12/100], Step [4/56], Loss: 0.5417\n",
      "Epoch [12/100], Step [5/56], Loss: 0.3420\n",
      "Epoch [12/100], Step [6/56], Loss: 0.3647\n",
      "Epoch [12/100], Step [7/56], Loss: 0.7752\n",
      "Epoch [12/100], Step [8/56], Loss: 0.3863\n",
      "Epoch [12/100], Step [9/56], Loss: 0.5686\n",
      "Epoch [12/100], Step [10/56], Loss: 0.5798\n",
      "Epoch [12/100], Step [11/56], Loss: 0.4565\n",
      "Epoch [12/100], Step [12/56], Loss: 0.5813\n",
      "Epoch [12/100], Step [13/56], Loss: 0.4877\n",
      "Epoch [12/100], Step [14/56], Loss: 0.5728\n",
      "Epoch [12/100], Step [15/56], Loss: 0.4051\n",
      "Epoch [12/100], Step [16/56], Loss: 0.3583\n",
      "Epoch [12/100], Step [17/56], Loss: 0.3730\n",
      "Epoch [12/100], Step [18/56], Loss: 0.5871\n",
      "Epoch [12/100], Step [19/56], Loss: 0.2860\n",
      "Epoch [12/100], Step [20/56], Loss: 0.4985\n",
      "Epoch [12/100], Step [21/56], Loss: 0.3861\n",
      "Epoch [12/100], Step [22/56], Loss: 0.4018\n",
      "Epoch [12/100], Step [23/56], Loss: 0.3548\n",
      "Epoch [12/100], Step [24/56], Loss: 0.4035\n",
      "Epoch [12/100], Step [25/56], Loss: 0.4959\n",
      "Epoch [12/100], Step [26/56], Loss: 0.5129\n",
      "Epoch [12/100], Step [27/56], Loss: 0.3411\n",
      "Epoch [12/100], Step [28/56], Loss: 0.3115\n",
      "Epoch [12/100], Step [29/56], Loss: 0.7776\n",
      "Epoch [12/100], Step [30/56], Loss: 0.6151\n",
      "Epoch [12/100], Step [31/56], Loss: 0.4618\n",
      "Epoch [12/100], Step [32/56], Loss: 0.2626\n",
      "Epoch [12/100], Step [33/56], Loss: 0.4000\n",
      "Epoch [12/100], Step [34/56], Loss: 0.4493\n",
      "Epoch [12/100], Step [35/56], Loss: 0.4419\n",
      "Epoch [12/100], Step [36/56], Loss: 0.6783\n",
      "Epoch [12/100], Step [37/56], Loss: 0.3581\n",
      "Epoch [12/100], Step [38/56], Loss: 0.4332\n",
      "Epoch [12/100], Step [39/56], Loss: 0.4871\n",
      "Epoch [12/100], Step [40/56], Loss: 0.3383\n",
      "Epoch [12/100], Step [41/56], Loss: 0.2837\n",
      "Epoch [12/100], Step [42/56], Loss: 0.4113\n",
      "Epoch [12/100], Step [43/56], Loss: 0.4693\n",
      "Epoch [12/100], Step [44/56], Loss: 0.5229\n",
      "Epoch [12/100], Step [45/56], Loss: 0.3176\n",
      "Epoch [12/100], Step [46/56], Loss: 0.3962\n",
      "Epoch [12/100], Step [47/56], Loss: 0.3403\n",
      "Epoch [12/100], Step [48/56], Loss: 0.3051\n",
      "Epoch [12/100], Step [49/56], Loss: 0.9195\n",
      "Epoch [12/100], Step [50/56], Loss: 0.3067\n",
      "Epoch [12/100], Step [51/56], Loss: 0.5335\n",
      "Epoch [12/100], Step [52/56], Loss: 0.4122\n",
      "Epoch [12/100], Step [53/56], Loss: 0.4511\n",
      "Epoch [12/100], Step [54/56], Loss: 0.6187\n",
      "Epoch [12/100], Step [55/56], Loss: 0.2638\n",
      "Epoch [12/100], Step [56/56], Loss: 0.2108\n",
      "Val. loss :0.3499\n",
      "Epoch [13/100], Step [1/56], Loss: 0.4962\n",
      "Epoch [13/100], Step [2/56], Loss: 0.6705\n",
      "Epoch [13/100], Step [3/56], Loss: 0.4983\n",
      "Epoch [13/100], Step [4/56], Loss: 0.4397\n",
      "Epoch [13/100], Step [5/56], Loss: 0.4694\n",
      "Epoch [13/100], Step [6/56], Loss: 0.4305\n",
      "Epoch [13/100], Step [7/56], Loss: 0.5072\n",
      "Epoch [13/100], Step [8/56], Loss: 0.5347\n",
      "Epoch [13/100], Step [9/56], Loss: 0.4289\n",
      "Epoch [13/100], Step [10/56], Loss: 0.3061\n",
      "Epoch [13/100], Step [11/56], Loss: 0.4633\n",
      "Epoch [13/100], Step [12/56], Loss: 0.2592\n",
      "Epoch [13/100], Step [13/56], Loss: 0.4808\n",
      "Epoch [13/100], Step [14/56], Loss: 0.4624\n",
      "Epoch [13/100], Step [15/56], Loss: 0.6801\n",
      "Epoch [13/100], Step [16/56], Loss: 0.4471\n",
      "Epoch [13/100], Step [17/56], Loss: 0.3595\n",
      "Epoch [13/100], Step [18/56], Loss: 0.3664\n",
      "Epoch [13/100], Step [19/56], Loss: 0.6602\n",
      "Epoch [13/100], Step [20/56], Loss: 0.6877\n",
      "Epoch [13/100], Step [21/56], Loss: 0.4648\n",
      "Epoch [13/100], Step [22/56], Loss: 0.6017\n",
      "Epoch [13/100], Step [23/56], Loss: 0.3897\n",
      "Epoch [13/100], Step [24/56], Loss: 0.3223\n",
      "Epoch [13/100], Step [25/56], Loss: 0.3432\n",
      "Epoch [13/100], Step [26/56], Loss: 0.2787\n",
      "Epoch [13/100], Step [27/56], Loss: 0.4871\n",
      "Epoch [13/100], Step [28/56], Loss: 0.3507\n",
      "Epoch [13/100], Step [29/56], Loss: 0.4705\n",
      "Epoch [13/100], Step [30/56], Loss: 0.5545\n",
      "Epoch [13/100], Step [31/56], Loss: 0.4503\n",
      "Epoch [13/100], Step [32/56], Loss: 0.4986\n",
      "Epoch [13/100], Step [33/56], Loss: 0.3481\n",
      "Epoch [13/100], Step [34/56], Loss: 0.4328\n",
      "Epoch [13/100], Step [35/56], Loss: 0.3469\n",
      "Epoch [13/100], Step [36/56], Loss: 0.4097\n",
      "Epoch [13/100], Step [37/56], Loss: 0.4394\n",
      "Epoch [13/100], Step [38/56], Loss: 0.2548\n",
      "Epoch [13/100], Step [39/56], Loss: 0.5268\n",
      "Epoch [13/100], Step [40/56], Loss: 0.4165\n",
      "Epoch [13/100], Step [41/56], Loss: 0.3147\n",
      "Epoch [13/100], Step [42/56], Loss: 0.5652\n",
      "Epoch [13/100], Step [43/56], Loss: 0.3679\n",
      "Epoch [13/100], Step [44/56], Loss: 0.4255\n",
      "Epoch [13/100], Step [45/56], Loss: 0.3941\n",
      "Epoch [13/100], Step [46/56], Loss: 0.3590\n",
      "Epoch [13/100], Step [47/56], Loss: 0.4424\n",
      "Epoch [13/100], Step [48/56], Loss: 0.4287\n",
      "Epoch [13/100], Step [49/56], Loss: 0.3509\n",
      "Epoch [13/100], Step [50/56], Loss: 0.4104\n",
      "Epoch [13/100], Step [51/56], Loss: 0.3396\n",
      "Epoch [13/100], Step [52/56], Loss: 0.4111\n",
      "Epoch [13/100], Step [53/56], Loss: 0.3473\n",
      "Epoch [13/100], Step [54/56], Loss: 0.3704\n",
      "Epoch [13/100], Step [55/56], Loss: 0.2320\n",
      "Epoch [13/100], Step [56/56], Loss: 0.1586\n",
      "Val. loss :0.3287\n",
      "Epoch [14/100], Step [1/56], Loss: 0.3641\n",
      "Epoch [14/100], Step [2/56], Loss: 0.2958\n",
      "Epoch [14/100], Step [3/56], Loss: 0.4079\n",
      "Epoch [14/100], Step [4/56], Loss: 0.3093\n",
      "Epoch [14/100], Step [5/56], Loss: 0.4855\n",
      "Epoch [14/100], Step [6/56], Loss: 0.5200\n",
      "Epoch [14/100], Step [7/56], Loss: 0.3292\n",
      "Epoch [14/100], Step [8/56], Loss: 0.5524\n",
      "Epoch [14/100], Step [9/56], Loss: 0.3751\n",
      "Epoch [14/100], Step [10/56], Loss: 0.3182\n",
      "Epoch [14/100], Step [11/56], Loss: 0.4532\n",
      "Epoch [14/100], Step [12/56], Loss: 0.2726\n",
      "Epoch [14/100], Step [13/56], Loss: 0.3803\n",
      "Epoch [14/100], Step [14/56], Loss: 0.5199\n",
      "Epoch [14/100], Step [15/56], Loss: 0.3076\n",
      "Epoch [14/100], Step [16/56], Loss: 0.3744\n",
      "Epoch [14/100], Step [17/56], Loss: 0.2551\n",
      "Epoch [14/100], Step [18/56], Loss: 0.5252\n",
      "Epoch [14/100], Step [19/56], Loss: 0.4095\n",
      "Epoch [14/100], Step [20/56], Loss: 0.3114\n",
      "Epoch [14/100], Step [21/56], Loss: 0.6349\n",
      "Epoch [14/100], Step [22/56], Loss: 0.4153\n",
      "Epoch [14/100], Step [23/56], Loss: 0.3442\n",
      "Epoch [14/100], Step [24/56], Loss: 0.4515\n",
      "Epoch [14/100], Step [25/56], Loss: 0.4083\n",
      "Epoch [14/100], Step [26/56], Loss: 0.2514\n",
      "Epoch [14/100], Step [27/56], Loss: 0.3689\n",
      "Epoch [14/100], Step [28/56], Loss: 0.3744\n",
      "Epoch [14/100], Step [29/56], Loss: 0.3550\n",
      "Epoch [14/100], Step [30/56], Loss: 0.4968\n",
      "Epoch [14/100], Step [31/56], Loss: 0.3901\n",
      "Epoch [14/100], Step [32/56], Loss: 0.6396\n",
      "Epoch [14/100], Step [33/56], Loss: 0.3646\n",
      "Epoch [14/100], Step [34/56], Loss: 0.4924\n",
      "Epoch [14/100], Step [35/56], Loss: 0.4955\n",
      "Epoch [14/100], Step [36/56], Loss: 0.3730\n",
      "Epoch [14/100], Step [37/56], Loss: 0.4281\n",
      "Epoch [14/100], Step [38/56], Loss: 0.2998\n",
      "Epoch [14/100], Step [39/56], Loss: 0.3569\n",
      "Epoch [14/100], Step [40/56], Loss: 0.4127\n",
      "Epoch [14/100], Step [41/56], Loss: 0.3780\n",
      "Epoch [14/100], Step [42/56], Loss: 0.2501\n",
      "Epoch [14/100], Step [43/56], Loss: 0.4219\n",
      "Epoch [14/100], Step [44/56], Loss: 0.2890\n",
      "Epoch [14/100], Step [45/56], Loss: 0.3847\n",
      "Epoch [14/100], Step [46/56], Loss: 0.3363\n",
      "Epoch [14/100], Step [47/56], Loss: 0.3939\n",
      "Epoch [14/100], Step [48/56], Loss: 0.2556\n",
      "Epoch [14/100], Step [49/56], Loss: 0.4300\n",
      "Epoch [14/100], Step [50/56], Loss: 0.3164\n",
      "Epoch [14/100], Step [51/56], Loss: 0.3527\n",
      "Epoch [14/100], Step [52/56], Loss: 0.2461\n",
      "Epoch [14/100], Step [53/56], Loss: 0.1917\n",
      "Epoch [14/100], Step [54/56], Loss: 0.2025\n",
      "Epoch [14/100], Step [55/56], Loss: 0.2735\n",
      "Epoch [14/100], Step [56/56], Loss: 0.2222\n",
      "Val. loss :0.2759\n",
      "Epoch [15/100], Step [1/56], Loss: 0.3169\n",
      "Epoch [15/100], Step [2/56], Loss: 0.2764\n",
      "Epoch [15/100], Step [3/56], Loss: 0.3342\n",
      "Epoch [15/100], Step [4/56], Loss: 0.3497\n",
      "Epoch [15/100], Step [5/56], Loss: 0.3042\n",
      "Epoch [15/100], Step [6/56], Loss: 0.3246\n",
      "Epoch [15/100], Step [7/56], Loss: 0.2342\n",
      "Epoch [15/100], Step [8/56], Loss: 0.2788\n",
      "Epoch [15/100], Step [9/56], Loss: 0.4049\n",
      "Epoch [15/100], Step [10/56], Loss: 0.4087\n",
      "Epoch [15/100], Step [11/56], Loss: 0.3636\n",
      "Epoch [15/100], Step [12/56], Loss: 0.2895\n",
      "Epoch [15/100], Step [13/56], Loss: 0.3330\n",
      "Epoch [15/100], Step [14/56], Loss: 0.3979\n",
      "Epoch [15/100], Step [15/56], Loss: 0.3402\n",
      "Epoch [15/100], Step [16/56], Loss: 0.2835\n",
      "Epoch [15/100], Step [17/56], Loss: 0.4916\n",
      "Epoch [15/100], Step [18/56], Loss: 0.3257\n",
      "Epoch [15/100], Step [19/56], Loss: 0.4202\n",
      "Epoch [15/100], Step [20/56], Loss: 0.6366\n",
      "Epoch [15/100], Step [21/56], Loss: 0.5856\n",
      "Epoch [15/100], Step [22/56], Loss: 0.3853\n",
      "Epoch [15/100], Step [23/56], Loss: 0.5128\n",
      "Epoch [15/100], Step [24/56], Loss: 0.3705\n",
      "Epoch [15/100], Step [25/56], Loss: 0.5119\n",
      "Epoch [15/100], Step [26/56], Loss: 0.5196\n",
      "Epoch [15/100], Step [27/56], Loss: 0.4653\n",
      "Epoch [15/100], Step [28/56], Loss: 0.3552\n",
      "Epoch [15/100], Step [29/56], Loss: 0.4088\n",
      "Epoch [15/100], Step [30/56], Loss: 0.3689\n",
      "Epoch [15/100], Step [31/56], Loss: 0.3039\n",
      "Epoch [15/100], Step [32/56], Loss: 0.4318\n",
      "Epoch [15/100], Step [33/56], Loss: 0.4548\n",
      "Epoch [15/100], Step [34/56], Loss: 0.2806\n",
      "Epoch [15/100], Step [35/56], Loss: 0.4474\n",
      "Epoch [15/100], Step [36/56], Loss: 0.7297\n",
      "Epoch [15/100], Step [37/56], Loss: 0.7631\n",
      "Epoch [15/100], Step [38/56], Loss: 0.7404\n",
      "Epoch [15/100], Step [39/56], Loss: 0.3192\n",
      "Epoch [15/100], Step [40/56], Loss: 0.5763\n",
      "Epoch [15/100], Step [41/56], Loss: 0.3199\n",
      "Epoch [15/100], Step [42/56], Loss: 0.3363\n",
      "Epoch [15/100], Step [43/56], Loss: 0.3949\n",
      "Epoch [15/100], Step [44/56], Loss: 0.3445\n",
      "Epoch [15/100], Step [45/56], Loss: 0.2674\n",
      "Epoch [15/100], Step [46/56], Loss: 0.3195\n",
      "Epoch [15/100], Step [47/56], Loss: 0.2315\n",
      "Epoch [15/100], Step [48/56], Loss: 0.5654\n",
      "Epoch [15/100], Step [49/56], Loss: 0.5159\n",
      "Epoch [15/100], Step [50/56], Loss: 0.3873\n",
      "Epoch [15/100], Step [51/56], Loss: 0.1918\n",
      "Epoch [15/100], Step [52/56], Loss: 0.2012\n",
      "Epoch [15/100], Step [53/56], Loss: 0.2755\n",
      "Epoch [15/100], Step [54/56], Loss: 0.2711\n",
      "Epoch [15/100], Step [55/56], Loss: 0.2398\n",
      "Epoch [15/100], Step [56/56], Loss: 0.3937\n",
      "Val. loss :0.2687\n",
      "Epoch [16/100], Step [1/56], Loss: 0.5097\n",
      "Epoch [16/100], Step [2/56], Loss: 0.2288\n",
      "Epoch [16/100], Step [3/56], Loss: 0.4823\n",
      "Epoch [16/100], Step [4/56], Loss: 0.4440\n",
      "Epoch [16/100], Step [5/56], Loss: 0.1807\n",
      "Epoch [16/100], Step [6/56], Loss: 0.6367\n",
      "Epoch [16/100], Step [7/56], Loss: 0.3887\n",
      "Epoch [16/100], Step [8/56], Loss: 0.2477\n",
      "Epoch [16/100], Step [9/56], Loss: 0.2474\n",
      "Epoch [16/100], Step [10/56], Loss: 0.1597\n",
      "Epoch [16/100], Step [11/56], Loss: 0.2601\n",
      "Epoch [16/100], Step [12/56], Loss: 0.3218\n",
      "Epoch [16/100], Step [13/56], Loss: 0.4233\n",
      "Epoch [16/100], Step [14/56], Loss: 0.4488\n",
      "Epoch [16/100], Step [15/56], Loss: 0.2240\n",
      "Epoch [16/100], Step [16/56], Loss: 0.4163\n",
      "Epoch [16/100], Step [17/56], Loss: 0.2591\n",
      "Epoch [16/100], Step [18/56], Loss: 0.4504\n",
      "Epoch [16/100], Step [19/56], Loss: 0.2292\n",
      "Epoch [16/100], Step [20/56], Loss: 0.4021\n",
      "Epoch [16/100], Step [21/56], Loss: 0.3121\n",
      "Epoch [16/100], Step [22/56], Loss: 0.2175\n",
      "Epoch [16/100], Step [23/56], Loss: 0.4797\n",
      "Epoch [16/100], Step [24/56], Loss: 0.2970\n",
      "Epoch [16/100], Step [25/56], Loss: 0.2804\n",
      "Epoch [16/100], Step [26/56], Loss: 0.4001\n",
      "Epoch [16/100], Step [27/56], Loss: 0.2140\n",
      "Epoch [16/100], Step [28/56], Loss: 0.4769\n",
      "Epoch [16/100], Step [29/56], Loss: 0.3187\n",
      "Epoch [16/100], Step [30/56], Loss: 0.4756\n",
      "Epoch [16/100], Step [31/56], Loss: 0.1888\n",
      "Epoch [16/100], Step [32/56], Loss: 0.3568\n",
      "Epoch [16/100], Step [33/56], Loss: 0.4028\n",
      "Epoch [16/100], Step [34/56], Loss: 0.2356\n",
      "Epoch [16/100], Step [35/56], Loss: 0.2647\n",
      "Epoch [16/100], Step [36/56], Loss: 0.3468\n",
      "Epoch [16/100], Step [37/56], Loss: 0.2763\n",
      "Epoch [16/100], Step [38/56], Loss: 0.2489\n",
      "Epoch [16/100], Step [39/56], Loss: 0.4366\n",
      "Epoch [16/100], Step [40/56], Loss: 0.2741\n",
      "Epoch [16/100], Step [41/56], Loss: 0.4660\n",
      "Epoch [16/100], Step [42/56], Loss: 0.3289\n",
      "Epoch [16/100], Step [43/56], Loss: 0.5319\n",
      "Epoch [16/100], Step [44/56], Loss: 0.2138\n",
      "Epoch [16/100], Step [45/56], Loss: 0.2466\n",
      "Epoch [16/100], Step [46/56], Loss: 0.3527\n",
      "Epoch [16/100], Step [47/56], Loss: 0.4343\n",
      "Epoch [16/100], Step [48/56], Loss: 0.7957\n",
      "Epoch [16/100], Step [49/56], Loss: 0.5788\n",
      "Epoch [16/100], Step [50/56], Loss: 0.5348\n",
      "Epoch [16/100], Step [51/56], Loss: 0.4570\n",
      "Epoch [16/100], Step [52/56], Loss: 0.4614\n",
      "Epoch [16/100], Step [53/56], Loss: 0.4242\n",
      "Epoch [16/100], Step [54/56], Loss: 0.4182\n",
      "Epoch [16/100], Step [55/56], Loss: 0.4082\n",
      "Epoch [16/100], Step [56/56], Loss: 0.1842\n",
      "Val. loss :0.2567\n",
      "Epoch [17/100], Step [1/56], Loss: 0.2616\n",
      "Epoch [17/100], Step [2/56], Loss: 0.3239\n",
      "Epoch [17/100], Step [3/56], Loss: 0.2126\n",
      "Epoch [17/100], Step [4/56], Loss: 0.2394\n",
      "Epoch [17/100], Step [5/56], Loss: 0.2757\n",
      "Epoch [17/100], Step [6/56], Loss: 0.3089\n",
      "Epoch [17/100], Step [7/56], Loss: 0.4145\n",
      "Epoch [17/100], Step [8/56], Loss: 0.3095\n",
      "Epoch [17/100], Step [9/56], Loss: 0.2971\n",
      "Epoch [17/100], Step [10/56], Loss: 0.5966\n",
      "Epoch [17/100], Step [11/56], Loss: 0.2777\n",
      "Epoch [17/100], Step [12/56], Loss: 0.2005\n",
      "Epoch [17/100], Step [13/56], Loss: 0.3535\n",
      "Epoch [17/100], Step [14/56], Loss: 0.3754\n",
      "Epoch [17/100], Step [15/56], Loss: 0.3634\n",
      "Epoch [17/100], Step [16/56], Loss: 0.4837\n",
      "Epoch [17/100], Step [17/56], Loss: 0.4020\n",
      "Epoch [17/100], Step [18/56], Loss: 0.3879\n",
      "Epoch [17/100], Step [19/56], Loss: 0.4349\n",
      "Epoch [17/100], Step [20/56], Loss: 0.3339\n",
      "Epoch [17/100], Step [21/56], Loss: 0.6468\n",
      "Epoch [17/100], Step [22/56], Loss: 0.3337\n",
      "Epoch [17/100], Step [23/56], Loss: 0.3345\n",
      "Epoch [17/100], Step [24/56], Loss: 0.5186\n",
      "Epoch [17/100], Step [25/56], Loss: 0.2023\n",
      "Epoch [17/100], Step [26/56], Loss: 0.3499\n",
      "Epoch [17/100], Step [27/56], Loss: 0.4039\n",
      "Epoch [17/100], Step [28/56], Loss: 0.5958\n",
      "Epoch [17/100], Step [29/56], Loss: 0.2392\n",
      "Epoch [17/100], Step [30/56], Loss: 0.4652\n",
      "Epoch [17/100], Step [31/56], Loss: 0.3328\n",
      "Epoch [17/100], Step [32/56], Loss: 0.2127\n",
      "Epoch [17/100], Step [33/56], Loss: 0.2280\n",
      "Epoch [17/100], Step [34/56], Loss: 0.3887\n",
      "Epoch [17/100], Step [35/56], Loss: 0.2808\n",
      "Epoch [17/100], Step [36/56], Loss: 0.4355\n",
      "Epoch [17/100], Step [37/56], Loss: 0.3280\n",
      "Epoch [17/100], Step [38/56], Loss: 0.1953\n",
      "Epoch [17/100], Step [39/56], Loss: 0.3471\n",
      "Epoch [17/100], Step [40/56], Loss: 0.1993\n",
      "Epoch [17/100], Step [41/56], Loss: 0.1995\n",
      "Epoch [17/100], Step [42/56], Loss: 0.3631\n",
      "Epoch [17/100], Step [43/56], Loss: 0.3991\n",
      "Epoch [17/100], Step [44/56], Loss: 0.5014\n",
      "Epoch [17/100], Step [45/56], Loss: 0.2245\n",
      "Epoch [17/100], Step [46/56], Loss: 0.2750\n",
      "Epoch [17/100], Step [47/56], Loss: 0.3192\n",
      "Epoch [17/100], Step [48/56], Loss: 0.3145\n",
      "Epoch [17/100], Step [49/56], Loss: 0.2185\n",
      "Epoch [17/100], Step [50/56], Loss: 0.2052\n",
      "Epoch [17/100], Step [51/56], Loss: 0.2973\n",
      "Epoch [17/100], Step [52/56], Loss: 0.3686\n",
      "Epoch [17/100], Step [53/56], Loss: 0.3179\n",
      "Epoch [17/100], Step [54/56], Loss: 0.3812\n",
      "Epoch [17/100], Step [55/56], Loss: 0.2346\n",
      "Epoch [17/100], Step [56/56], Loss: 0.0924\n",
      "Val. loss :0.2618\n",
      "Epoch [18/100], Step [1/56], Loss: 0.2659\n",
      "Epoch [18/100], Step [2/56], Loss: 0.2488\n",
      "Epoch [18/100], Step [3/56], Loss: 0.2800\n",
      "Epoch [18/100], Step [4/56], Loss: 0.3382\n",
      "Epoch [18/100], Step [5/56], Loss: 0.1861\n",
      "Epoch [18/100], Step [6/56], Loss: 0.4074\n",
      "Epoch [18/100], Step [7/56], Loss: 0.2900\n",
      "Epoch [18/100], Step [8/56], Loss: 0.1831\n",
      "Epoch [18/100], Step [9/56], Loss: 0.1362\n",
      "Epoch [18/100], Step [10/56], Loss: 0.3656\n",
      "Epoch [18/100], Step [11/56], Loss: 0.3302\n",
      "Epoch [18/100], Step [12/56], Loss: 0.2576\n",
      "Epoch [18/100], Step [13/56], Loss: 0.4063\n",
      "Epoch [18/100], Step [14/56], Loss: 0.3992\n",
      "Epoch [18/100], Step [15/56], Loss: 0.2581\n",
      "Epoch [18/100], Step [16/56], Loss: 0.3151\n",
      "Epoch [18/100], Step [17/56], Loss: 0.2811\n",
      "Epoch [18/100], Step [18/56], Loss: 0.3163\n",
      "Epoch [18/100], Step [19/56], Loss: 0.3333\n",
      "Epoch [18/100], Step [20/56], Loss: 0.3160\n",
      "Epoch [18/100], Step [21/56], Loss: 0.5161\n",
      "Epoch [18/100], Step [22/56], Loss: 0.3797\n",
      "Epoch [18/100], Step [23/56], Loss: 0.4084\n",
      "Epoch [18/100], Step [24/56], Loss: 0.2030\n",
      "Epoch [18/100], Step [25/56], Loss: 0.2505\n",
      "Epoch [18/100], Step [26/56], Loss: 0.3069\n",
      "Epoch [18/100], Step [27/56], Loss: 0.3992\n",
      "Epoch [18/100], Step [28/56], Loss: 0.4484\n",
      "Epoch [18/100], Step [29/56], Loss: 0.1691\n",
      "Epoch [18/100], Step [30/56], Loss: 0.2728\n",
      "Epoch [18/100], Step [31/56], Loss: 0.1776\n",
      "Epoch [18/100], Step [32/56], Loss: 0.2978\n",
      "Epoch [18/100], Step [33/56], Loss: 0.1916\n",
      "Epoch [18/100], Step [34/56], Loss: 0.3975\n",
      "Epoch [18/100], Step [35/56], Loss: 0.2416\n",
      "Epoch [18/100], Step [36/56], Loss: 0.5850\n",
      "Epoch [18/100], Step [37/56], Loss: 0.3608\n",
      "Epoch [18/100], Step [38/56], Loss: 0.2403\n",
      "Epoch [18/100], Step [39/56], Loss: 0.3916\n",
      "Epoch [18/100], Step [40/56], Loss: 0.2292\n",
      "Epoch [18/100], Step [41/56], Loss: 0.4050\n",
      "Epoch [18/100], Step [42/56], Loss: 0.2624\n",
      "Epoch [18/100], Step [43/56], Loss: 0.3223\n",
      "Epoch [18/100], Step [44/56], Loss: 0.4822\n",
      "Epoch [18/100], Step [45/56], Loss: 0.2535\n",
      "Epoch [18/100], Step [46/56], Loss: 0.2517\n",
      "Epoch [18/100], Step [47/56], Loss: 0.3176\n",
      "Epoch [18/100], Step [48/56], Loss: 0.2396\n",
      "Epoch [18/100], Step [49/56], Loss: 0.2191\n",
      "Epoch [18/100], Step [50/56], Loss: 0.2364\n",
      "Epoch [18/100], Step [51/56], Loss: 0.3084\n",
      "Epoch [18/100], Step [52/56], Loss: 0.2249\n",
      "Epoch [18/100], Step [53/56], Loss: 0.5015\n",
      "Epoch [18/100], Step [54/56], Loss: 0.2373\n",
      "Epoch [18/100], Step [55/56], Loss: 0.1803\n",
      "Epoch [18/100], Step [56/56], Loss: 0.1059\n",
      "Val. loss :0.2191\n",
      "Epoch [19/100], Step [1/56], Loss: 0.3216\n",
      "Epoch [19/100], Step [2/56], Loss: 0.2587\n",
      "Epoch [19/100], Step [3/56], Loss: 0.2021\n",
      "Epoch [19/100], Step [4/56], Loss: 0.1670\n",
      "Epoch [19/100], Step [5/56], Loss: 0.1372\n",
      "Epoch [19/100], Step [6/56], Loss: 0.2795\n",
      "Epoch [19/100], Step [7/56], Loss: 0.2706\n",
      "Epoch [19/100], Step [8/56], Loss: 0.1196\n",
      "Epoch [19/100], Step [9/56], Loss: 0.2760\n",
      "Epoch [19/100], Step [10/56], Loss: 0.3436\n",
      "Epoch [19/100], Step [11/56], Loss: 0.1599\n",
      "Epoch [19/100], Step [12/56], Loss: 0.5934\n",
      "Epoch [19/100], Step [13/56], Loss: 0.2426\n",
      "Epoch [19/100], Step [14/56], Loss: 0.3798\n",
      "Epoch [19/100], Step [15/56], Loss: 0.5712\n",
      "Epoch [19/100], Step [16/56], Loss: 0.2422\n",
      "Epoch [19/100], Step [17/56], Loss: 0.2926\n",
      "Epoch [19/100], Step [18/56], Loss: 0.2345\n",
      "Epoch [19/100], Step [19/56], Loss: 0.3586\n",
      "Epoch [19/100], Step [20/56], Loss: 0.2362\n",
      "Epoch [19/100], Step [21/56], Loss: 0.1898\n",
      "Epoch [19/100], Step [22/56], Loss: 0.2818\n",
      "Epoch [19/100], Step [23/56], Loss: 0.2178\n",
      "Epoch [19/100], Step [24/56], Loss: 0.2315\n",
      "Epoch [19/100], Step [25/56], Loss: 0.4156\n",
      "Epoch [19/100], Step [26/56], Loss: 0.2147\n",
      "Epoch [19/100], Step [27/56], Loss: 0.2222\n",
      "Epoch [19/100], Step [28/56], Loss: 0.1899\n",
      "Epoch [19/100], Step [29/56], Loss: 0.2176\n",
      "Epoch [19/100], Step [30/56], Loss: 0.2963\n",
      "Epoch [19/100], Step [31/56], Loss: 0.5645\n",
      "Epoch [19/100], Step [32/56], Loss: 0.5725\n",
      "Epoch [19/100], Step [33/56], Loss: 0.3707\n",
      "Epoch [19/100], Step [34/56], Loss: 0.2437\n",
      "Epoch [19/100], Step [35/56], Loss: 0.2451\n",
      "Epoch [19/100], Step [36/56], Loss: 0.2308\n",
      "Epoch [19/100], Step [37/56], Loss: 0.3774\n",
      "Epoch [19/100], Step [38/56], Loss: 0.2092\n",
      "Epoch [19/100], Step [39/56], Loss: 0.5396\n",
      "Epoch [19/100], Step [40/56], Loss: 0.2675\n",
      "Epoch [19/100], Step [41/56], Loss: 0.3259\n",
      "Epoch [19/100], Step [42/56], Loss: 0.2897\n",
      "Epoch [19/100], Step [43/56], Loss: 0.1559\n",
      "Epoch [19/100], Step [44/56], Loss: 0.3035\n",
      "Epoch [19/100], Step [45/56], Loss: 0.2187\n",
      "Epoch [19/100], Step [46/56], Loss: 0.2652\n",
      "Epoch [19/100], Step [47/56], Loss: 0.1741\n",
      "Epoch [19/100], Step [48/56], Loss: 0.2431\n",
      "Epoch [19/100], Step [49/56], Loss: 0.3385\n",
      "Epoch [19/100], Step [50/56], Loss: 0.2088\n",
      "Epoch [19/100], Step [51/56], Loss: 0.2323\n",
      "Epoch [19/100], Step [52/56], Loss: 0.2495\n",
      "Epoch [19/100], Step [53/56], Loss: 0.2562\n",
      "Epoch [19/100], Step [54/56], Loss: 0.3265\n",
      "Epoch [19/100], Step [55/56], Loss: 0.2829\n",
      "Epoch [19/100], Step [56/56], Loss: 0.0979\n",
      "Val. loss :0.2378\n",
      "Epoch [20/100], Step [1/56], Loss: 0.5448\n",
      "Epoch [20/100], Step [2/56], Loss: 0.4184\n",
      "Epoch [20/100], Step [3/56], Loss: 0.2376\n",
      "Epoch [20/100], Step [4/56], Loss: 0.2213\n",
      "Epoch [20/100], Step [5/56], Loss: 0.2557\n",
      "Epoch [20/100], Step [6/56], Loss: 0.4375\n",
      "Epoch [20/100], Step [7/56], Loss: 0.2744\n",
      "Epoch [20/100], Step [8/56], Loss: 0.2540\n",
      "Epoch [20/100], Step [9/56], Loss: 0.1302\n",
      "Epoch [20/100], Step [10/56], Loss: 0.1555\n",
      "Epoch [20/100], Step [11/56], Loss: 0.3134\n",
      "Epoch [20/100], Step [12/56], Loss: 0.3477\n",
      "Epoch [20/100], Step [13/56], Loss: 0.3104\n",
      "Epoch [20/100], Step [14/56], Loss: 0.4771\n",
      "Epoch [20/100], Step [15/56], Loss: 0.2126\n",
      "Epoch [20/100], Step [16/56], Loss: 0.1925\n",
      "Epoch [20/100], Step [17/56], Loss: 0.2894\n",
      "Epoch [20/100], Step [18/56], Loss: 0.2759\n",
      "Epoch [20/100], Step [19/56], Loss: 0.2173\n",
      "Epoch [20/100], Step [20/56], Loss: 0.4413\n",
      "Epoch [20/100], Step [21/56], Loss: 0.3194\n",
      "Epoch [20/100], Step [22/56], Loss: 0.4174\n",
      "Epoch [20/100], Step [23/56], Loss: 0.3821\n",
      "Epoch [20/100], Step [24/56], Loss: 0.2138\n",
      "Epoch [20/100], Step [25/56], Loss: 0.2104\n",
      "Epoch [20/100], Step [26/56], Loss: 0.3178\n",
      "Epoch [20/100], Step [27/56], Loss: 0.3639\n",
      "Epoch [20/100], Step [28/56], Loss: 0.3416\n",
      "Epoch [20/100], Step [29/56], Loss: 0.3196\n",
      "Epoch [20/100], Step [30/56], Loss: 0.4042\n",
      "Epoch [20/100], Step [31/56], Loss: 0.2728\n",
      "Epoch [20/100], Step [32/56], Loss: 0.1589\n",
      "Epoch [20/100], Step [33/56], Loss: 0.3033\n",
      "Epoch [20/100], Step [34/56], Loss: 0.2538\n",
      "Epoch [20/100], Step [35/56], Loss: 0.2289\n",
      "Epoch [20/100], Step [36/56], Loss: 0.2497\n",
      "Epoch [20/100], Step [37/56], Loss: 0.1921\n",
      "Epoch [20/100], Step [38/56], Loss: 0.3030\n",
      "Epoch [20/100], Step [39/56], Loss: 0.1384\n",
      "Epoch [20/100], Step [40/56], Loss: 0.2466\n",
      "Epoch [20/100], Step [41/56], Loss: 0.2203\n",
      "Epoch [20/100], Step [42/56], Loss: 0.1392\n",
      "Epoch [20/100], Step [43/56], Loss: 0.3040\n",
      "Epoch [20/100], Step [44/56], Loss: 0.2673\n",
      "Epoch [20/100], Step [45/56], Loss: 0.2034\n",
      "Epoch [20/100], Step [46/56], Loss: 0.2277\n",
      "Epoch [20/100], Step [47/56], Loss: 0.1831\n",
      "Epoch [20/100], Step [48/56], Loss: 0.1169\n",
      "Epoch [20/100], Step [49/56], Loss: 0.1735\n",
      "Epoch [20/100], Step [50/56], Loss: 0.2959\n",
      "Epoch [20/100], Step [51/56], Loss: 0.2153\n",
      "Epoch [20/100], Step [52/56], Loss: 0.2325\n",
      "Epoch [20/100], Step [53/56], Loss: 0.2135\n",
      "Epoch [20/100], Step [54/56], Loss: 0.3455\n",
      "Epoch [20/100], Step [55/56], Loss: 0.1444\n",
      "Epoch [20/100], Step [56/56], Loss: 0.2337\n",
      "Val. loss :0.2029\n",
      "Epoch [21/100], Step [1/56], Loss: 0.3009\n",
      "Epoch [21/100], Step [2/56], Loss: 0.1717\n",
      "Epoch [21/100], Step [3/56], Loss: 0.3093\n",
      "Epoch [21/100], Step [4/56], Loss: 0.3221\n",
      "Epoch [21/100], Step [5/56], Loss: 0.2657\n",
      "Epoch [21/100], Step [6/56], Loss: 0.1982\n",
      "Epoch [21/100], Step [7/56], Loss: 0.3430\n",
      "Epoch [21/100], Step [8/56], Loss: 0.1840\n",
      "Epoch [21/100], Step [9/56], Loss: 0.3439\n",
      "Epoch [21/100], Step [10/56], Loss: 0.2040\n",
      "Epoch [21/100], Step [11/56], Loss: 0.1774\n",
      "Epoch [21/100], Step [12/56], Loss: 0.3449\n",
      "Epoch [21/100], Step [13/56], Loss: 0.3093\n",
      "Epoch [21/100], Step [14/56], Loss: 0.2389\n",
      "Epoch [21/100], Step [15/56], Loss: 0.1620\n",
      "Epoch [21/100], Step [16/56], Loss: 0.2047\n",
      "Epoch [21/100], Step [17/56], Loss: 0.2453\n",
      "Epoch [21/100], Step [18/56], Loss: 0.2952\n",
      "Epoch [21/100], Step [19/56], Loss: 0.2089\n",
      "Epoch [21/100], Step [20/56], Loss: 0.2084\n",
      "Epoch [21/100], Step [21/56], Loss: 0.1427\n",
      "Epoch [21/100], Step [22/56], Loss: 0.1896\n",
      "Epoch [21/100], Step [23/56], Loss: 0.2280\n",
      "Epoch [21/100], Step [24/56], Loss: 0.3005\n",
      "Epoch [21/100], Step [25/56], Loss: 0.2004\n",
      "Epoch [21/100], Step [26/56], Loss: 0.5186\n",
      "Epoch [21/100], Step [27/56], Loss: 0.3150\n",
      "Epoch [21/100], Step [28/56], Loss: 0.2538\n",
      "Epoch [21/100], Step [29/56], Loss: 0.2724\n",
      "Epoch [21/100], Step [30/56], Loss: 0.1302\n",
      "Epoch [21/100], Step [31/56], Loss: 0.3722\n",
      "Epoch [21/100], Step [32/56], Loss: 0.4162\n",
      "Epoch [21/100], Step [33/56], Loss: 0.2148\n",
      "Epoch [21/100], Step [34/56], Loss: 0.2949\n",
      "Epoch [21/100], Step [35/56], Loss: 0.3961\n",
      "Epoch [21/100], Step [36/56], Loss: 0.2294\n",
      "Epoch [21/100], Step [37/56], Loss: 0.2378\n",
      "Epoch [21/100], Step [38/56], Loss: 0.2153\n",
      "Epoch [21/100], Step [39/56], Loss: 0.2525\n",
      "Epoch [21/100], Step [40/56], Loss: 0.1971\n",
      "Epoch [21/100], Step [41/56], Loss: 0.2902\n",
      "Epoch [21/100], Step [42/56], Loss: 0.1947\n",
      "Epoch [21/100], Step [43/56], Loss: 0.1299\n",
      "Epoch [21/100], Step [44/56], Loss: 0.3591\n",
      "Epoch [21/100], Step [45/56], Loss: 0.3665\n",
      "Epoch [21/100], Step [46/56], Loss: 0.1439\n",
      "Epoch [21/100], Step [47/56], Loss: 0.2444\n",
      "Epoch [21/100], Step [48/56], Loss: 0.2531\n",
      "Epoch [21/100], Step [49/56], Loss: 0.2035\n",
      "Epoch [21/100], Step [50/56], Loss: 0.3928\n",
      "Epoch [21/100], Step [51/56], Loss: 0.3723\n",
      "Epoch [21/100], Step [52/56], Loss: 0.4024\n",
      "Epoch [21/100], Step [53/56], Loss: 0.2501\n",
      "Epoch [21/100], Step [54/56], Loss: 0.2148\n",
      "Epoch [21/100], Step [55/56], Loss: 0.1307\n",
      "Epoch [21/100], Step [56/56], Loss: 0.0820\n",
      "Val. loss :0.1910\n",
      "Epoch [22/100], Step [1/56], Loss: 0.3454\n",
      "Epoch [22/100], Step [2/56], Loss: 0.1473\n",
      "Epoch [22/100], Step [3/56], Loss: 0.1934\n",
      "Epoch [22/100], Step [4/56], Loss: 0.3189\n",
      "Epoch [22/100], Step [5/56], Loss: 0.2359\n",
      "Epoch [22/100], Step [6/56], Loss: 0.1597\n",
      "Epoch [22/100], Step [7/56], Loss: 0.1409\n",
      "Epoch [22/100], Step [8/56], Loss: 0.2821\n",
      "Epoch [22/100], Step [9/56], Loss: 0.3152\n",
      "Epoch [22/100], Step [10/56], Loss: 0.1971\n",
      "Epoch [22/100], Step [11/56], Loss: 0.2696\n",
      "Epoch [22/100], Step [12/56], Loss: 0.2940\n",
      "Epoch [22/100], Step [13/56], Loss: 0.2651\n",
      "Epoch [22/100], Step [14/56], Loss: 0.2005\n",
      "Epoch [22/100], Step [15/56], Loss: 0.3277\n",
      "Epoch [22/100], Step [16/56], Loss: 0.1568\n",
      "Epoch [22/100], Step [17/56], Loss: 0.1877\n",
      "Epoch [22/100], Step [18/56], Loss: 0.1613\n",
      "Epoch [22/100], Step [19/56], Loss: 0.3530\n",
      "Epoch [22/100], Step [20/56], Loss: 0.2932\n",
      "Epoch [22/100], Step [21/56], Loss: 0.1189\n",
      "Epoch [22/100], Step [22/56], Loss: 0.1973\n",
      "Epoch [22/100], Step [23/56], Loss: 0.4781\n",
      "Epoch [22/100], Step [24/56], Loss: 0.1837\n",
      "Epoch [22/100], Step [25/56], Loss: 0.2712\n",
      "Epoch [22/100], Step [26/56], Loss: 0.1877\n",
      "Epoch [22/100], Step [27/56], Loss: 0.2422\n",
      "Epoch [22/100], Step [28/56], Loss: 0.2550\n",
      "Epoch [22/100], Step [29/56], Loss: 0.5423\n",
      "Epoch [22/100], Step [30/56], Loss: 0.3314\n",
      "Epoch [22/100], Step [31/56], Loss: 0.2976\n",
      "Epoch [22/100], Step [32/56], Loss: 0.2277\n",
      "Epoch [22/100], Step [33/56], Loss: 0.2572\n",
      "Epoch [22/100], Step [34/56], Loss: 0.2100\n",
      "Epoch [22/100], Step [35/56], Loss: 0.1811\n",
      "Epoch [22/100], Step [36/56], Loss: 0.2956\n",
      "Epoch [22/100], Step [37/56], Loss: 0.1793\n",
      "Epoch [22/100], Step [38/56], Loss: 0.2898\n",
      "Epoch [22/100], Step [39/56], Loss: 0.1382\n",
      "Epoch [22/100], Step [40/56], Loss: 0.2723\n",
      "Epoch [22/100], Step [41/56], Loss: 0.3552\n",
      "Epoch [22/100], Step [42/56], Loss: 0.2132\n",
      "Epoch [22/100], Step [43/56], Loss: 0.3345\n",
      "Epoch [22/100], Step [44/56], Loss: 0.3184\n",
      "Epoch [22/100], Step [45/56], Loss: 0.2495\n",
      "Epoch [22/100], Step [46/56], Loss: 0.3672\n",
      "Epoch [22/100], Step [47/56], Loss: 0.4623\n",
      "Epoch [22/100], Step [48/56], Loss: 0.2934\n",
      "Epoch [22/100], Step [49/56], Loss: 0.2216\n",
      "Epoch [22/100], Step [50/56], Loss: 0.2029\n",
      "Epoch [22/100], Step [51/56], Loss: 0.2245\n",
      "Epoch [22/100], Step [52/56], Loss: 0.1874\n",
      "Epoch [22/100], Step [53/56], Loss: 0.2384\n",
      "Epoch [22/100], Step [54/56], Loss: 0.1718\n",
      "Epoch [22/100], Step [55/56], Loss: 0.3422\n",
      "Epoch [22/100], Step [56/56], Loss: 0.1378\n",
      "Val. loss :0.1673\n",
      "Epoch [23/100], Step [1/56], Loss: 0.2091\n",
      "Epoch [23/100], Step [2/56], Loss: 0.2563\n",
      "Epoch [23/100], Step [3/56], Loss: 0.4479\n",
      "Epoch [23/100], Step [4/56], Loss: 0.2233\n",
      "Epoch [23/100], Step [5/56], Loss: 0.3603\n",
      "Epoch [23/100], Step [6/56], Loss: 0.2733\n",
      "Epoch [23/100], Step [7/56], Loss: 0.3729\n",
      "Epoch [23/100], Step [8/56], Loss: 0.1628\n",
      "Epoch [23/100], Step [9/56], Loss: 0.1810\n",
      "Epoch [23/100], Step [10/56], Loss: 0.3142\n",
      "Epoch [23/100], Step [11/56], Loss: 0.2741\n",
      "Epoch [23/100], Step [12/56], Loss: 0.2452\n",
      "Epoch [23/100], Step [13/56], Loss: 0.3578\n",
      "Epoch [23/100], Step [14/56], Loss: 0.2236\n",
      "Epoch [23/100], Step [15/56], Loss: 0.3071\n",
      "Epoch [23/100], Step [16/56], Loss: 0.3940\n",
      "Epoch [23/100], Step [17/56], Loss: 0.1687\n",
      "Epoch [23/100], Step [18/56], Loss: 0.2773\n",
      "Epoch [23/100], Step [19/56], Loss: 0.1538\n",
      "Epoch [23/100], Step [20/56], Loss: 0.1180\n",
      "Epoch [23/100], Step [21/56], Loss: 0.2098\n",
      "Epoch [23/100], Step [22/56], Loss: 0.2099\n",
      "Epoch [23/100], Step [23/56], Loss: 0.1169\n",
      "Epoch [23/100], Step [24/56], Loss: 0.1832\n",
      "Epoch [23/100], Step [25/56], Loss: 0.2225\n",
      "Epoch [23/100], Step [26/56], Loss: 0.4875\n",
      "Epoch [23/100], Step [27/56], Loss: 0.3017\n",
      "Epoch [23/100], Step [28/56], Loss: 0.1802\n",
      "Epoch [23/100], Step [29/56], Loss: 0.1880\n",
      "Epoch [23/100], Step [30/56], Loss: 0.1056\n",
      "Epoch [23/100], Step [31/56], Loss: 0.3352\n",
      "Epoch [23/100], Step [32/56], Loss: 0.1607\n",
      "Epoch [23/100], Step [33/56], Loss: 0.2058\n",
      "Epoch [23/100], Step [34/56], Loss: 0.4099\n",
      "Epoch [23/100], Step [35/56], Loss: 0.2049\n",
      "Epoch [23/100], Step [36/56], Loss: 0.2638\n",
      "Epoch [23/100], Step [37/56], Loss: 0.4097\n",
      "Epoch [23/100], Step [38/56], Loss: 0.2203\n",
      "Epoch [23/100], Step [39/56], Loss: 0.1991\n",
      "Epoch [23/100], Step [40/56], Loss: 0.1505\n",
      "Epoch [23/100], Step [41/56], Loss: 0.2615\n",
      "Epoch [23/100], Step [42/56], Loss: 0.2636\n",
      "Epoch [23/100], Step [43/56], Loss: 0.3630\n",
      "Epoch [23/100], Step [44/56], Loss: 0.1543\n",
      "Epoch [23/100], Step [45/56], Loss: 0.2532\n",
      "Epoch [23/100], Step [46/56], Loss: 0.4425\n",
      "Epoch [23/100], Step [47/56], Loss: 0.2783\n",
      "Epoch [23/100], Step [48/56], Loss: 0.2693\n",
      "Epoch [23/100], Step [49/56], Loss: 0.3519\n",
      "Epoch [23/100], Step [50/56], Loss: 0.2535\n",
      "Epoch [23/100], Step [51/56], Loss: 0.3552\n",
      "Epoch [23/100], Step [52/56], Loss: 0.1795\n",
      "Epoch [23/100], Step [53/56], Loss: 0.4331\n",
      "Epoch [23/100], Step [54/56], Loss: 0.2309\n",
      "Epoch [23/100], Step [55/56], Loss: 0.2830\n",
      "Epoch [23/100], Step [56/56], Loss: 0.0641\n",
      "Val. loss :0.2358\n",
      "Epoch [24/100], Step [1/56], Loss: 0.2260\n",
      "Epoch [24/100], Step [2/56], Loss: 0.2258\n",
      "Epoch [24/100], Step [3/56], Loss: 0.3454\n",
      "Epoch [24/100], Step [4/56], Loss: 0.2092\n",
      "Epoch [24/100], Step [5/56], Loss: 0.4564\n",
      "Epoch [24/100], Step [6/56], Loss: 0.2428\n",
      "Epoch [24/100], Step [7/56], Loss: 0.2580\n",
      "Epoch [24/100], Step [8/56], Loss: 0.3052\n",
      "Epoch [24/100], Step [9/56], Loss: 0.2553\n",
      "Epoch [24/100], Step [10/56], Loss: 0.2804\n",
      "Epoch [24/100], Step [11/56], Loss: 0.2640\n",
      "Epoch [24/100], Step [12/56], Loss: 0.2123\n",
      "Epoch [24/100], Step [13/56], Loss: 0.2271\n",
      "Epoch [24/100], Step [14/56], Loss: 0.3117\n",
      "Epoch [24/100], Step [15/56], Loss: 0.3155\n",
      "Epoch [24/100], Step [16/56], Loss: 0.3547\n",
      "Epoch [24/100], Step [17/56], Loss: 0.3809\n",
      "Epoch [24/100], Step [18/56], Loss: 0.1837\n",
      "Epoch [24/100], Step [19/56], Loss: 0.3826\n",
      "Epoch [24/100], Step [20/56], Loss: 0.1900\n",
      "Epoch [24/100], Step [21/56], Loss: 0.1964\n",
      "Epoch [24/100], Step [22/56], Loss: 0.1734\n",
      "Epoch [24/100], Step [23/56], Loss: 0.1428\n",
      "Epoch [24/100], Step [24/56], Loss: 0.3633\n",
      "Epoch [24/100], Step [25/56], Loss: 0.1442\n",
      "Epoch [24/100], Step [26/56], Loss: 0.1730\n",
      "Epoch [24/100], Step [27/56], Loss: 0.1757\n",
      "Epoch [24/100], Step [28/56], Loss: 0.2134\n",
      "Epoch [24/100], Step [29/56], Loss: 0.3380\n",
      "Epoch [24/100], Step [30/56], Loss: 0.2655\n",
      "Epoch [24/100], Step [31/56], Loss: 0.2561\n",
      "Epoch [24/100], Step [32/56], Loss: 0.1852\n",
      "Epoch [24/100], Step [33/56], Loss: 0.2859\n",
      "Epoch [24/100], Step [34/56], Loss: 0.1568\n",
      "Epoch [24/100], Step [35/56], Loss: 0.1533\n",
      "Epoch [24/100], Step [36/56], Loss: 0.1953\n",
      "Epoch [24/100], Step [37/56], Loss: 0.2088\n",
      "Epoch [24/100], Step [38/56], Loss: 0.1621\n",
      "Epoch [24/100], Step [39/56], Loss: 0.2195\n",
      "Epoch [24/100], Step [40/56], Loss: 0.1229\n",
      "Epoch [24/100], Step [41/56], Loss: 0.3203\n",
      "Epoch [24/100], Step [42/56], Loss: 0.2393\n",
      "Epoch [24/100], Step [43/56], Loss: 0.2770\n",
      "Epoch [24/100], Step [44/56], Loss: 0.1182\n",
      "Epoch [24/100], Step [45/56], Loss: 0.2389\n",
      "Epoch [24/100], Step [46/56], Loss: 0.1284\n",
      "Epoch [24/100], Step [47/56], Loss: 0.1743\n",
      "Epoch [24/100], Step [48/56], Loss: 0.3048\n",
      "Epoch [24/100], Step [49/56], Loss: 0.1709\n",
      "Epoch [24/100], Step [50/56], Loss: 0.2140\n",
      "Epoch [24/100], Step [51/56], Loss: 0.2441\n",
      "Epoch [24/100], Step [52/56], Loss: 0.2136\n",
      "Epoch [24/100], Step [53/56], Loss: 0.2621\n",
      "Epoch [24/100], Step [54/56], Loss: 0.3413\n",
      "Epoch [24/100], Step [55/56], Loss: 0.1956\n",
      "Epoch [24/100], Step [56/56], Loss: 0.1067\n",
      "Val. loss :0.1581\n",
      "Epoch [25/100], Step [1/56], Loss: 0.1767\n",
      "Epoch [25/100], Step [2/56], Loss: 0.2617\n",
      "Epoch [25/100], Step [3/56], Loss: 0.3016\n",
      "Epoch [25/100], Step [4/56], Loss: 0.1629\n",
      "Epoch [25/100], Step [5/56], Loss: 0.2777\n",
      "Epoch [25/100], Step [6/56], Loss: 0.2952\n",
      "Epoch [25/100], Step [7/56], Loss: 0.1780\n",
      "Epoch [25/100], Step [8/56], Loss: 0.1630\n",
      "Epoch [25/100], Step [9/56], Loss: 0.2095\n",
      "Epoch [25/100], Step [10/56], Loss: 0.4218\n",
      "Epoch [25/100], Step [11/56], Loss: 0.1620\n",
      "Epoch [25/100], Step [12/56], Loss: 0.2019\n",
      "Epoch [25/100], Step [13/56], Loss: 0.3496\n",
      "Epoch [25/100], Step [14/56], Loss: 0.2415\n",
      "Epoch [25/100], Step [15/56], Loss: 0.1814\n",
      "Epoch [25/100], Step [16/56], Loss: 0.2547\n",
      "Epoch [25/100], Step [17/56], Loss: 0.1823\n",
      "Epoch [25/100], Step [18/56], Loss: 0.4051\n",
      "Epoch [25/100], Step [19/56], Loss: 0.2148\n",
      "Epoch [25/100], Step [20/56], Loss: 0.2067\n",
      "Epoch [25/100], Step [21/56], Loss: 0.3199\n",
      "Epoch [25/100], Step [22/56], Loss: 0.1259\n",
      "Epoch [25/100], Step [23/56], Loss: 0.1560\n",
      "Epoch [25/100], Step [24/56], Loss: 0.3093\n",
      "Epoch [25/100], Step [25/56], Loss: 0.1008\n",
      "Epoch [25/100], Step [26/56], Loss: 0.1309\n",
      "Epoch [25/100], Step [27/56], Loss: 0.2540\n",
      "Epoch [25/100], Step [28/56], Loss: 0.2538\n",
      "Epoch [25/100], Step [29/56], Loss: 0.4403\n",
      "Epoch [25/100], Step [30/56], Loss: 0.2620\n",
      "Epoch [25/100], Step [31/56], Loss: 0.1099\n",
      "Epoch [25/100], Step [32/56], Loss: 0.2434\n",
      "Epoch [25/100], Step [33/56], Loss: 0.3397\n",
      "Epoch [25/100], Step [34/56], Loss: 0.2448\n",
      "Epoch [25/100], Step [35/56], Loss: 0.1522\n",
      "Epoch [25/100], Step [36/56], Loss: 0.2914\n",
      "Epoch [25/100], Step [37/56], Loss: 0.1627\n",
      "Epoch [25/100], Step [38/56], Loss: 0.2434\n",
      "Epoch [25/100], Step [39/56], Loss: 0.2335\n",
      "Epoch [25/100], Step [40/56], Loss: 0.4086\n",
      "Epoch [25/100], Step [41/56], Loss: 0.4761\n",
      "Epoch [25/100], Step [42/56], Loss: 0.2000\n",
      "Epoch [25/100], Step [43/56], Loss: 0.1784\n",
      "Epoch [25/100], Step [44/56], Loss: 0.1310\n",
      "Epoch [25/100], Step [45/56], Loss: 0.2114\n",
      "Epoch [25/100], Step [46/56], Loss: 0.2501\n",
      "Epoch [25/100], Step [47/56], Loss: 0.1517\n",
      "Epoch [25/100], Step [48/56], Loss: 0.3388\n",
      "Epoch [25/100], Step [49/56], Loss: 0.3776\n",
      "Epoch [25/100], Step [50/56], Loss: 0.4778\n",
      "Epoch [25/100], Step [51/56], Loss: 0.2851\n",
      "Epoch [25/100], Step [52/56], Loss: 0.1501\n",
      "Epoch [25/100], Step [53/56], Loss: 0.1444\n",
      "Epoch [25/100], Step [54/56], Loss: 0.2502\n",
      "Epoch [25/100], Step [55/56], Loss: 0.1874\n",
      "Epoch [25/100], Step [56/56], Loss: 0.1324\n",
      "Val. loss :0.1939\n",
      "Epoch [26/100], Step [1/56], Loss: 0.2842\n",
      "Epoch [26/100], Step [2/56], Loss: 0.3760\n",
      "Epoch [26/100], Step [3/56], Loss: 0.2141\n",
      "Epoch [26/100], Step [4/56], Loss: 0.1479\n",
      "Epoch [26/100], Step [5/56], Loss: 0.2730\n",
      "Epoch [26/100], Step [6/56], Loss: 0.2430\n",
      "Epoch [26/100], Step [7/56], Loss: 0.1687\n",
      "Epoch [26/100], Step [8/56], Loss: 0.2240\n",
      "Epoch [26/100], Step [9/56], Loss: 0.1902\n",
      "Epoch [26/100], Step [10/56], Loss: 0.2806\n",
      "Epoch [26/100], Step [11/56], Loss: 0.1670\n",
      "Epoch [26/100], Step [12/56], Loss: 0.2450\n",
      "Epoch [26/100], Step [13/56], Loss: 0.1730\n",
      "Epoch [26/100], Step [14/56], Loss: 0.2493\n",
      "Epoch [26/100], Step [15/56], Loss: 0.1787\n",
      "Epoch [26/100], Step [16/56], Loss: 0.2977\n",
      "Epoch [26/100], Step [17/56], Loss: 0.2974\n",
      "Epoch [26/100], Step [18/56], Loss: 0.1529\n",
      "Epoch [26/100], Step [19/56], Loss: 0.1911\n",
      "Epoch [26/100], Step [20/56], Loss: 0.1846\n",
      "Epoch [26/100], Step [21/56], Loss: 0.1603\n",
      "Epoch [26/100], Step [22/56], Loss: 0.1284\n",
      "Epoch [26/100], Step [23/56], Loss: 0.1093\n",
      "Epoch [26/100], Step [24/56], Loss: 0.3909\n",
      "Epoch [26/100], Step [25/56], Loss: 0.2266\n",
      "Epoch [26/100], Step [26/56], Loss: 0.2585\n",
      "Epoch [26/100], Step [27/56], Loss: 0.1556\n",
      "Epoch [26/100], Step [28/56], Loss: 0.2177\n",
      "Epoch [26/100], Step [29/56], Loss: 0.1582\n",
      "Epoch [26/100], Step [30/56], Loss: 0.2136\n",
      "Epoch [26/100], Step [31/56], Loss: 0.2710\n",
      "Epoch [26/100], Step [32/56], Loss: 0.1043\n",
      "Epoch [26/100], Step [33/56], Loss: 0.1566\n",
      "Epoch [26/100], Step [34/56], Loss: 0.1569\n",
      "Epoch [26/100], Step [35/56], Loss: 0.1536\n",
      "Epoch [26/100], Step [36/56], Loss: 0.3947\n",
      "Epoch [26/100], Step [37/56], Loss: 0.1900\n",
      "Epoch [26/100], Step [38/56], Loss: 0.2827\n",
      "Epoch [26/100], Step [39/56], Loss: 0.1371\n",
      "Epoch [26/100], Step [40/56], Loss: 0.1579\n",
      "Epoch [26/100], Step [41/56], Loss: 0.2594\n",
      "Epoch [26/100], Step [42/56], Loss: 0.2614\n",
      "Epoch [26/100], Step [43/56], Loss: 0.2071\n",
      "Epoch [26/100], Step [44/56], Loss: 0.2962\n",
      "Epoch [26/100], Step [45/56], Loss: 0.3667\n",
      "Epoch [26/100], Step [46/56], Loss: 0.1684\n",
      "Epoch [26/100], Step [47/56], Loss: 0.2118\n",
      "Epoch [26/100], Step [48/56], Loss: 0.2596\n",
      "Epoch [26/100], Step [49/56], Loss: 0.1365\n",
      "Epoch [26/100], Step [50/56], Loss: 0.3029\n",
      "Epoch [26/100], Step [51/56], Loss: 0.1340\n",
      "Epoch [26/100], Step [52/56], Loss: 0.1716\n",
      "Epoch [26/100], Step [53/56], Loss: 0.3209\n",
      "Epoch [26/100], Step [54/56], Loss: 0.2330\n",
      "Epoch [26/100], Step [55/56], Loss: 0.1786\n",
      "Epoch [26/100], Step [56/56], Loss: 0.1053\n",
      "Val. loss :0.1316\n",
      "Epoch [27/100], Step [1/56], Loss: 0.2243\n",
      "Epoch [27/100], Step [2/56], Loss: 0.1196\n",
      "Epoch [27/100], Step [3/56], Loss: 0.1852\n",
      "Epoch [27/100], Step [4/56], Loss: 0.1961\n",
      "Epoch [27/100], Step [5/56], Loss: 0.2583\n",
      "Epoch [27/100], Step [6/56], Loss: 0.1335\n",
      "Epoch [27/100], Step [7/56], Loss: 0.1829\n",
      "Epoch [27/100], Step [8/56], Loss: 0.3446\n",
      "Epoch [27/100], Step [9/56], Loss: 0.0973\n",
      "Epoch [27/100], Step [10/56], Loss: 0.2889\n",
      "Epoch [27/100], Step [11/56], Loss: 0.1930\n",
      "Epoch [27/100], Step [12/56], Loss: 0.1393\n",
      "Epoch [27/100], Step [13/56], Loss: 0.1598\n",
      "Epoch [27/100], Step [14/56], Loss: 0.1395\n",
      "Epoch [27/100], Step [15/56], Loss: 0.1310\n",
      "Epoch [27/100], Step [16/56], Loss: 0.3443\n",
      "Epoch [27/100], Step [17/56], Loss: 0.1703\n",
      "Epoch [27/100], Step [18/56], Loss: 0.2306\n",
      "Epoch [27/100], Step [19/56], Loss: 0.3781\n",
      "Epoch [27/100], Step [20/56], Loss: 0.2058\n",
      "Epoch [27/100], Step [21/56], Loss: 0.1293\n",
      "Epoch [27/100], Step [22/56], Loss: 0.1590\n",
      "Epoch [27/100], Step [23/56], Loss: 0.1824\n",
      "Epoch [27/100], Step [24/56], Loss: 0.1858\n",
      "Epoch [27/100], Step [25/56], Loss: 0.4151\n",
      "Epoch [27/100], Step [26/56], Loss: 0.1438\n",
      "Epoch [27/100], Step [27/56], Loss: 0.2387\n",
      "Epoch [27/100], Step [28/56], Loss: 0.1684\n",
      "Epoch [27/100], Step [29/56], Loss: 0.1855\n",
      "Epoch [27/100], Step [30/56], Loss: 0.1751\n",
      "Epoch [27/100], Step [31/56], Loss: 0.2126\n",
      "Epoch [27/100], Step [32/56], Loss: 0.2748\n",
      "Epoch [27/100], Step [33/56], Loss: 0.2101\n",
      "Epoch [27/100], Step [34/56], Loss: 0.1692\n",
      "Epoch [27/100], Step [35/56], Loss: 0.2070\n",
      "Epoch [27/100], Step [36/56], Loss: 0.2408\n",
      "Epoch [27/100], Step [37/56], Loss: 0.1329\n",
      "Epoch [27/100], Step [38/56], Loss: 0.1608\n",
      "Epoch [27/100], Step [39/56], Loss: 0.0858\n",
      "Epoch [27/100], Step [40/56], Loss: 0.1054\n",
      "Epoch [27/100], Step [41/56], Loss: 0.1452\n",
      "Epoch [27/100], Step [42/56], Loss: 0.1107\n",
      "Epoch [27/100], Step [43/56], Loss: 0.1473\n",
      "Epoch [27/100], Step [44/56], Loss: 0.2656\n",
      "Epoch [27/100], Step [45/56], Loss: 0.3954\n",
      "Epoch [27/100], Step [46/56], Loss: 0.1856\n",
      "Epoch [27/100], Step [47/56], Loss: 0.1988\n",
      "Epoch [27/100], Step [48/56], Loss: 0.1994\n",
      "Epoch [27/100], Step [49/56], Loss: 0.0885\n",
      "Epoch [27/100], Step [50/56], Loss: 0.2085\n",
      "Epoch [27/100], Step [51/56], Loss: 0.1213\n",
      "Epoch [27/100], Step [52/56], Loss: 0.1846\n",
      "Epoch [27/100], Step [53/56], Loss: 0.2783\n",
      "Epoch [27/100], Step [54/56], Loss: 0.4247\n",
      "Epoch [27/100], Step [55/56], Loss: 0.1400\n",
      "Epoch [27/100], Step [56/56], Loss: 0.0667\n",
      "Val. loss :0.1574\n",
      "Epoch [28/100], Step [1/56], Loss: 0.1660\n",
      "Epoch [28/100], Step [2/56], Loss: 0.1828\n",
      "Epoch [28/100], Step [3/56], Loss: 0.1537\n",
      "Epoch [28/100], Step [4/56], Loss: 0.2177\n",
      "Epoch [28/100], Step [5/56], Loss: 0.1968\n",
      "Epoch [28/100], Step [6/56], Loss: 0.3143\n",
      "Epoch [28/100], Step [7/56], Loss: 0.3366\n",
      "Epoch [28/100], Step [8/56], Loss: 0.2017\n",
      "Epoch [28/100], Step [9/56], Loss: 0.1122\n",
      "Epoch [28/100], Step [10/56], Loss: 0.1668\n",
      "Epoch [28/100], Step [11/56], Loss: 0.2292\n",
      "Epoch [28/100], Step [12/56], Loss: 0.1699\n",
      "Epoch [28/100], Step [13/56], Loss: 0.2810\n",
      "Epoch [28/100], Step [14/56], Loss: 0.5034\n",
      "Epoch [28/100], Step [15/56], Loss: 0.2405\n",
      "Epoch [28/100], Step [16/56], Loss: 0.2935\n",
      "Epoch [28/100], Step [17/56], Loss: 0.2789\n",
      "Epoch [28/100], Step [18/56], Loss: 0.3592\n",
      "Epoch [28/100], Step [19/56], Loss: 0.1664\n",
      "Epoch [28/100], Step [20/56], Loss: 0.1665\n",
      "Epoch [28/100], Step [21/56], Loss: 0.1372\n",
      "Epoch [28/100], Step [22/56], Loss: 0.2406\n",
      "Epoch [28/100], Step [23/56], Loss: 0.5327\n",
      "Epoch [28/100], Step [24/56], Loss: 0.1524\n",
      "Epoch [28/100], Step [25/56], Loss: 0.1637\n",
      "Epoch [28/100], Step [26/56], Loss: 0.1980\n",
      "Epoch [28/100], Step [27/56], Loss: 0.2571\n",
      "Epoch [28/100], Step [28/56], Loss: 0.1845\n",
      "Epoch [28/100], Step [29/56], Loss: 0.3032\n",
      "Epoch [28/100], Step [30/56], Loss: 0.1762\n",
      "Epoch [28/100], Step [31/56], Loss: 0.2199\n",
      "Epoch [28/100], Step [32/56], Loss: 0.1611\n",
      "Epoch [28/100], Step [33/56], Loss: 0.2000\n",
      "Epoch [28/100], Step [34/56], Loss: 0.1728\n",
      "Epoch [28/100], Step [35/56], Loss: 0.2142\n",
      "Epoch [28/100], Step [36/56], Loss: 0.4271\n",
      "Epoch [28/100], Step [37/56], Loss: 0.1079\n",
      "Epoch [28/100], Step [38/56], Loss: 0.2398\n",
      "Epoch [28/100], Step [39/56], Loss: 0.2925\n",
      "Epoch [28/100], Step [40/56], Loss: 0.2483\n",
      "Epoch [28/100], Step [41/56], Loss: 0.1664\n",
      "Epoch [28/100], Step [42/56], Loss: 0.2473\n",
      "Epoch [28/100], Step [43/56], Loss: 0.1493\n",
      "Epoch [28/100], Step [44/56], Loss: 0.2083\n",
      "Epoch [28/100], Step [45/56], Loss: 0.1442\n",
      "Epoch [28/100], Step [46/56], Loss: 0.1792\n",
      "Epoch [28/100], Step [47/56], Loss: 0.2180\n",
      "Epoch [28/100], Step [48/56], Loss: 0.1789\n",
      "Epoch [28/100], Step [49/56], Loss: 0.1551\n",
      "Epoch [28/100], Step [50/56], Loss: 0.2045\n",
      "Epoch [28/100], Step [51/56], Loss: 0.1872\n",
      "Epoch [28/100], Step [52/56], Loss: 0.2131\n",
      "Epoch [28/100], Step [53/56], Loss: 0.2803\n",
      "Epoch [28/100], Step [54/56], Loss: 0.1566\n",
      "Epoch [28/100], Step [55/56], Loss: 0.3323\n",
      "Epoch [28/100], Step [56/56], Loss: 0.1150\n",
      "Val. loss :0.1602\n",
      "Epoch [29/100], Step [1/56], Loss: 0.1717\n",
      "Epoch [29/100], Step [2/56], Loss: 0.1487\n",
      "Epoch [29/100], Step [3/56], Loss: 0.1403\n",
      "Epoch [29/100], Step [4/56], Loss: 0.1894\n",
      "Epoch [29/100], Step [5/56], Loss: 0.1712\n",
      "Epoch [29/100], Step [6/56], Loss: 0.1144\n",
      "Epoch [29/100], Step [7/56], Loss: 0.2110\n",
      "Epoch [29/100], Step [8/56], Loss: 0.2894\n",
      "Epoch [29/100], Step [9/56], Loss: 0.1655\n",
      "Epoch [29/100], Step [10/56], Loss: 0.2812\n",
      "Epoch [29/100], Step [11/56], Loss: 0.1807\n",
      "Epoch [29/100], Step [12/56], Loss: 0.3271\n",
      "Epoch [29/100], Step [13/56], Loss: 0.2201\n",
      "Epoch [29/100], Step [14/56], Loss: 0.2406\n",
      "Epoch [29/100], Step [15/56], Loss: 0.2102\n",
      "Epoch [29/100], Step [16/56], Loss: 0.1170\n",
      "Epoch [29/100], Step [17/56], Loss: 0.1943\n",
      "Epoch [29/100], Step [18/56], Loss: 0.2123\n",
      "Epoch [29/100], Step [19/56], Loss: 0.1925\n",
      "Epoch [29/100], Step [20/56], Loss: 0.2296\n",
      "Epoch [29/100], Step [21/56], Loss: 0.2106\n",
      "Epoch [29/100], Step [22/56], Loss: 0.1300\n",
      "Epoch [29/100], Step [23/56], Loss: 0.1298\n",
      "Epoch [29/100], Step [24/56], Loss: 0.1493\n",
      "Epoch [29/100], Step [25/56], Loss: 0.3543\n",
      "Epoch [29/100], Step [26/56], Loss: 0.1576\n",
      "Epoch [29/100], Step [27/56], Loss: 0.3128\n",
      "Epoch [29/100], Step [28/56], Loss: 0.1596\n",
      "Epoch [29/100], Step [29/56], Loss: 0.2874\n",
      "Epoch [29/100], Step [30/56], Loss: 0.2309\n",
      "Epoch [29/100], Step [31/56], Loss: 0.2122\n",
      "Epoch [29/100], Step [32/56], Loss: 0.1888\n",
      "Epoch [29/100], Step [33/56], Loss: 0.2273\n",
      "Epoch [29/100], Step [34/56], Loss: 0.2008\n",
      "Epoch [29/100], Step [35/56], Loss: 0.1409\n",
      "Epoch [29/100], Step [36/56], Loss: 0.1787\n",
      "Epoch [29/100], Step [37/56], Loss: 0.1396\n",
      "Epoch [29/100], Step [38/56], Loss: 0.1869\n",
      "Epoch [29/100], Step [39/56], Loss: 0.1301\n",
      "Epoch [29/100], Step [40/56], Loss: 0.1671\n",
      "Epoch [29/100], Step [41/56], Loss: 0.2814\n",
      "Epoch [29/100], Step [42/56], Loss: 0.1808\n",
      "Epoch [29/100], Step [43/56], Loss: 0.1668\n",
      "Epoch [29/100], Step [44/56], Loss: 0.1568\n",
      "Epoch [29/100], Step [45/56], Loss: 0.1921\n",
      "Epoch [29/100], Step [46/56], Loss: 0.2612\n",
      "Epoch [29/100], Step [47/56], Loss: 0.3007\n",
      "Epoch [29/100], Step [48/56], Loss: 0.3009\n",
      "Epoch [29/100], Step [49/56], Loss: 0.1329\n",
      "Epoch [29/100], Step [50/56], Loss: 0.1612\n",
      "Epoch [29/100], Step [51/56], Loss: 0.1666\n",
      "Epoch [29/100], Step [52/56], Loss: 0.1532\n",
      "Epoch [29/100], Step [53/56], Loss: 0.1244\n",
      "Epoch [29/100], Step [54/56], Loss: 0.2119\n",
      "Epoch [29/100], Step [55/56], Loss: 0.1808\n",
      "Epoch [29/100], Step [56/56], Loss: 0.1058\n",
      "Val. loss :0.1505\n",
      "Epoch [30/100], Step [1/56], Loss: 0.2214\n",
      "Epoch [30/100], Step [2/56], Loss: 0.1240\n",
      "Epoch [30/100], Step [3/56], Loss: 0.3207\n",
      "Epoch [30/100], Step [4/56], Loss: 0.1006\n",
      "Epoch [30/100], Step [5/56], Loss: 0.2254\n",
      "Epoch [30/100], Step [6/56], Loss: 0.2245\n",
      "Epoch [30/100], Step [7/56], Loss: 0.1843\n",
      "Epoch [30/100], Step [8/56], Loss: 0.1303\n",
      "Epoch [30/100], Step [9/56], Loss: 0.3106\n",
      "Epoch [30/100], Step [10/56], Loss: 0.1406\n",
      "Epoch [30/100], Step [11/56], Loss: 0.3580\n",
      "Epoch [30/100], Step [12/56], Loss: 0.2683\n",
      "Epoch [30/100], Step [13/56], Loss: 0.2052\n",
      "Epoch [30/100], Step [14/56], Loss: 0.1254\n",
      "Epoch [30/100], Step [15/56], Loss: 0.3437\n",
      "Epoch [30/100], Step [16/56], Loss: 0.2596\n",
      "Epoch [30/100], Step [17/56], Loss: 0.2177\n",
      "Epoch [30/100], Step [18/56], Loss: 0.1282\n",
      "Epoch [30/100], Step [19/56], Loss: 0.2201\n",
      "Epoch [30/100], Step [20/56], Loss: 0.1789\n",
      "Epoch [30/100], Step [21/56], Loss: 0.1344\n",
      "Epoch [30/100], Step [22/56], Loss: 0.1110\n",
      "Epoch [30/100], Step [23/56], Loss: 0.1571\n",
      "Epoch [30/100], Step [24/56], Loss: 0.1085\n",
      "Epoch [30/100], Step [25/56], Loss: 0.1726\n",
      "Epoch [30/100], Step [26/56], Loss: 0.0931\n",
      "Epoch [30/100], Step [27/56], Loss: 0.1989\n",
      "Epoch [30/100], Step [28/56], Loss: 0.1450\n",
      "Epoch [30/100], Step [29/56], Loss: 0.1205\n",
      "Epoch [30/100], Step [30/56], Loss: 0.3186\n",
      "Epoch [30/100], Step [31/56], Loss: 0.1624\n",
      "Epoch [30/100], Step [32/56], Loss: 0.1380\n",
      "Epoch [30/100], Step [33/56], Loss: 0.1402\n",
      "Epoch [30/100], Step [34/56], Loss: 0.1654\n",
      "Epoch [30/100], Step [35/56], Loss: 0.2074\n",
      "Epoch [30/100], Step [36/56], Loss: 0.2040\n",
      "Epoch [30/100], Step [37/56], Loss: 0.1460\n",
      "Epoch [30/100], Step [38/56], Loss: 0.2689\n",
      "Epoch [30/100], Step [39/56], Loss: 0.0946\n",
      "Epoch [30/100], Step [40/56], Loss: 0.1893\n",
      "Epoch [30/100], Step [41/56], Loss: 0.1401\n",
      "Epoch [30/100], Step [42/56], Loss: 0.2312\n",
      "Epoch [30/100], Step [43/56], Loss: 0.1159\n",
      "Epoch [30/100], Step [44/56], Loss: 0.1527\n",
      "Epoch [30/100], Step [45/56], Loss: 0.1603\n",
      "Epoch [30/100], Step [46/56], Loss: 0.1228\n",
      "Epoch [30/100], Step [47/56], Loss: 0.0934\n",
      "Epoch [30/100], Step [48/56], Loss: 0.1094\n",
      "Epoch [30/100], Step [49/56], Loss: 0.1386\n",
      "Epoch [30/100], Step [50/56], Loss: 0.3039\n",
      "Epoch [30/100], Step [51/56], Loss: 0.2591\n",
      "Epoch [30/100], Step [52/56], Loss: 0.1130\n",
      "Epoch [30/100], Step [53/56], Loss: 0.0881\n",
      "Epoch [30/100], Step [54/56], Loss: 0.2141\n",
      "Epoch [30/100], Step [55/56], Loss: 0.1180\n",
      "Epoch [30/100], Step [56/56], Loss: 0.0579\n",
      "Val. loss :0.1380\n",
      "Epoch [31/100], Step [1/56], Loss: 0.2070\n",
      "Epoch [31/100], Step [2/56], Loss: 0.1403\n",
      "Epoch [31/100], Step [3/56], Loss: 0.1191\n",
      "Epoch [31/100], Step [4/56], Loss: 0.1322\n",
      "Epoch [31/100], Step [5/56], Loss: 0.1689\n",
      "Epoch [31/100], Step [6/56], Loss: 0.1207\n",
      "Epoch [31/100], Step [7/56], Loss: 0.1456\n",
      "Epoch [31/100], Step [8/56], Loss: 0.1661\n",
      "Epoch [31/100], Step [9/56], Loss: 0.3738\n",
      "Epoch [31/100], Step [10/56], Loss: 0.1234\n",
      "Epoch [31/100], Step [11/56], Loss: 0.1108\n",
      "Epoch [31/100], Step [12/56], Loss: 0.1201\n",
      "Epoch [31/100], Step [13/56], Loss: 0.1009\n",
      "Epoch [31/100], Step [14/56], Loss: 0.1317\n",
      "Epoch [31/100], Step [15/56], Loss: 0.2197\n",
      "Epoch [31/100], Step [16/56], Loss: 0.1507\n",
      "Epoch [31/100], Step [17/56], Loss: 0.1198\n",
      "Epoch [31/100], Step [18/56], Loss: 0.1323\n",
      "Epoch [31/100], Step [19/56], Loss: 0.1931\n",
      "Epoch [31/100], Step [20/56], Loss: 0.1152\n",
      "Epoch [31/100], Step [21/56], Loss: 0.2133\n",
      "Epoch [31/100], Step [22/56], Loss: 0.1090\n",
      "Epoch [31/100], Step [23/56], Loss: 0.4580\n",
      "Epoch [31/100], Step [24/56], Loss: 0.1755\n",
      "Epoch [31/100], Step [25/56], Loss: 0.1516\n",
      "Epoch [31/100], Step [26/56], Loss: 0.1554\n",
      "Epoch [31/100], Step [27/56], Loss: 0.3497\n",
      "Epoch [31/100], Step [28/56], Loss: 0.1617\n",
      "Epoch [31/100], Step [29/56], Loss: 0.1316\n",
      "Epoch [31/100], Step [30/56], Loss: 0.2126\n",
      "Epoch [31/100], Step [31/56], Loss: 0.1116\n",
      "Epoch [31/100], Step [32/56], Loss: 0.1931\n",
      "Epoch [31/100], Step [33/56], Loss: 0.1479\n",
      "Epoch [31/100], Step [34/56], Loss: 0.1412\n",
      "Epoch [31/100], Step [35/56], Loss: 0.2224\n",
      "Epoch [31/100], Step [36/56], Loss: 0.0848\n",
      "Epoch [31/100], Step [37/56], Loss: 0.1612\n",
      "Epoch [31/100], Step [38/56], Loss: 0.3619\n",
      "Epoch [31/100], Step [39/56], Loss: 0.0791\n",
      "Epoch [31/100], Step [40/56], Loss: 0.2386\n",
      "Epoch [31/100], Step [41/56], Loss: 0.2333\n",
      "Epoch [31/100], Step [42/56], Loss: 0.1563\n",
      "Epoch [31/100], Step [43/56], Loss: 0.2240\n",
      "Epoch [31/100], Step [44/56], Loss: 0.1536\n",
      "Epoch [31/100], Step [45/56], Loss: 0.1307\n",
      "Epoch [31/100], Step [46/56], Loss: 0.3119\n",
      "Epoch [31/100], Step [47/56], Loss: 0.5321\n",
      "Epoch [31/100], Step [48/56], Loss: 0.2504\n",
      "Epoch [31/100], Step [49/56], Loss: 0.1528\n",
      "Epoch [31/100], Step [50/56], Loss: 0.2567\n",
      "Epoch [31/100], Step [51/56], Loss: 0.1598\n",
      "Epoch [31/100], Step [52/56], Loss: 0.0796\n",
      "Epoch [31/100], Step [53/56], Loss: 0.1557\n",
      "Epoch [31/100], Step [54/56], Loss: 0.1073\n",
      "Epoch [31/100], Step [55/56], Loss: 0.3472\n",
      "Epoch [31/100], Step [56/56], Loss: 0.0518\n",
      "Val. loss :0.1628\n",
      "Epoch [32/100], Step [1/56], Loss: 0.2253\n",
      "Epoch [32/100], Step [2/56], Loss: 0.1371\n",
      "Epoch [32/100], Step [3/56], Loss: 0.2279\n",
      "Epoch [32/100], Step [4/56], Loss: 0.3711\n",
      "Epoch [32/100], Step [5/56], Loss: 0.1738\n",
      "Epoch [32/100], Step [6/56], Loss: 0.1575\n",
      "Epoch [32/100], Step [7/56], Loss: 0.1041\n",
      "Epoch [32/100], Step [8/56], Loss: 0.1067\n",
      "Epoch [32/100], Step [9/56], Loss: 0.2043\n",
      "Epoch [32/100], Step [10/56], Loss: 0.1716\n",
      "Epoch [32/100], Step [11/56], Loss: 0.1348\n",
      "Epoch [32/100], Step [12/56], Loss: 0.2654\n",
      "Epoch [32/100], Step [13/56], Loss: 0.1664\n",
      "Epoch [32/100], Step [14/56], Loss: 0.2347\n",
      "Epoch [32/100], Step [15/56], Loss: 0.1053\n",
      "Epoch [32/100], Step [16/56], Loss: 0.1318\n",
      "Epoch [32/100], Step [17/56], Loss: 0.2149\n",
      "Epoch [32/100], Step [18/56], Loss: 0.0675\n",
      "Epoch [32/100], Step [19/56], Loss: 0.1879\n",
      "Epoch [32/100], Step [20/56], Loss: 0.1154\n",
      "Epoch [32/100], Step [21/56], Loss: 0.3945\n",
      "Epoch [32/100], Step [22/56], Loss: 0.1106\n",
      "Epoch [32/100], Step [23/56], Loss: 0.1041\n",
      "Epoch [32/100], Step [24/56], Loss: 0.2704\n",
      "Epoch [32/100], Step [25/56], Loss: 0.1635\n",
      "Epoch [32/100], Step [26/56], Loss: 0.2696\n",
      "Epoch [32/100], Step [27/56], Loss: 0.1114\n",
      "Epoch [32/100], Step [28/56], Loss: 0.1458\n",
      "Epoch [32/100], Step [29/56], Loss: 0.1823\n",
      "Epoch [32/100], Step [30/56], Loss: 0.1091\n",
      "Epoch [32/100], Step [31/56], Loss: 0.1158\n",
      "Epoch [32/100], Step [32/56], Loss: 0.1777\n",
      "Epoch [32/100], Step [33/56], Loss: 0.1925\n",
      "Epoch [32/100], Step [34/56], Loss: 0.0963\n",
      "Epoch [32/100], Step [35/56], Loss: 0.2697\n",
      "Epoch [32/100], Step [36/56], Loss: 0.2111\n",
      "Epoch [32/100], Step [37/56], Loss: 0.1064\n",
      "Epoch [32/100], Step [38/56], Loss: 0.3876\n",
      "Epoch [32/100], Step [39/56], Loss: 0.1992\n",
      "Epoch [32/100], Step [40/56], Loss: 0.1967\n",
      "Epoch [32/100], Step [41/56], Loss: 0.1251\n",
      "Epoch [32/100], Step [42/56], Loss: 0.0971\n",
      "Epoch [32/100], Step [43/56], Loss: 0.1830\n",
      "Epoch [32/100], Step [44/56], Loss: 0.3310\n",
      "Epoch [32/100], Step [45/56], Loss: 0.0907\n",
      "Epoch [32/100], Step [46/56], Loss: 0.1535\n",
      "Epoch [32/100], Step [47/56], Loss: 0.2007\n",
      "Epoch [32/100], Step [48/56], Loss: 0.2015\n",
      "Epoch [32/100], Step [49/56], Loss: 0.3864\n",
      "Epoch [32/100], Step [50/56], Loss: 0.2628\n",
      "Epoch [32/100], Step [51/56], Loss: 0.1138\n",
      "Epoch [32/100], Step [52/56], Loss: 0.1594\n",
      "Epoch [32/100], Step [53/56], Loss: 0.3182\n",
      "Epoch [32/100], Step [54/56], Loss: 0.1308\n",
      "Epoch [32/100], Step [55/56], Loss: 0.1793\n",
      "Epoch [32/100], Step [56/56], Loss: 0.1036\n",
      "Val. loss :0.1279\n",
      "Epoch [33/100], Step [1/56], Loss: 0.1867\n",
      "Epoch [33/100], Step [2/56], Loss: 0.1805\n",
      "Epoch [33/100], Step [3/56], Loss: 0.2148\n",
      "Epoch [33/100], Step [4/56], Loss: 0.1816\n",
      "Epoch [33/100], Step [5/56], Loss: 0.1151\n",
      "Epoch [33/100], Step [6/56], Loss: 0.1112\n",
      "Epoch [33/100], Step [7/56], Loss: 0.1977\n",
      "Epoch [33/100], Step [8/56], Loss: 0.2331\n",
      "Epoch [33/100], Step [9/56], Loss: 0.1530\n",
      "Epoch [33/100], Step [10/56], Loss: 0.1448\n",
      "Epoch [33/100], Step [11/56], Loss: 0.2692\n",
      "Epoch [33/100], Step [12/56], Loss: 0.2679\n",
      "Epoch [33/100], Step [13/56], Loss: 0.0936\n",
      "Epoch [33/100], Step [14/56], Loss: 0.1340\n",
      "Epoch [33/100], Step [15/56], Loss: 0.2619\n",
      "Epoch [33/100], Step [16/56], Loss: 0.0674\n",
      "Epoch [33/100], Step [17/56], Loss: 0.1436\n",
      "Epoch [33/100], Step [18/56], Loss: 0.1452\n",
      "Epoch [33/100], Step [19/56], Loss: 0.1357\n",
      "Epoch [33/100], Step [20/56], Loss: 0.1416\n",
      "Epoch [33/100], Step [21/56], Loss: 0.0975\n",
      "Epoch [33/100], Step [22/56], Loss: 0.0882\n",
      "Epoch [33/100], Step [23/56], Loss: 0.1885\n",
      "Epoch [33/100], Step [24/56], Loss: 0.3247\n",
      "Epoch [33/100], Step [25/56], Loss: 0.1251\n",
      "Epoch [33/100], Step [26/56], Loss: 0.1877\n",
      "Epoch [33/100], Step [27/56], Loss: 0.2705\n",
      "Epoch [33/100], Step [28/56], Loss: 0.1313\n",
      "Epoch [33/100], Step [29/56], Loss: 0.1536\n",
      "Epoch [33/100], Step [30/56], Loss: 0.1339\n",
      "Epoch [33/100], Step [31/56], Loss: 0.1402\n",
      "Epoch [33/100], Step [32/56], Loss: 0.1589\n",
      "Epoch [33/100], Step [33/56], Loss: 0.1226\n",
      "Epoch [33/100], Step [34/56], Loss: 0.2027\n",
      "Epoch [33/100], Step [35/56], Loss: 0.2099\n",
      "Epoch [33/100], Step [36/56], Loss: 0.2468\n",
      "Epoch [33/100], Step [37/56], Loss: 0.1393\n",
      "Epoch [33/100], Step [38/56], Loss: 0.1948\n",
      "Epoch [33/100], Step [39/56], Loss: 0.1942\n",
      "Epoch [33/100], Step [40/56], Loss: 0.1976\n",
      "Epoch [33/100], Step [41/56], Loss: 0.3132\n",
      "Epoch [33/100], Step [42/56], Loss: 0.1180\n",
      "Epoch [33/100], Step [43/56], Loss: 0.0967\n",
      "Epoch [33/100], Step [44/56], Loss: 0.1855\n",
      "Epoch [33/100], Step [45/56], Loss: 0.2374\n",
      "Epoch [33/100], Step [46/56], Loss: 0.0958\n",
      "Epoch [33/100], Step [47/56], Loss: 0.1191\n",
      "Epoch [33/100], Step [48/56], Loss: 0.1613\n",
      "Epoch [33/100], Step [49/56], Loss: 0.3703\n",
      "Epoch [33/100], Step [50/56], Loss: 0.1373\n",
      "Epoch [33/100], Step [51/56], Loss: 0.0926\n",
      "Epoch [33/100], Step [52/56], Loss: 0.2159\n",
      "Epoch [33/100], Step [53/56], Loss: 0.2652\n",
      "Epoch [33/100], Step [54/56], Loss: 0.1124\n",
      "Epoch [33/100], Step [55/56], Loss: 0.3361\n",
      "Epoch [33/100], Step [56/56], Loss: 0.1425\n",
      "Val. loss :0.1231\n",
      "Epoch [34/100], Step [1/56], Loss: 0.2082\n",
      "Epoch [34/100], Step [2/56], Loss: 0.1463\n",
      "Epoch [34/100], Step [3/56], Loss: 0.1987\n",
      "Epoch [34/100], Step [4/56], Loss: 0.1870\n",
      "Epoch [34/100], Step [5/56], Loss: 0.1645\n",
      "Epoch [34/100], Step [6/56], Loss: 0.0976\n",
      "Epoch [34/100], Step [7/56], Loss: 0.2541\n",
      "Epoch [34/100], Step [8/56], Loss: 0.1927\n",
      "Epoch [34/100], Step [9/56], Loss: 0.2788\n",
      "Epoch [34/100], Step [10/56], Loss: 0.1492\n",
      "Epoch [34/100], Step [11/56], Loss: 0.1067\n",
      "Epoch [34/100], Step [12/56], Loss: 0.2534\n",
      "Epoch [34/100], Step [13/56], Loss: 0.1499\n",
      "Epoch [34/100], Step [14/56], Loss: 0.1339\n",
      "Epoch [34/100], Step [15/56], Loss: 0.1658\n",
      "Epoch [34/100], Step [16/56], Loss: 0.1771\n",
      "Epoch [34/100], Step [17/56], Loss: 0.1516\n",
      "Epoch [34/100], Step [18/56], Loss: 0.1227\n",
      "Epoch [34/100], Step [19/56], Loss: 0.1536\n",
      "Epoch [34/100], Step [20/56], Loss: 0.2449\n",
      "Epoch [34/100], Step [21/56], Loss: 0.2486\n",
      "Epoch [34/100], Step [22/56], Loss: 0.0899\n",
      "Epoch [34/100], Step [23/56], Loss: 0.1173\n",
      "Epoch [34/100], Step [24/56], Loss: 0.1587\n",
      "Epoch [34/100], Step [25/56], Loss: 0.0971\n",
      "Epoch [34/100], Step [26/56], Loss: 0.1298\n",
      "Epoch [34/100], Step [27/56], Loss: 0.1827\n",
      "Epoch [34/100], Step [28/56], Loss: 0.1571\n",
      "Epoch [34/100], Step [29/56], Loss: 0.1570\n",
      "Epoch [34/100], Step [30/56], Loss: 0.4131\n",
      "Epoch [34/100], Step [31/56], Loss: 0.1031\n",
      "Epoch [34/100], Step [32/56], Loss: 0.1083\n",
      "Epoch [34/100], Step [33/56], Loss: 0.2014\n",
      "Epoch [34/100], Step [34/56], Loss: 0.2121\n",
      "Epoch [34/100], Step [35/56], Loss: 0.1013\n",
      "Epoch [34/100], Step [36/56], Loss: 0.1595\n",
      "Epoch [34/100], Step [37/56], Loss: 0.1380\n",
      "Epoch [34/100], Step [38/56], Loss: 0.1409\n",
      "Epoch [34/100], Step [39/56], Loss: 0.1734\n",
      "Epoch [34/100], Step [40/56], Loss: 0.1280\n",
      "Epoch [34/100], Step [41/56], Loss: 0.1192\n",
      "Epoch [34/100], Step [42/56], Loss: 0.1319\n",
      "Epoch [34/100], Step [43/56], Loss: 0.0983\n",
      "Epoch [34/100], Step [44/56], Loss: 0.1521\n",
      "Epoch [34/100], Step [45/56], Loss: 0.1220\n",
      "Epoch [34/100], Step [46/56], Loss: 0.1188\n",
      "Epoch [34/100], Step [47/56], Loss: 0.0772\n",
      "Epoch [34/100], Step [48/56], Loss: 0.1690\n",
      "Epoch [34/100], Step [49/56], Loss: 0.3230\n",
      "Epoch [34/100], Step [50/56], Loss: 0.1757\n",
      "Epoch [34/100], Step [51/56], Loss: 0.2661\n",
      "Epoch [34/100], Step [52/56], Loss: 0.1479\n",
      "Epoch [34/100], Step [53/56], Loss: 0.0899\n",
      "Epoch [34/100], Step [54/56], Loss: 0.1126\n",
      "Epoch [34/100], Step [55/56], Loss: 0.1764\n",
      "Epoch [34/100], Step [56/56], Loss: 0.0429\n",
      "Val. loss :0.1684\n",
      "Epoch [35/100], Step [1/56], Loss: 0.1203\n",
      "Epoch [35/100], Step [2/56], Loss: 0.2775\n",
      "Epoch [35/100], Step [3/56], Loss: 0.2618\n",
      "Epoch [35/100], Step [4/56], Loss: 0.2739\n",
      "Epoch [35/100], Step [5/56], Loss: 0.2024\n",
      "Epoch [35/100], Step [6/56], Loss: 0.1686\n",
      "Epoch [35/100], Step [7/56], Loss: 0.1110\n",
      "Epoch [35/100], Step [8/56], Loss: 0.2379\n",
      "Epoch [35/100], Step [9/56], Loss: 0.1947\n",
      "Epoch [35/100], Step [10/56], Loss: 0.2584\n",
      "Epoch [35/100], Step [11/56], Loss: 0.1288\n",
      "Epoch [35/100], Step [12/56], Loss: 0.1458\n",
      "Epoch [35/100], Step [13/56], Loss: 0.1100\n",
      "Epoch [35/100], Step [14/56], Loss: 0.1560\n",
      "Epoch [35/100], Step [15/56], Loss: 0.3406\n",
      "Epoch [35/100], Step [16/56], Loss: 0.1099\n",
      "Epoch [35/100], Step [17/56], Loss: 0.2540\n",
      "Epoch [35/100], Step [18/56], Loss: 0.1906\n",
      "Epoch [35/100], Step [19/56], Loss: 0.1983\n",
      "Epoch [35/100], Step [20/56], Loss: 0.2477\n",
      "Epoch [35/100], Step [21/56], Loss: 0.1286\n",
      "Epoch [35/100], Step [22/56], Loss: 0.1246\n",
      "Epoch [35/100], Step [23/56], Loss: 0.1565\n",
      "Epoch [35/100], Step [24/56], Loss: 0.1425\n",
      "Epoch [35/100], Step [25/56], Loss: 0.1422\n",
      "Epoch [35/100], Step [26/56], Loss: 0.2727\n",
      "Epoch [35/100], Step [27/56], Loss: 0.2559\n",
      "Epoch [35/100], Step [28/56], Loss: 0.1595\n",
      "Epoch [35/100], Step [29/56], Loss: 0.1561\n",
      "Epoch [35/100], Step [30/56], Loss: 0.1738\n",
      "Epoch [35/100], Step [31/56], Loss: 0.1050\n",
      "Epoch [35/100], Step [32/56], Loss: 0.5798\n",
      "Epoch [35/100], Step [33/56], Loss: 0.2168\n",
      "Epoch [35/100], Step [34/56], Loss: 0.1356\n",
      "Epoch [35/100], Step [35/56], Loss: 0.1601\n",
      "Epoch [35/100], Step [36/56], Loss: 0.1816\n",
      "Epoch [35/100], Step [37/56], Loss: 0.3050\n",
      "Epoch [35/100], Step [38/56], Loss: 0.1586\n",
      "Epoch [35/100], Step [39/56], Loss: 0.1452\n",
      "Epoch [35/100], Step [40/56], Loss: 0.1564\n",
      "Epoch [35/100], Step [41/56], Loss: 0.2015\n",
      "Epoch [35/100], Step [42/56], Loss: 0.1417\n",
      "Epoch [35/100], Step [43/56], Loss: 0.1408\n",
      "Epoch [35/100], Step [44/56], Loss: 0.1716\n",
      "Epoch [35/100], Step [45/56], Loss: 0.0969\n",
      "Epoch [35/100], Step [46/56], Loss: 0.2125\n",
      "Epoch [35/100], Step [47/56], Loss: 0.0886\n",
      "Epoch [35/100], Step [48/56], Loss: 0.0685\n",
      "Epoch [35/100], Step [49/56], Loss: 0.1246\n",
      "Epoch [35/100], Step [50/56], Loss: 0.2653\n",
      "Epoch [35/100], Step [51/56], Loss: 0.1056\n",
      "Epoch [35/100], Step [52/56], Loss: 0.1939\n",
      "Epoch [35/100], Step [53/56], Loss: 0.1098\n",
      "Epoch [35/100], Step [54/56], Loss: 0.1108\n",
      "Epoch [35/100], Step [55/56], Loss: 0.2094\n",
      "Epoch [35/100], Step [56/56], Loss: 0.0770\n",
      "Val. loss :0.1243\n",
      "Epoch [36/100], Step [1/56], Loss: 0.1281\n",
      "Epoch [36/100], Step [2/56], Loss: 0.2214\n",
      "Epoch [36/100], Step [3/56], Loss: 0.1396\n",
      "Epoch [36/100], Step [4/56], Loss: 0.1053\n",
      "Epoch [36/100], Step [5/56], Loss: 0.2508\n",
      "Epoch [36/100], Step [6/56], Loss: 0.1587\n",
      "Epoch [36/100], Step [7/56], Loss: 0.0806\n",
      "Epoch [36/100], Step [8/56], Loss: 0.2254\n",
      "Epoch [36/100], Step [9/56], Loss: 0.2141\n",
      "Epoch [36/100], Step [10/56], Loss: 0.1572\n",
      "Epoch [36/100], Step [11/56], Loss: 0.1397\n",
      "Epoch [36/100], Step [12/56], Loss: 0.2221\n",
      "Epoch [36/100], Step [13/56], Loss: 0.2795\n",
      "Epoch [36/100], Step [14/56], Loss: 0.0970\n",
      "Epoch [36/100], Step [15/56], Loss: 0.1167\n",
      "Epoch [36/100], Step [16/56], Loss: 0.1109\n",
      "Epoch [36/100], Step [17/56], Loss: 0.0696\n",
      "Epoch [36/100], Step [18/56], Loss: 0.1332\n",
      "Epoch [36/100], Step [19/56], Loss: 0.0814\n",
      "Epoch [36/100], Step [20/56], Loss: 0.1569\n",
      "Epoch [36/100], Step [21/56], Loss: 0.0714\n",
      "Epoch [36/100], Step [22/56], Loss: 0.2322\n",
      "Epoch [36/100], Step [23/56], Loss: 0.1255\n",
      "Epoch [36/100], Step [24/56], Loss: 0.1066\n",
      "Epoch [36/100], Step [25/56], Loss: 0.0981\n",
      "Epoch [36/100], Step [26/56], Loss: 0.1381\n",
      "Epoch [36/100], Step [27/56], Loss: 0.1096\n",
      "Epoch [36/100], Step [28/56], Loss: 0.1491\n",
      "Epoch [36/100], Step [29/56], Loss: 0.1583\n",
      "Epoch [36/100], Step [30/56], Loss: 0.1551\n",
      "Epoch [36/100], Step [31/56], Loss: 0.1252\n",
      "Epoch [36/100], Step [32/56], Loss: 0.2217\n",
      "Epoch [36/100], Step [33/56], Loss: 0.1781\n",
      "Epoch [36/100], Step [34/56], Loss: 0.1246\n",
      "Epoch [36/100], Step [35/56], Loss: 0.3944\n",
      "Epoch [36/100], Step [36/56], Loss: 0.1264\n",
      "Epoch [36/100], Step [37/56], Loss: 0.0792\n",
      "Epoch [36/100], Step [38/56], Loss: 0.1338\n",
      "Epoch [36/100], Step [39/56], Loss: 0.1265\n",
      "Epoch [36/100], Step [40/56], Loss: 0.1461\n",
      "Epoch [36/100], Step [41/56], Loss: 0.1095\n",
      "Epoch [36/100], Step [42/56], Loss: 0.1108\n",
      "Epoch [36/100], Step [43/56], Loss: 0.1083\n",
      "Epoch [36/100], Step [44/56], Loss: 0.2753\n",
      "Epoch [36/100], Step [45/56], Loss: 0.1215\n",
      "Epoch [36/100], Step [46/56], Loss: 0.3760\n",
      "Epoch [36/100], Step [47/56], Loss: 0.1027\n",
      "Epoch [36/100], Step [48/56], Loss: 0.0991\n",
      "Epoch [36/100], Step [49/56], Loss: 0.1217\n",
      "Epoch [36/100], Step [50/56], Loss: 0.0720\n",
      "Epoch [36/100], Step [51/56], Loss: 0.0736\n",
      "Epoch [36/100], Step [52/56], Loss: 0.1596\n",
      "Epoch [36/100], Step [53/56], Loss: 0.3334\n",
      "Epoch [36/100], Step [54/56], Loss: 0.1054\n",
      "Epoch [36/100], Step [55/56], Loss: 0.1167\n",
      "Epoch [36/100], Step [56/56], Loss: 0.0963\n",
      "Val. loss :0.1590\n",
      "Epoch [37/100], Step [1/56], Loss: 0.1969\n",
      "Epoch [37/100], Step [2/56], Loss: 0.2005\n",
      "Epoch [37/100], Step [3/56], Loss: 0.1496\n",
      "Epoch [37/100], Step [4/56], Loss: 0.0995\n",
      "Epoch [37/100], Step [5/56], Loss: 0.1913\n",
      "Epoch [37/100], Step [6/56], Loss: 0.3933\n",
      "Epoch [37/100], Step [7/56], Loss: 0.2156\n",
      "Epoch [37/100], Step [8/56], Loss: 0.1550\n",
      "Epoch [37/100], Step [9/56], Loss: 0.1631\n",
      "Epoch [37/100], Step [10/56], Loss: 0.2192\n",
      "Epoch [37/100], Step [11/56], Loss: 0.1618\n",
      "Epoch [37/100], Step [12/56], Loss: 0.2183\n",
      "Epoch [37/100], Step [13/56], Loss: 0.1405\n",
      "Epoch [37/100], Step [14/56], Loss: 0.1202\n",
      "Epoch [37/100], Step [15/56], Loss: 0.1573\n",
      "Epoch [37/100], Step [16/56], Loss: 0.1503\n",
      "Epoch [37/100], Step [17/56], Loss: 0.1279\n",
      "Epoch [37/100], Step [18/56], Loss: 0.1025\n",
      "Epoch [37/100], Step [19/56], Loss: 0.0852\n",
      "Epoch [37/100], Step [20/56], Loss: 0.1861\n",
      "Epoch [37/100], Step [21/56], Loss: 0.1423\n",
      "Epoch [37/100], Step [22/56], Loss: 0.4243\n",
      "Epoch [37/100], Step [23/56], Loss: 0.0975\n",
      "Epoch [37/100], Step [24/56], Loss: 0.1155\n",
      "Epoch [37/100], Step [25/56], Loss: 0.2358\n",
      "Epoch [37/100], Step [26/56], Loss: 0.1803\n",
      "Epoch [37/100], Step [27/56], Loss: 0.2980\n",
      "Epoch [37/100], Step [28/56], Loss: 0.0835\n",
      "Epoch [37/100], Step [29/56], Loss: 0.1553\n",
      "Epoch [37/100], Step [30/56], Loss: 0.1507\n",
      "Epoch [37/100], Step [31/56], Loss: 0.1125\n",
      "Epoch [37/100], Step [32/56], Loss: 0.1396\n",
      "Epoch [37/100], Step [33/56], Loss: 0.0904\n",
      "Epoch [37/100], Step [34/56], Loss: 0.1144\n",
      "Epoch [37/100], Step [35/56], Loss: 0.2974\n",
      "Epoch [37/100], Step [36/56], Loss: 0.0948\n",
      "Epoch [37/100], Step [37/56], Loss: 0.0872\n",
      "Epoch [37/100], Step [38/56], Loss: 0.1162\n",
      "Epoch [37/100], Step [39/56], Loss: 0.1413\n",
      "Epoch [37/100], Step [40/56], Loss: 0.3346\n",
      "Epoch [37/100], Step [41/56], Loss: 0.0887\n",
      "Epoch [37/100], Step [42/56], Loss: 0.1110\n",
      "Epoch [37/100], Step [43/56], Loss: 0.1216\n",
      "Epoch [37/100], Step [44/56], Loss: 0.0942\n",
      "Epoch [37/100], Step [45/56], Loss: 0.1947\n",
      "Epoch [37/100], Step [46/56], Loss: 0.1887\n",
      "Epoch [37/100], Step [47/56], Loss: 0.0980\n",
      "Epoch [37/100], Step [48/56], Loss: 0.1190\n",
      "Epoch [37/100], Step [49/56], Loss: 0.1617\n",
      "Epoch [37/100], Step [50/56], Loss: 0.0821\n",
      "Epoch [37/100], Step [51/56], Loss: 0.1211\n",
      "Epoch [37/100], Step [52/56], Loss: 0.1145\n",
      "Epoch [37/100], Step [53/56], Loss: 0.1507\n",
      "Epoch [37/100], Step [54/56], Loss: 0.2310\n",
      "Epoch [37/100], Step [55/56], Loss: 0.1151\n",
      "Epoch [37/100], Step [56/56], Loss: 0.0995\n",
      "Val. loss :0.1489\n",
      "Epoch [38/100], Step [1/56], Loss: 0.1214\n",
      "Epoch [38/100], Step [2/56], Loss: 0.2217\n",
      "Epoch [38/100], Step [3/56], Loss: 0.0786\n",
      "Epoch [38/100], Step [4/56], Loss: 0.2017\n",
      "Epoch [38/100], Step [5/56], Loss: 0.1037\n",
      "Epoch [38/100], Step [6/56], Loss: 0.3642\n",
      "Epoch [38/100], Step [7/56], Loss: 0.2231\n",
      "Epoch [38/100], Step [8/56], Loss: 0.0685\n",
      "Epoch [38/100], Step [9/56], Loss: 0.2313\n",
      "Epoch [38/100], Step [10/56], Loss: 0.1290\n",
      "Epoch [38/100], Step [11/56], Loss: 0.2426\n",
      "Epoch [38/100], Step [12/56], Loss: 0.1792\n",
      "Epoch [38/100], Step [13/56], Loss: 0.1011\n",
      "Epoch [38/100], Step [14/56], Loss: 0.2175\n",
      "Epoch [38/100], Step [15/56], Loss: 0.1528\n",
      "Epoch [38/100], Step [16/56], Loss: 0.0840\n",
      "Epoch [38/100], Step [17/56], Loss: 0.1173\n",
      "Epoch [38/100], Step [18/56], Loss: 0.0987\n",
      "Epoch [38/100], Step [19/56], Loss: 0.1149\n",
      "Epoch [38/100], Step [20/56], Loss: 0.1474\n",
      "Epoch [38/100], Step [21/56], Loss: 0.2114\n",
      "Epoch [38/100], Step [22/56], Loss: 0.0912\n",
      "Epoch [38/100], Step [23/56], Loss: 0.1688\n",
      "Epoch [38/100], Step [24/56], Loss: 0.1120\n",
      "Epoch [38/100], Step [25/56], Loss: 0.0825\n",
      "Epoch [38/100], Step [26/56], Loss: 0.2638\n",
      "Epoch [38/100], Step [27/56], Loss: 0.0959\n",
      "Epoch [38/100], Step [28/56], Loss: 0.1495\n",
      "Epoch [38/100], Step [29/56], Loss: 0.1102\n",
      "Epoch [38/100], Step [30/56], Loss: 0.2179\n",
      "Epoch [38/100], Step [31/56], Loss: 0.0913\n",
      "Epoch [38/100], Step [32/56], Loss: 0.2435\n",
      "Epoch [38/100], Step [33/56], Loss: 0.1200\n",
      "Epoch [38/100], Step [34/56], Loss: 0.0677\n",
      "Epoch [38/100], Step [35/56], Loss: 0.2583\n",
      "Epoch [38/100], Step [36/56], Loss: 0.1320\n",
      "Epoch [38/100], Step [37/56], Loss: 0.1522\n",
      "Epoch [38/100], Step [38/56], Loss: 0.1171\n",
      "Epoch [38/100], Step [39/56], Loss: 0.0738\n",
      "Epoch [38/100], Step [40/56], Loss: 0.1859\n",
      "Epoch [38/100], Step [41/56], Loss: 0.1480\n",
      "Epoch [38/100], Step [42/56], Loss: 0.1414\n",
      "Epoch [38/100], Step [43/56], Loss: 0.2026\n",
      "Epoch [38/100], Step [44/56], Loss: 0.0887\n",
      "Epoch [38/100], Step [45/56], Loss: 0.1096\n",
      "Epoch [38/100], Step [46/56], Loss: 0.1871\n",
      "Epoch [38/100], Step [47/56], Loss: 0.1727\n",
      "Epoch [38/100], Step [48/56], Loss: 0.2817\n",
      "Epoch [38/100], Step [49/56], Loss: 0.1168\n",
      "Epoch [38/100], Step [50/56], Loss: 0.1972\n",
      "Epoch [38/100], Step [51/56], Loss: 0.1182\n",
      "Epoch [38/100], Step [52/56], Loss: 0.1221\n",
      "Epoch [38/100], Step [53/56], Loss: 0.1200\n",
      "Epoch [38/100], Step [54/56], Loss: 0.2343\n",
      "Epoch [38/100], Step [55/56], Loss: 0.1559\n",
      "Epoch [38/100], Step [56/56], Loss: 0.0787\n",
      "Val. loss :0.1063\n",
      "Epoch [39/100], Step [1/56], Loss: 0.1045\n",
      "Epoch [39/100], Step [2/56], Loss: 0.0913\n",
      "Epoch [39/100], Step [3/56], Loss: 0.1030\n",
      "Epoch [39/100], Step [4/56], Loss: 0.1865\n",
      "Epoch [39/100], Step [5/56], Loss: 0.0716\n",
      "Epoch [39/100], Step [6/56], Loss: 0.0995\n",
      "Epoch [39/100], Step [7/56], Loss: 0.0905\n",
      "Epoch [39/100], Step [8/56], Loss: 0.0843\n",
      "Epoch [39/100], Step [9/56], Loss: 0.1675\n",
      "Epoch [39/100], Step [10/56], Loss: 0.0764\n",
      "Epoch [39/100], Step [11/56], Loss: 0.0906\n",
      "Epoch [39/100], Step [12/56], Loss: 0.0646\n",
      "Epoch [39/100], Step [13/56], Loss: 0.3035\n",
      "Epoch [39/100], Step [14/56], Loss: 0.1148\n",
      "Epoch [39/100], Step [15/56], Loss: 0.0797\n",
      "Epoch [39/100], Step [16/56], Loss: 0.1767\n",
      "Epoch [39/100], Step [17/56], Loss: 0.0960\n",
      "Epoch [39/100], Step [18/56], Loss: 0.2135\n",
      "Epoch [39/100], Step [19/56], Loss: 0.1078\n",
      "Epoch [39/100], Step [20/56], Loss: 0.3583\n",
      "Epoch [39/100], Step [21/56], Loss: 0.1420\n",
      "Epoch [39/100], Step [22/56], Loss: 0.0966\n",
      "Epoch [39/100], Step [23/56], Loss: 0.4430\n",
      "Epoch [39/100], Step [24/56], Loss: 0.1884\n",
      "Epoch [39/100], Step [25/56], Loss: 0.1005\n",
      "Epoch [39/100], Step [26/56], Loss: 0.1608\n",
      "Epoch [39/100], Step [27/56], Loss: 0.1615\n",
      "Epoch [39/100], Step [28/56], Loss: 0.1439\n",
      "Epoch [39/100], Step [29/56], Loss: 0.1670\n",
      "Epoch [39/100], Step [30/56], Loss: 0.1428\n",
      "Epoch [39/100], Step [31/56], Loss: 0.2397\n",
      "Epoch [39/100], Step [32/56], Loss: 0.1144\n",
      "Epoch [39/100], Step [33/56], Loss: 0.1443\n",
      "Epoch [39/100], Step [34/56], Loss: 0.1265\n",
      "Epoch [39/100], Step [35/56], Loss: 0.1289\n",
      "Epoch [39/100], Step [36/56], Loss: 0.1103\n",
      "Epoch [39/100], Step [37/56], Loss: 0.0777\n",
      "Epoch [39/100], Step [38/56], Loss: 0.1664\n",
      "Epoch [39/100], Step [39/56], Loss: 0.1055\n",
      "Epoch [39/100], Step [40/56], Loss: 0.0799\n",
      "Epoch [39/100], Step [41/56], Loss: 0.2099\n",
      "Epoch [39/100], Step [42/56], Loss: 0.0742\n",
      "Epoch [39/100], Step [43/56], Loss: 0.0890\n",
      "Epoch [39/100], Step [44/56], Loss: 0.1593\n",
      "Epoch [39/100], Step [45/56], Loss: 0.1041\n",
      "Epoch [39/100], Step [46/56], Loss: 0.1847\n",
      "Epoch [39/100], Step [47/56], Loss: 0.0701\n",
      "Epoch [39/100], Step [48/56], Loss: 0.0859\n",
      "Epoch [39/100], Step [49/56], Loss: 0.1144\n",
      "Epoch [39/100], Step [50/56], Loss: 0.1140\n",
      "Epoch [39/100], Step [51/56], Loss: 0.0670\n",
      "Epoch [39/100], Step [52/56], Loss: 0.3337\n",
      "Epoch [39/100], Step [53/56], Loss: 0.0888\n",
      "Epoch [39/100], Step [54/56], Loss: 0.1239\n",
      "Epoch [39/100], Step [55/56], Loss: 0.1667\n",
      "Epoch [39/100], Step [56/56], Loss: 0.0633\n",
      "Val. loss :0.0824\n",
      "Epoch [40/100], Step [1/56], Loss: 0.0853\n",
      "Epoch [40/100], Step [2/56], Loss: 0.0946\n",
      "Epoch [40/100], Step [3/56], Loss: 0.1663\n",
      "Epoch [40/100], Step [4/56], Loss: 0.1265\n",
      "Epoch [40/100], Step [5/56], Loss: 0.2812\n",
      "Epoch [40/100], Step [6/56], Loss: 0.1609\n",
      "Epoch [40/100], Step [7/56], Loss: 0.0687\n",
      "Epoch [40/100], Step [8/56], Loss: 0.1410\n",
      "Epoch [40/100], Step [9/56], Loss: 0.1269\n",
      "Epoch [40/100], Step [10/56], Loss: 0.2047\n",
      "Epoch [40/100], Step [11/56], Loss: 0.2320\n",
      "Epoch [40/100], Step [12/56], Loss: 0.0708\n",
      "Epoch [40/100], Step [13/56], Loss: 0.1078\n",
      "Epoch [40/100], Step [14/56], Loss: 0.1070\n",
      "Epoch [40/100], Step [15/56], Loss: 0.1402\n",
      "Epoch [40/100], Step [16/56], Loss: 0.1609\n",
      "Epoch [40/100], Step [17/56], Loss: 0.1255\n",
      "Epoch [40/100], Step [18/56], Loss: 0.0785\n",
      "Epoch [40/100], Step [19/56], Loss: 0.1986\n",
      "Epoch [40/100], Step [20/56], Loss: 0.2603\n",
      "Epoch [40/100], Step [21/56], Loss: 0.0524\n",
      "Epoch [40/100], Step [22/56], Loss: 0.0948\n",
      "Epoch [40/100], Step [23/56], Loss: 0.0764\n",
      "Epoch [40/100], Step [24/56], Loss: 0.1193\n",
      "Epoch [40/100], Step [25/56], Loss: 0.3499\n",
      "Epoch [40/100], Step [26/56], Loss: 0.1315\n",
      "Epoch [40/100], Step [27/56], Loss: 0.1864\n",
      "Epoch [40/100], Step [28/56], Loss: 0.1146\n",
      "Epoch [40/100], Step [29/56], Loss: 0.2484\n",
      "Epoch [40/100], Step [30/56], Loss: 0.1677\n",
      "Epoch [40/100], Step [31/56], Loss: 0.2271\n",
      "Epoch [40/100], Step [32/56], Loss: 0.1176\n",
      "Epoch [40/100], Step [33/56], Loss: 0.1286\n",
      "Epoch [40/100], Step [34/56], Loss: 0.1359\n",
      "Epoch [40/100], Step [35/56], Loss: 0.1221\n",
      "Epoch [40/100], Step [36/56], Loss: 0.0846\n",
      "Epoch [40/100], Step [37/56], Loss: 0.0864\n",
      "Epoch [40/100], Step [38/56], Loss: 0.1842\n",
      "Epoch [40/100], Step [39/56], Loss: 0.0972\n",
      "Epoch [40/100], Step [40/56], Loss: 0.1532\n",
      "Epoch [40/100], Step [41/56], Loss: 0.2953\n",
      "Epoch [40/100], Step [42/56], Loss: 0.0918\n",
      "Epoch [40/100], Step [43/56], Loss: 0.1466\n",
      "Epoch [40/100], Step [44/56], Loss: 0.0998\n",
      "Epoch [40/100], Step [45/56], Loss: 0.0917\n",
      "Epoch [40/100], Step [46/56], Loss: 0.2992\n",
      "Epoch [40/100], Step [47/56], Loss: 0.1900\n",
      "Epoch [40/100], Step [48/56], Loss: 0.2017\n",
      "Epoch [40/100], Step [49/56], Loss: 0.0739\n",
      "Epoch [40/100], Step [50/56], Loss: 0.2131\n",
      "Epoch [40/100], Step [51/56], Loss: 0.1110\n",
      "Epoch [40/100], Step [52/56], Loss: 0.1861\n",
      "Epoch [40/100], Step [53/56], Loss: 0.1704\n",
      "Epoch [40/100], Step [54/56], Loss: 0.3118\n",
      "Epoch [40/100], Step [55/56], Loss: 0.1065\n",
      "Epoch [40/100], Step [56/56], Loss: 0.0339\n",
      "Val. loss :0.1058\n",
      "Epoch [41/100], Step [1/56], Loss: 0.0965\n",
      "Epoch [41/100], Step [2/56], Loss: 0.1036\n",
      "Epoch [41/100], Step [3/56], Loss: 0.0992\n",
      "Epoch [41/100], Step [4/56], Loss: 0.0537\n",
      "Epoch [41/100], Step [5/56], Loss: 0.1041\n",
      "Epoch [41/100], Step [6/56], Loss: 0.1843\n",
      "Epoch [41/100], Step [7/56], Loss: 0.1007\n",
      "Epoch [41/100], Step [8/56], Loss: 0.1092\n",
      "Epoch [41/100], Step [9/56], Loss: 0.1264\n",
      "Epoch [41/100], Step [10/56], Loss: 0.2468\n",
      "Epoch [41/100], Step [11/56], Loss: 0.0772\n",
      "Epoch [41/100], Step [12/56], Loss: 0.0917\n",
      "Epoch [41/100], Step [13/56], Loss: 0.1486\n",
      "Epoch [41/100], Step [14/56], Loss: 0.1609\n",
      "Epoch [41/100], Step [15/56], Loss: 0.0644\n",
      "Epoch [41/100], Step [16/56], Loss: 0.1746\n",
      "Epoch [41/100], Step [17/56], Loss: 0.2904\n",
      "Epoch [41/100], Step [18/56], Loss: 0.1483\n",
      "Epoch [41/100], Step [19/56], Loss: 0.0605\n",
      "Epoch [41/100], Step [20/56], Loss: 0.0856\n",
      "Epoch [41/100], Step [21/56], Loss: 0.3358\n",
      "Epoch [41/100], Step [22/56], Loss: 0.1193\n",
      "Epoch [41/100], Step [23/56], Loss: 0.1218\n",
      "Epoch [41/100], Step [24/56], Loss: 0.1193\n",
      "Epoch [41/100], Step [25/56], Loss: 0.0971\n",
      "Epoch [41/100], Step [26/56], Loss: 0.1040\n",
      "Epoch [41/100], Step [27/56], Loss: 0.3652\n",
      "Epoch [41/100], Step [28/56], Loss: 0.0713\n",
      "Epoch [41/100], Step [29/56], Loss: 0.1050\n",
      "Epoch [41/100], Step [30/56], Loss: 0.1207\n",
      "Epoch [41/100], Step [31/56], Loss: 0.1705\n",
      "Epoch [41/100], Step [32/56], Loss: 0.2648\n",
      "Epoch [41/100], Step [33/56], Loss: 0.0964\n",
      "Epoch [41/100], Step [34/56], Loss: 0.0916\n",
      "Epoch [41/100], Step [35/56], Loss: 0.1756\n",
      "Epoch [41/100], Step [36/56], Loss: 0.1140\n",
      "Epoch [41/100], Step [37/56], Loss: 0.0863\n",
      "Epoch [41/100], Step [38/56], Loss: 0.1148\n",
      "Epoch [41/100], Step [39/56], Loss: 0.1315\n",
      "Epoch [41/100], Step [40/56], Loss: 0.0944\n",
      "Epoch [41/100], Step [41/56], Loss: 0.0803\n",
      "Epoch [41/100], Step [42/56], Loss: 0.1303\n",
      "Epoch [41/100], Step [43/56], Loss: 0.1114\n",
      "Epoch [41/100], Step [44/56], Loss: 0.1227\n",
      "Epoch [41/100], Step [45/56], Loss: 0.2335\n",
      "Epoch [41/100], Step [46/56], Loss: 0.1141\n",
      "Epoch [41/100], Step [47/56], Loss: 0.2308\n",
      "Epoch [41/100], Step [48/56], Loss: 0.3092\n",
      "Epoch [41/100], Step [49/56], Loss: 0.1020\n",
      "Epoch [41/100], Step [50/56], Loss: 0.0654\n",
      "Epoch [41/100], Step [51/56], Loss: 0.1291\n",
      "Epoch [41/100], Step [52/56], Loss: 0.0984\n",
      "Epoch [41/100], Step [53/56], Loss: 0.1229\n",
      "Epoch [41/100], Step [54/56], Loss: 0.2556\n",
      "Epoch [41/100], Step [55/56], Loss: 0.1669\n",
      "Epoch [41/100], Step [56/56], Loss: 0.0969\n",
      "Val. loss :0.1008\n",
      "Epoch [42/100], Step [1/56], Loss: 0.1128\n",
      "Epoch [42/100], Step [2/56], Loss: 0.2728\n",
      "Epoch [42/100], Step [3/56], Loss: 0.0952\n",
      "Epoch [42/100], Step [4/56], Loss: 0.0791\n",
      "Epoch [42/100], Step [5/56], Loss: 0.0752\n",
      "Epoch [42/100], Step [6/56], Loss: 0.0864\n",
      "Epoch [42/100], Step [7/56], Loss: 0.1349\n",
      "Epoch [42/100], Step [8/56], Loss: 0.1580\n",
      "Epoch [42/100], Step [9/56], Loss: 0.1992\n",
      "Epoch [42/100], Step [10/56], Loss: 0.1918\n",
      "Epoch [42/100], Step [11/56], Loss: 0.0882\n",
      "Epoch [42/100], Step [12/56], Loss: 0.0994\n",
      "Epoch [42/100], Step [13/56], Loss: 0.1207\n",
      "Epoch [42/100], Step [14/56], Loss: 0.1058\n",
      "Epoch [42/100], Step [15/56], Loss: 0.1012\n",
      "Epoch [42/100], Step [16/56], Loss: 0.0930\n",
      "Epoch [42/100], Step [17/56], Loss: 0.0992\n",
      "Epoch [42/100], Step [18/56], Loss: 0.1292\n",
      "Epoch [42/100], Step [19/56], Loss: 0.1426\n",
      "Epoch [42/100], Step [20/56], Loss: 0.1775\n",
      "Epoch [42/100], Step [21/56], Loss: 0.2520\n",
      "Epoch [42/100], Step [22/56], Loss: 0.0737\n",
      "Epoch [42/100], Step [23/56], Loss: 0.1504\n",
      "Epoch [42/100], Step [24/56], Loss: 0.1377\n",
      "Epoch [42/100], Step [25/56], Loss: 0.1287\n",
      "Epoch [42/100], Step [26/56], Loss: 0.0820\n",
      "Epoch [42/100], Step [27/56], Loss: 0.1529\n",
      "Epoch [42/100], Step [28/56], Loss: 0.1971\n",
      "Epoch [42/100], Step [29/56], Loss: 0.1193\n",
      "Epoch [42/100], Step [30/56], Loss: 0.1686\n",
      "Epoch [42/100], Step [31/56], Loss: 0.1386\n",
      "Epoch [42/100], Step [32/56], Loss: 0.0748\n",
      "Epoch [42/100], Step [33/56], Loss: 0.1270\n",
      "Epoch [42/100], Step [34/56], Loss: 0.0998\n",
      "Epoch [42/100], Step [35/56], Loss: 0.0978\n",
      "Epoch [42/100], Step [36/56], Loss: 0.1742\n",
      "Epoch [42/100], Step [37/56], Loss: 0.3534\n",
      "Epoch [42/100], Step [38/56], Loss: 0.2041\n",
      "Epoch [42/100], Step [39/56], Loss: 0.1881\n",
      "Epoch [42/100], Step [40/56], Loss: 0.1347\n",
      "Epoch [42/100], Step [41/56], Loss: 0.2043\n",
      "Epoch [42/100], Step [42/56], Loss: 0.2548\n",
      "Epoch [42/100], Step [43/56], Loss: 0.0944\n",
      "Epoch [42/100], Step [44/56], Loss: 0.0701\n",
      "Epoch [42/100], Step [45/56], Loss: 0.1285\n",
      "Epoch [42/100], Step [46/56], Loss: 0.1231\n",
      "Epoch [42/100], Step [47/56], Loss: 0.1265\n",
      "Epoch [42/100], Step [48/56], Loss: 0.2293\n",
      "Epoch [42/100], Step [49/56], Loss: 0.1676\n",
      "Epoch [42/100], Step [50/56], Loss: 0.1313\n",
      "Epoch [42/100], Step [51/56], Loss: 0.1627\n",
      "Epoch [42/100], Step [52/56], Loss: 0.1741\n",
      "Epoch [42/100], Step [53/56], Loss: 0.2035\n",
      "Epoch [42/100], Step [54/56], Loss: 0.1658\n",
      "Epoch [42/100], Step [55/56], Loss: 0.0989\n",
      "Epoch [42/100], Step [56/56], Loss: 0.0974\n",
      "Val. loss :0.0892\n",
      "Epoch [43/100], Step [1/56], Loss: 0.1458\n",
      "Epoch [43/100], Step [2/56], Loss: 0.1197\n",
      "Epoch [43/100], Step [3/56], Loss: 0.1686\n",
      "Epoch [43/100], Step [4/56], Loss: 0.0900\n",
      "Epoch [43/100], Step [5/56], Loss: 0.1874\n",
      "Epoch [43/100], Step [6/56], Loss: 0.1915\n",
      "Epoch [43/100], Step [7/56], Loss: 0.1835\n",
      "Epoch [43/100], Step [8/56], Loss: 0.1268\n",
      "Epoch [43/100], Step [9/56], Loss: 0.1174\n",
      "Epoch [43/100], Step [10/56], Loss: 0.0737\n",
      "Epoch [43/100], Step [11/56], Loss: 0.2465\n",
      "Epoch [43/100], Step [12/56], Loss: 0.0919\n",
      "Epoch [43/100], Step [13/56], Loss: 0.1438\n",
      "Epoch [43/100], Step [14/56], Loss: 0.1683\n",
      "Epoch [43/100], Step [15/56], Loss: 0.2949\n",
      "Epoch [43/100], Step [16/56], Loss: 0.0757\n",
      "Epoch [43/100], Step [17/56], Loss: 0.1459\n",
      "Epoch [43/100], Step [18/56], Loss: 0.1289\n",
      "Epoch [43/100], Step [19/56], Loss: 0.0998\n",
      "Epoch [43/100], Step [20/56], Loss: 0.1662\n",
      "Epoch [43/100], Step [21/56], Loss: 0.0743\n",
      "Epoch [43/100], Step [22/56], Loss: 0.1194\n",
      "Epoch [43/100], Step [23/56], Loss: 0.2738\n",
      "Epoch [43/100], Step [24/56], Loss: 0.1152\n",
      "Epoch [43/100], Step [25/56], Loss: 0.1514\n",
      "Epoch [43/100], Step [26/56], Loss: 0.0770\n",
      "Epoch [43/100], Step [27/56], Loss: 0.2274\n",
      "Epoch [43/100], Step [28/56], Loss: 0.1065\n",
      "Epoch [43/100], Step [29/56], Loss: 0.2254\n",
      "Epoch [43/100], Step [30/56], Loss: 0.1202\n",
      "Epoch [43/100], Step [31/56], Loss: 0.0915\n",
      "Epoch [43/100], Step [32/56], Loss: 0.0720\n",
      "Epoch [43/100], Step [33/56], Loss: 0.2080\n",
      "Epoch [43/100], Step [34/56], Loss: 0.0839\n",
      "Epoch [43/100], Step [35/56], Loss: 0.0683\n",
      "Epoch [43/100], Step [36/56], Loss: 0.0923\n",
      "Epoch [43/100], Step [37/56], Loss: 0.2602\n",
      "Epoch [43/100], Step [38/56], Loss: 0.0822\n",
      "Epoch [43/100], Step [39/56], Loss: 0.2351\n",
      "Epoch [43/100], Step [40/56], Loss: 0.1238\n",
      "Epoch [43/100], Step [41/56], Loss: 0.1097\n",
      "Epoch [43/100], Step [42/56], Loss: 0.1245\n",
      "Epoch [43/100], Step [43/56], Loss: 0.0953\n",
      "Epoch [43/100], Step [44/56], Loss: 0.0902\n",
      "Epoch [43/100], Step [45/56], Loss: 0.0891\n",
      "Epoch [43/100], Step [46/56], Loss: 0.0614\n",
      "Epoch [43/100], Step [47/56], Loss: 0.2003\n",
      "Epoch [43/100], Step [48/56], Loss: 0.1191\n",
      "Epoch [43/100], Step [49/56], Loss: 0.0858\n",
      "Epoch [43/100], Step [50/56], Loss: 0.3186\n",
      "Epoch [43/100], Step [51/56], Loss: 0.0908\n",
      "Epoch [43/100], Step [52/56], Loss: 0.1044\n",
      "Epoch [43/100], Step [53/56], Loss: 0.1584\n",
      "Epoch [43/100], Step [54/56], Loss: 0.1586\n",
      "Epoch [43/100], Step [55/56], Loss: 0.2527\n",
      "Epoch [43/100], Step [56/56], Loss: 0.0258\n",
      "Val. loss :0.0926\n",
      "Epoch [44/100], Step [1/56], Loss: 0.1689\n",
      "Epoch [44/100], Step [2/56], Loss: 0.1015\n",
      "Epoch [44/100], Step [3/56], Loss: 0.1511\n",
      "Epoch [44/100], Step [4/56], Loss: 0.0973\n",
      "Epoch [44/100], Step [5/56], Loss: 0.0670\n",
      "Epoch [44/100], Step [6/56], Loss: 0.0757\n",
      "Epoch [44/100], Step [7/56], Loss: 0.0854\n",
      "Epoch [44/100], Step [8/56], Loss: 0.0885\n",
      "Epoch [44/100], Step [9/56], Loss: 0.0574\n",
      "Epoch [44/100], Step [10/56], Loss: 0.1056\n",
      "Epoch [44/100], Step [11/56], Loss: 0.0849\n",
      "Epoch [44/100], Step [12/56], Loss: 0.1621\n",
      "Epoch [44/100], Step [13/56], Loss: 0.0898\n",
      "Epoch [44/100], Step [14/56], Loss: 0.0803\n",
      "Epoch [44/100], Step [15/56], Loss: 0.0757\n",
      "Epoch [44/100], Step [16/56], Loss: 0.0857\n",
      "Epoch [44/100], Step [17/56], Loss: 0.2002\n",
      "Epoch [44/100], Step [18/56], Loss: 0.1426\n",
      "Epoch [44/100], Step [19/56], Loss: 0.1430\n",
      "Epoch [44/100], Step [20/56], Loss: 0.0660\n",
      "Epoch [44/100], Step [21/56], Loss: 0.1128\n",
      "Epoch [44/100], Step [22/56], Loss: 0.2939\n",
      "Epoch [44/100], Step [23/56], Loss: 0.2173\n",
      "Epoch [44/100], Step [24/56], Loss: 0.1557\n",
      "Epoch [44/100], Step [25/56], Loss: 0.0758\n",
      "Epoch [44/100], Step [26/56], Loss: 0.1296\n",
      "Epoch [44/100], Step [27/56], Loss: 0.2049\n",
      "Epoch [44/100], Step [28/56], Loss: 0.1075\n",
      "Epoch [44/100], Step [29/56], Loss: 0.1814\n",
      "Epoch [44/100], Step [30/56], Loss: 0.1381\n",
      "Epoch [44/100], Step [31/56], Loss: 0.1161\n",
      "Epoch [44/100], Step [32/56], Loss: 0.0732\n",
      "Epoch [44/100], Step [33/56], Loss: 0.1848\n",
      "Epoch [44/100], Step [34/56], Loss: 0.1152\n",
      "Epoch [44/100], Step [35/56], Loss: 0.0613\n",
      "Epoch [44/100], Step [36/56], Loss: 0.2729\n",
      "Epoch [44/100], Step [37/56], Loss: 0.0864\n",
      "Epoch [44/100], Step [38/56], Loss: 0.1440\n",
      "Epoch [44/100], Step [39/56], Loss: 0.1227\n",
      "Epoch [44/100], Step [40/56], Loss: 0.0893\n",
      "Epoch [44/100], Step [41/56], Loss: 0.2134\n",
      "Epoch [44/100], Step [42/56], Loss: 0.1425\n",
      "Epoch [44/100], Step [43/56], Loss: 0.1051\n",
      "Epoch [44/100], Step [44/56], Loss: 0.2044\n",
      "Epoch [44/100], Step [45/56], Loss: 0.0865\n",
      "Epoch [44/100], Step [46/56], Loss: 0.0986\n",
      "Epoch [44/100], Step [47/56], Loss: 0.1189\n",
      "Epoch [44/100], Step [48/56], Loss: 0.1687\n",
      "Epoch [44/100], Step [49/56], Loss: 0.1540\n",
      "Epoch [44/100], Step [50/56], Loss: 0.1497\n",
      "Epoch [44/100], Step [51/56], Loss: 0.2755\n",
      "Epoch [44/100], Step [52/56], Loss: 0.1268\n",
      "Epoch [44/100], Step [53/56], Loss: 0.1971\n",
      "Epoch [44/100], Step [54/56], Loss: 0.0925\n",
      "Epoch [44/100], Step [55/56], Loss: 0.1236\n",
      "Epoch [44/100], Step [56/56], Loss: 0.0769\n",
      "Val. loss :0.1293\n",
      "Epoch [45/100], Step [1/56], Loss: 0.1140\n",
      "Epoch [45/100], Step [2/56], Loss: 0.1210\n",
      "Epoch [45/100], Step [3/56], Loss: 0.1229\n",
      "Epoch [45/100], Step [4/56], Loss: 0.1214\n",
      "Epoch [45/100], Step [5/56], Loss: 0.0961\n",
      "Epoch [45/100], Step [6/56], Loss: 0.1346\n",
      "Epoch [45/100], Step [7/56], Loss: 0.1873\n",
      "Epoch [45/100], Step [8/56], Loss: 0.0832\n",
      "Epoch [45/100], Step [9/56], Loss: 0.1094\n",
      "Epoch [45/100], Step [10/56], Loss: 0.1257\n",
      "Epoch [45/100], Step [11/56], Loss: 0.1445\n",
      "Epoch [45/100], Step [12/56], Loss: 0.1540\n",
      "Epoch [45/100], Step [13/56], Loss: 0.1178\n",
      "Epoch [45/100], Step [14/56], Loss: 0.0688\n",
      "Epoch [45/100], Step [15/56], Loss: 0.0796\n",
      "Epoch [45/100], Step [16/56], Loss: 0.1280\n",
      "Epoch [45/100], Step [17/56], Loss: 0.1952\n",
      "Epoch [45/100], Step [18/56], Loss: 0.1063\n",
      "Epoch [45/100], Step [19/56], Loss: 0.1600\n",
      "Epoch [45/100], Step [20/56], Loss: 0.0768\n",
      "Epoch [45/100], Step [21/56], Loss: 0.0763\n",
      "Epoch [45/100], Step [22/56], Loss: 0.1015\n",
      "Epoch [45/100], Step [23/56], Loss: 0.1266\n",
      "Epoch [45/100], Step [24/56], Loss: 0.1116\n",
      "Epoch [45/100], Step [25/56], Loss: 0.1595\n",
      "Epoch [45/100], Step [26/56], Loss: 0.0852\n",
      "Epoch [45/100], Step [27/56], Loss: 0.1406\n",
      "Epoch [45/100], Step [28/56], Loss: 0.0747\n",
      "Epoch [45/100], Step [29/56], Loss: 0.0864\n",
      "Epoch [45/100], Step [30/56], Loss: 0.1462\n",
      "Epoch [45/100], Step [31/56], Loss: 0.2697\n",
      "Epoch [45/100], Step [32/56], Loss: 0.0774\n",
      "Epoch [45/100], Step [33/56], Loss: 0.1354\n",
      "Epoch [45/100], Step [34/56], Loss: 0.0957\n",
      "Epoch [45/100], Step [35/56], Loss: 0.0998\n",
      "Epoch [45/100], Step [36/56], Loss: 0.2759\n",
      "Epoch [45/100], Step [37/56], Loss: 0.0978\n",
      "Epoch [45/100], Step [38/56], Loss: 0.1288\n",
      "Epoch [45/100], Step [39/56], Loss: 0.1554\n",
      "Epoch [45/100], Step [40/56], Loss: 0.1536\n",
      "Epoch [45/100], Step [41/56], Loss: 0.1225\n",
      "Epoch [45/100], Step [42/56], Loss: 0.1434\n",
      "Epoch [45/100], Step [43/56], Loss: 0.0920\n",
      "Epoch [45/100], Step [44/56], Loss: 0.0677\n",
      "Epoch [45/100], Step [45/56], Loss: 0.1370\n",
      "Epoch [45/100], Step [46/56], Loss: 0.1268\n",
      "Epoch [45/100], Step [47/56], Loss: 0.1575\n",
      "Epoch [45/100], Step [48/56], Loss: 0.0676\n",
      "Epoch [45/100], Step [49/56], Loss: 0.0803\n",
      "Epoch [45/100], Step [50/56], Loss: 0.0895\n",
      "Epoch [45/100], Step [51/56], Loss: 0.1182\n",
      "Epoch [45/100], Step [52/56], Loss: 0.0589\n",
      "Epoch [45/100], Step [53/56], Loss: 0.1556\n",
      "Epoch [45/100], Step [54/56], Loss: 0.0645\n",
      "Epoch [45/100], Step [55/56], Loss: 0.0942\n",
      "Epoch [45/100], Step [56/56], Loss: 0.0358\n",
      "Val. loss :0.0879\n",
      "Epoch [46/100], Step [1/56], Loss: 0.3030\n",
      "Epoch [46/100], Step [2/56], Loss: 0.1064\n",
      "Epoch [46/100], Step [3/56], Loss: 0.1212\n",
      "Epoch [46/100], Step [4/56], Loss: 0.0770\n",
      "Epoch [46/100], Step [5/56], Loss: 0.0666\n",
      "Epoch [46/100], Step [6/56], Loss: 0.1198\n",
      "Epoch [46/100], Step [7/56], Loss: 0.1834\n",
      "Epoch [46/100], Step [8/56], Loss: 0.1113\n",
      "Epoch [46/100], Step [9/56], Loss: 0.1178\n",
      "Epoch [46/100], Step [10/56], Loss: 0.0533\n",
      "Epoch [46/100], Step [11/56], Loss: 0.0599\n",
      "Epoch [46/100], Step [12/56], Loss: 0.1739\n",
      "Epoch [46/100], Step [13/56], Loss: 0.0918\n",
      "Epoch [46/100], Step [14/56], Loss: 0.0857\n",
      "Epoch [46/100], Step [15/56], Loss: 0.2589\n",
      "Epoch [46/100], Step [16/56], Loss: 0.0806\n",
      "Epoch [46/100], Step [17/56], Loss: 0.1330\n",
      "Epoch [46/100], Step [18/56], Loss: 0.0745\n",
      "Epoch [46/100], Step [19/56], Loss: 0.0679\n",
      "Epoch [46/100], Step [20/56], Loss: 0.0548\n",
      "Epoch [46/100], Step [21/56], Loss: 0.1418\n",
      "Epoch [46/100], Step [22/56], Loss: 0.0662\n",
      "Epoch [46/100], Step [23/56], Loss: 0.0762\n",
      "Epoch [46/100], Step [24/56], Loss: 0.0676\n",
      "Epoch [46/100], Step [25/56], Loss: 0.1003\n",
      "Epoch [46/100], Step [26/56], Loss: 0.0565\n",
      "Epoch [46/100], Step [27/56], Loss: 0.0757\n",
      "Epoch [46/100], Step [28/56], Loss: 0.1119\n",
      "Epoch [46/100], Step [29/56], Loss: 0.1217\n",
      "Epoch [46/100], Step [30/56], Loss: 0.1508\n",
      "Epoch [46/100], Step [31/56], Loss: 0.1073\n",
      "Epoch [46/100], Step [32/56], Loss: 0.1050\n",
      "Epoch [46/100], Step [33/56], Loss: 0.0936\n",
      "Epoch [46/100], Step [34/56], Loss: 0.0913\n",
      "Epoch [46/100], Step [35/56], Loss: 0.0533\n",
      "Epoch [46/100], Step [36/56], Loss: 0.1194\n",
      "Epoch [46/100], Step [37/56], Loss: 0.1545\n",
      "Epoch [46/100], Step [38/56], Loss: 0.3336\n",
      "Epoch [46/100], Step [39/56], Loss: 0.0898\n",
      "Epoch [46/100], Step [40/56], Loss: 0.1235\n",
      "Epoch [46/100], Step [41/56], Loss: 0.1174\n",
      "Epoch [46/100], Step [42/56], Loss: 0.1742\n",
      "Epoch [46/100], Step [43/56], Loss: 0.1126\n",
      "Epoch [46/100], Step [44/56], Loss: 0.1070\n",
      "Epoch [46/100], Step [45/56], Loss: 0.1037\n",
      "Epoch [46/100], Step [46/56], Loss: 0.1180\n",
      "Epoch [46/100], Step [47/56], Loss: 0.1832\n",
      "Epoch [46/100], Step [48/56], Loss: 0.0856\n",
      "Epoch [46/100], Step [49/56], Loss: 0.1541\n",
      "Epoch [46/100], Step [50/56], Loss: 0.0523\n",
      "Epoch [46/100], Step [51/56], Loss: 0.0899\n",
      "Epoch [46/100], Step [52/56], Loss: 0.0850\n",
      "Epoch [46/100], Step [53/56], Loss: 0.1969\n",
      "Epoch [46/100], Step [54/56], Loss: 0.1191\n",
      "Epoch [46/100], Step [55/56], Loss: 0.0886\n",
      "Epoch [46/100], Step [56/56], Loss: 0.0292\n",
      "Val. loss :0.1384\n",
      "Epoch [47/100], Step [1/56], Loss: 0.1057\n",
      "Epoch [47/100], Step [2/56], Loss: 0.0681\n",
      "Epoch [47/100], Step [3/56], Loss: 0.0944\n",
      "Epoch [47/100], Step [4/56], Loss: 0.1161\n",
      "Epoch [47/100], Step [5/56], Loss: 0.0792\n",
      "Epoch [47/100], Step [6/56], Loss: 0.0476\n",
      "Epoch [47/100], Step [7/56], Loss: 0.0871\n",
      "Epoch [47/100], Step [8/56], Loss: 0.1305\n",
      "Epoch [47/100], Step [9/56], Loss: 0.0758\n",
      "Epoch [47/100], Step [10/56], Loss: 0.1089\n",
      "Epoch [47/100], Step [11/56], Loss: 0.1379\n",
      "Epoch [47/100], Step [12/56], Loss: 0.0690\n",
      "Epoch [47/100], Step [13/56], Loss: 0.0715\n",
      "Epoch [47/100], Step [14/56], Loss: 0.0524\n",
      "Epoch [47/100], Step [15/56], Loss: 0.1286\n",
      "Epoch [47/100], Step [16/56], Loss: 0.0934\n",
      "Epoch [47/100], Step [17/56], Loss: 0.0673\n",
      "Epoch [47/100], Step [18/56], Loss: 0.0680\n",
      "Epoch [47/100], Step [19/56], Loss: 0.1183\n",
      "Epoch [47/100], Step [20/56], Loss: 0.1233\n",
      "Epoch [47/100], Step [21/56], Loss: 0.0738\n",
      "Epoch [47/100], Step [22/56], Loss: 0.1419\n",
      "Epoch [47/100], Step [23/56], Loss: 0.0817\n",
      "Epoch [47/100], Step [24/56], Loss: 0.2377\n",
      "Epoch [47/100], Step [25/56], Loss: 0.3225\n",
      "Epoch [47/100], Step [26/56], Loss: 0.1631\n",
      "Epoch [47/100], Step [27/56], Loss: 0.1885\n",
      "Epoch [47/100], Step [28/56], Loss: 0.0770\n",
      "Epoch [47/100], Step [29/56], Loss: 0.0856\n",
      "Epoch [47/100], Step [30/56], Loss: 0.1371\n",
      "Epoch [47/100], Step [31/56], Loss: 0.1378\n",
      "Epoch [47/100], Step [32/56], Loss: 0.0708\n",
      "Epoch [47/100], Step [33/56], Loss: 0.1081\n",
      "Epoch [47/100], Step [34/56], Loss: 0.1379\n",
      "Epoch [47/100], Step [35/56], Loss: 0.0959\n",
      "Epoch [47/100], Step [36/56], Loss: 0.1331\n",
      "Epoch [47/100], Step [37/56], Loss: 0.0846\n",
      "Epoch [47/100], Step [38/56], Loss: 0.0689\n",
      "Epoch [47/100], Step [39/56], Loss: 0.0757\n",
      "Epoch [47/100], Step [40/56], Loss: 0.0761\n",
      "Epoch [47/100], Step [41/56], Loss: 0.2097\n",
      "Epoch [47/100], Step [42/56], Loss: 0.2209\n",
      "Epoch [47/100], Step [43/56], Loss: 0.0722\n",
      "Epoch [47/100], Step [44/56], Loss: 0.1581\n",
      "Epoch [47/100], Step [45/56], Loss: 0.0906\n",
      "Epoch [47/100], Step [46/56], Loss: 0.1210\n",
      "Epoch [47/100], Step [47/56], Loss: 0.0805\n",
      "Epoch [47/100], Step [48/56], Loss: 0.1597\n",
      "Epoch [47/100], Step [49/56], Loss: 0.1309\n",
      "Epoch [47/100], Step [50/56], Loss: 0.1015\n",
      "Epoch [47/100], Step [51/56], Loss: 0.1187\n",
      "Epoch [47/100], Step [52/56], Loss: 0.1238\n",
      "Epoch [47/100], Step [53/56], Loss: 0.1301\n",
      "Epoch [47/100], Step [54/56], Loss: 0.0694\n",
      "Epoch [47/100], Step [55/56], Loss: 0.1049\n",
      "Epoch [47/100], Step [56/56], Loss: 0.0587\n",
      "Val. loss :0.0738\n",
      "Epoch [48/100], Step [1/56], Loss: 0.0748\n",
      "Epoch [48/100], Step [2/56], Loss: 0.1062\n",
      "Epoch [48/100], Step [3/56], Loss: 0.1387\n",
      "Epoch [48/100], Step [4/56], Loss: 0.1255\n",
      "Epoch [48/100], Step [5/56], Loss: 0.0589\n",
      "Epoch [48/100], Step [6/56], Loss: 0.1256\n",
      "Epoch [48/100], Step [7/56], Loss: 0.0492\n",
      "Epoch [48/100], Step [8/56], Loss: 0.0436\n",
      "Epoch [48/100], Step [9/56], Loss: 0.3647\n",
      "Epoch [48/100], Step [10/56], Loss: 0.1113\n",
      "Epoch [48/100], Step [11/56], Loss: 0.0661\n",
      "Epoch [48/100], Step [12/56], Loss: 0.1065\n",
      "Epoch [48/100], Step [13/56], Loss: 0.1349\n",
      "Epoch [48/100], Step [14/56], Loss: 0.0814\n",
      "Epoch [48/100], Step [15/56], Loss: 0.0884\n",
      "Epoch [48/100], Step [16/56], Loss: 0.0781\n",
      "Epoch [48/100], Step [17/56], Loss: 0.1083\n",
      "Epoch [48/100], Step [18/56], Loss: 0.1363\n",
      "Epoch [48/100], Step [19/56], Loss: 0.1472\n",
      "Epoch [48/100], Step [20/56], Loss: 0.1157\n",
      "Epoch [48/100], Step [21/56], Loss: 0.0755\n",
      "Epoch [48/100], Step [22/56], Loss: 0.0734\n",
      "Epoch [48/100], Step [23/56], Loss: 0.1162\n",
      "Epoch [48/100], Step [24/56], Loss: 0.1473\n",
      "Epoch [48/100], Step [25/56], Loss: 0.1690\n",
      "Epoch [48/100], Step [26/56], Loss: 0.0790\n",
      "Epoch [48/100], Step [27/56], Loss: 0.0830\n",
      "Epoch [48/100], Step [28/56], Loss: 0.1402\n",
      "Epoch [48/100], Step [29/56], Loss: 0.1186\n",
      "Epoch [48/100], Step [30/56], Loss: 0.1123\n",
      "Epoch [48/100], Step [31/56], Loss: 0.0738\n",
      "Epoch [48/100], Step [32/56], Loss: 0.0681\n",
      "Epoch [48/100], Step [33/56], Loss: 0.0725\n",
      "Epoch [48/100], Step [34/56], Loss: 0.1154\n",
      "Epoch [48/100], Step [35/56], Loss: 0.1368\n",
      "Epoch [48/100], Step [36/56], Loss: 0.0736\n",
      "Epoch [48/100], Step [37/56], Loss: 0.1082\n",
      "Epoch [48/100], Step [38/56], Loss: 0.0661\n",
      "Epoch [48/100], Step [39/56], Loss: 0.2970\n",
      "Epoch [48/100], Step [40/56], Loss: 0.1300\n",
      "Epoch [48/100], Step [41/56], Loss: 0.0515\n",
      "Epoch [48/100], Step [42/56], Loss: 0.1792\n",
      "Epoch [48/100], Step [43/56], Loss: 0.1390\n",
      "Epoch [48/100], Step [44/56], Loss: 0.0905\n",
      "Epoch [48/100], Step [45/56], Loss: 0.0749\n",
      "Epoch [48/100], Step [46/56], Loss: 0.0835\n",
      "Epoch [48/100], Step [47/56], Loss: 0.1919\n",
      "Epoch [48/100], Step [48/56], Loss: 0.0880\n",
      "Epoch [48/100], Step [49/56], Loss: 0.0603\n",
      "Epoch [48/100], Step [50/56], Loss: 0.0621\n",
      "Epoch [48/100], Step [51/56], Loss: 0.1315\n",
      "Epoch [48/100], Step [52/56], Loss: 0.1681\n",
      "Epoch [48/100], Step [53/56], Loss: 0.1812\n",
      "Epoch [48/100], Step [54/56], Loss: 0.1379\n",
      "Epoch [48/100], Step [55/56], Loss: 0.2421\n",
      "Epoch [48/100], Step [56/56], Loss: 0.0296\n",
      "Val. loss :0.1229\n",
      "Epoch [49/100], Step [1/56], Loss: 0.0821\n",
      "Epoch [49/100], Step [2/56], Loss: 0.2009\n",
      "Epoch [49/100], Step [3/56], Loss: 0.0800\n",
      "Epoch [49/100], Step [4/56], Loss: 0.1011\n",
      "Epoch [49/100], Step [5/56], Loss: 0.0998\n",
      "Epoch [49/100], Step [6/56], Loss: 0.0608\n",
      "Epoch [49/100], Step [7/56], Loss: 0.0596\n",
      "Epoch [49/100], Step [8/56], Loss: 0.0678\n",
      "Epoch [49/100], Step [9/56], Loss: 0.0657\n",
      "Epoch [49/100], Step [10/56], Loss: 0.1210\n",
      "Epoch [49/100], Step [11/56], Loss: 0.1015\n",
      "Epoch [49/100], Step [12/56], Loss: 0.0842\n",
      "Epoch [49/100], Step [13/56], Loss: 0.0937\n",
      "Epoch [49/100], Step [14/56], Loss: 0.1135\n",
      "Epoch [49/100], Step [15/56], Loss: 0.0873\n",
      "Epoch [49/100], Step [16/56], Loss: 0.0610\n",
      "Epoch [49/100], Step [17/56], Loss: 0.0930\n",
      "Epoch [49/100], Step [18/56], Loss: 0.1243\n",
      "Epoch [49/100], Step [19/56], Loss: 0.0648\n",
      "Epoch [49/100], Step [20/56], Loss: 0.0868\n",
      "Epoch [49/100], Step [21/56], Loss: 0.0675\n",
      "Epoch [49/100], Step [22/56], Loss: 0.1132\n",
      "Epoch [49/100], Step [23/56], Loss: 0.1324\n",
      "Epoch [49/100], Step [24/56], Loss: 0.0897\n",
      "Epoch [49/100], Step [25/56], Loss: 0.0931\n",
      "Epoch [49/100], Step [26/56], Loss: 0.1567\n",
      "Epoch [49/100], Step [27/56], Loss: 0.0738\n",
      "Epoch [49/100], Step [28/56], Loss: 0.3291\n",
      "Epoch [49/100], Step [29/56], Loss: 0.0869\n",
      "Epoch [49/100], Step [30/56], Loss: 0.1158\n",
      "Epoch [49/100], Step [31/56], Loss: 0.1778\n",
      "Epoch [49/100], Step [32/56], Loss: 0.1408\n",
      "Epoch [49/100], Step [33/56], Loss: 0.0734\n",
      "Epoch [49/100], Step [34/56], Loss: 0.1173\n",
      "Epoch [49/100], Step [35/56], Loss: 0.2556\n",
      "Epoch [49/100], Step [36/56], Loss: 0.0887\n",
      "Epoch [49/100], Step [37/56], Loss: 0.1528\n",
      "Epoch [49/100], Step [38/56], Loss: 0.0838\n",
      "Epoch [49/100], Step [39/56], Loss: 0.0913\n",
      "Epoch [49/100], Step [40/56], Loss: 0.0504\n",
      "Epoch [49/100], Step [41/56], Loss: 0.1152\n",
      "Epoch [49/100], Step [42/56], Loss: 0.0593\n",
      "Epoch [49/100], Step [43/56], Loss: 0.0596\n",
      "Epoch [49/100], Step [44/56], Loss: 0.0907\n",
      "Epoch [49/100], Step [45/56], Loss: 0.1060\n",
      "Epoch [49/100], Step [46/56], Loss: 0.1574\n",
      "Epoch [49/100], Step [47/56], Loss: 0.1011\n",
      "Epoch [49/100], Step [48/56], Loss: 0.1012\n",
      "Epoch [49/100], Step [49/56], Loss: 0.0618\n",
      "Epoch [49/100], Step [50/56], Loss: 0.2329\n",
      "Epoch [49/100], Step [51/56], Loss: 0.1102\n",
      "Epoch [49/100], Step [52/56], Loss: 0.1528\n",
      "Epoch [49/100], Step [53/56], Loss: 0.0685\n",
      "Epoch [49/100], Step [54/56], Loss: 0.0816\n",
      "Epoch [49/100], Step [55/56], Loss: 0.0632\n",
      "Epoch [49/100], Step [56/56], Loss: 0.0333\n",
      "Val. loss :0.1019\n",
      "Epoch [50/100], Step [1/56], Loss: 0.1032\n",
      "Epoch [50/100], Step [2/56], Loss: 0.1294\n",
      "Epoch [50/100], Step [3/56], Loss: 0.2109\n",
      "Epoch [50/100], Step [4/56], Loss: 0.0890\n",
      "Epoch [50/100], Step [5/56], Loss: 0.0885\n",
      "Epoch [50/100], Step [6/56], Loss: 0.1978\n",
      "Epoch [50/100], Step [7/56], Loss: 0.1102\n",
      "Epoch [50/100], Step [8/56], Loss: 0.1951\n",
      "Epoch [50/100], Step [9/56], Loss: 0.0744\n",
      "Epoch [50/100], Step [10/56], Loss: 0.1016\n",
      "Epoch [50/100], Step [11/56], Loss: 0.0654\n",
      "Epoch [50/100], Step [12/56], Loss: 0.2242\n",
      "Epoch [50/100], Step [13/56], Loss: 0.2138\n",
      "Epoch [50/100], Step [14/56], Loss: 0.2005\n",
      "Epoch [50/100], Step [15/56], Loss: 0.0637\n",
      "Epoch [50/100], Step [16/56], Loss: 0.0917\n",
      "Epoch [50/100], Step [17/56], Loss: 0.1726\n",
      "Epoch [50/100], Step [18/56], Loss: 0.1204\n",
      "Epoch [50/100], Step [19/56], Loss: 0.0923\n",
      "Epoch [50/100], Step [20/56], Loss: 0.0984\n",
      "Epoch [50/100], Step [21/56], Loss: 0.1352\n",
      "Epoch [50/100], Step [22/56], Loss: 0.0773\n",
      "Epoch [50/100], Step [23/56], Loss: 0.1276\n",
      "Epoch [50/100], Step [24/56], Loss: 0.1434\n",
      "Epoch [50/100], Step [25/56], Loss: 0.1434\n",
      "Epoch [50/100], Step [26/56], Loss: 0.1462\n",
      "Epoch [50/100], Step [27/56], Loss: 0.2300\n",
      "Epoch [50/100], Step [28/56], Loss: 0.1366\n",
      "Epoch [50/100], Step [29/56], Loss: 0.1626\n",
      "Epoch [50/100], Step [30/56], Loss: 0.0763\n",
      "Epoch [50/100], Step [31/56], Loss: 0.0718\n",
      "Epoch [50/100], Step [32/56], Loss: 0.1537\n",
      "Epoch [50/100], Step [33/56], Loss: 0.1301\n",
      "Epoch [50/100], Step [34/56], Loss: 0.0816\n",
      "Epoch [50/100], Step [35/56], Loss: 0.0860\n",
      "Epoch [50/100], Step [36/56], Loss: 0.0715\n",
      "Epoch [50/100], Step [37/56], Loss: 0.0893\n",
      "Epoch [50/100], Step [38/56], Loss: 0.1335\n",
      "Epoch [50/100], Step [39/56], Loss: 0.1546\n",
      "Epoch [50/100], Step [40/56], Loss: 0.1305\n",
      "Epoch [50/100], Step [41/56], Loss: 0.1210\n",
      "Epoch [50/100], Step [42/56], Loss: 0.0613\n",
      "Epoch [50/100], Step [43/56], Loss: 0.1787\n",
      "Epoch [50/100], Step [44/56], Loss: 0.2307\n",
      "Epoch [50/100], Step [45/56], Loss: 0.1993\n",
      "Epoch [50/100], Step [46/56], Loss: 0.2729\n",
      "Epoch [50/100], Step [47/56], Loss: 0.1292\n",
      "Epoch [50/100], Step [48/56], Loss: 0.1186\n",
      "Epoch [50/100], Step [49/56], Loss: 0.1219\n",
      "Epoch [50/100], Step [50/56], Loss: 0.1075\n",
      "Epoch [50/100], Step [51/56], Loss: 0.1248\n",
      "Epoch [50/100], Step [52/56], Loss: 0.0865\n",
      "Epoch [50/100], Step [53/56], Loss: 0.1106\n",
      "Epoch [50/100], Step [54/56], Loss: 0.1268\n",
      "Epoch [50/100], Step [55/56], Loss: 0.1371\n",
      "Epoch [50/100], Step [56/56], Loss: 0.0521\n",
      "Val. loss :0.1300\n",
      "Epoch [51/100], Step [1/56], Loss: 0.2397\n",
      "Epoch [51/100], Step [2/56], Loss: 0.0761\n",
      "Epoch [51/100], Step [3/56], Loss: 0.0955\n",
      "Epoch [51/100], Step [4/56], Loss: 0.1046\n",
      "Epoch [51/100], Step [5/56], Loss: 0.1247\n",
      "Epoch [51/100], Step [6/56], Loss: 0.1277\n",
      "Epoch [51/100], Step [7/56], Loss: 0.1168\n",
      "Epoch [51/100], Step [8/56], Loss: 0.1136\n",
      "Epoch [51/100], Step [9/56], Loss: 0.1200\n",
      "Epoch [51/100], Step [10/56], Loss: 0.1815\n",
      "Epoch [51/100], Step [11/56], Loss: 0.1616\n",
      "Epoch [51/100], Step [12/56], Loss: 0.1175\n",
      "Epoch [51/100], Step [13/56], Loss: 0.0679\n",
      "Epoch [51/100], Step [14/56], Loss: 0.1155\n",
      "Epoch [51/100], Step [15/56], Loss: 0.0685\n",
      "Epoch [51/100], Step [16/56], Loss: 0.1606\n",
      "Epoch [51/100], Step [17/56], Loss: 0.0901\n",
      "Epoch [51/100], Step [18/56], Loss: 0.0865\n",
      "Epoch [51/100], Step [19/56], Loss: 0.0766\n",
      "Epoch [51/100], Step [20/56], Loss: 0.1024\n",
      "Epoch [51/100], Step [21/56], Loss: 0.3085\n",
      "Epoch [51/100], Step [22/56], Loss: 0.1975\n",
      "Epoch [51/100], Step [23/56], Loss: 0.2110\n",
      "Epoch [51/100], Step [24/56], Loss: 0.1939\n",
      "Epoch [51/100], Step [25/56], Loss: 0.1464\n",
      "Epoch [51/100], Step [26/56], Loss: 0.1428\n",
      "Epoch [51/100], Step [27/56], Loss: 0.1649\n",
      "Epoch [51/100], Step [28/56], Loss: 0.1407\n",
      "Epoch [51/100], Step [29/56], Loss: 0.1708\n",
      "Epoch [51/100], Step [30/56], Loss: 0.3373\n",
      "Epoch [51/100], Step [31/56], Loss: 0.1283\n",
      "Epoch [51/100], Step [32/56], Loss: 0.1746\n",
      "Epoch [51/100], Step [33/56], Loss: 0.2029\n",
      "Epoch [51/100], Step [34/56], Loss: 0.0943\n",
      "Epoch [51/100], Step [35/56], Loss: 0.1090\n",
      "Epoch [51/100], Step [36/56], Loss: 0.0838\n",
      "Epoch [51/100], Step [37/56], Loss: 0.1382\n",
      "Epoch [51/100], Step [38/56], Loss: 0.0975\n",
      "Epoch [51/100], Step [39/56], Loss: 0.2457\n",
      "Epoch [51/100], Step [40/56], Loss: 0.0912\n",
      "Epoch [51/100], Step [41/56], Loss: 0.0627\n",
      "Epoch [51/100], Step [42/56], Loss: 0.1367\n",
      "Epoch [51/100], Step [43/56], Loss: 0.2362\n",
      "Epoch [51/100], Step [44/56], Loss: 0.0717\n",
      "Epoch [51/100], Step [45/56], Loss: 0.0726\n",
      "Epoch [51/100], Step [46/56], Loss: 0.0865\n",
      "Epoch [51/100], Step [47/56], Loss: 0.2265\n",
      "Epoch [51/100], Step [48/56], Loss: 0.0698\n",
      "Epoch [51/100], Step [49/56], Loss: 0.0815\n",
      "Epoch [51/100], Step [50/56], Loss: 0.0844\n",
      "Epoch [51/100], Step [51/56], Loss: 0.1233\n",
      "Epoch [51/100], Step [52/56], Loss: 0.0715\n",
      "Epoch [51/100], Step [53/56], Loss: 0.0846\n",
      "Epoch [51/100], Step [54/56], Loss: 0.0788\n",
      "Epoch [51/100], Step [55/56], Loss: 0.1499\n",
      "Epoch [51/100], Step [56/56], Loss: 0.1521\n",
      "Val. loss :0.0897\n",
      "Epoch [52/100], Step [1/56], Loss: 0.1378\n",
      "Epoch [52/100], Step [2/56], Loss: 0.2410\n",
      "Epoch [52/100], Step [3/56], Loss: 0.0954\n",
      "Epoch [52/100], Step [4/56], Loss: 0.1605\n",
      "Epoch [52/100], Step [5/56], Loss: 0.1078\n",
      "Epoch [52/100], Step [6/56], Loss: 0.1052\n",
      "Epoch [52/100], Step [7/56], Loss: 0.0809\n",
      "Epoch [52/100], Step [8/56], Loss: 0.1041\n",
      "Epoch [52/100], Step [9/56], Loss: 0.0704\n",
      "Epoch [52/100], Step [10/56], Loss: 0.1032\n",
      "Epoch [52/100], Step [11/56], Loss: 0.0653\n",
      "Epoch [52/100], Step [12/56], Loss: 0.1195\n",
      "Epoch [52/100], Step [13/56], Loss: 0.0553\n",
      "Epoch [52/100], Step [14/56], Loss: 0.1301\n",
      "Epoch [52/100], Step [15/56], Loss: 0.1416\n",
      "Epoch [52/100], Step [16/56], Loss: 0.0699\n",
      "Epoch [52/100], Step [17/56], Loss: 0.0735\n",
      "Epoch [52/100], Step [18/56], Loss: 0.0932\n",
      "Epoch [52/100], Step [19/56], Loss: 0.1239\n",
      "Epoch [52/100], Step [20/56], Loss: 0.0563\n",
      "Epoch [52/100], Step [21/56], Loss: 0.0780\n",
      "Epoch [52/100], Step [22/56], Loss: 0.0989\n",
      "Epoch [52/100], Step [23/56], Loss: 0.0617\n",
      "Epoch [52/100], Step [24/56], Loss: 0.1185\n",
      "Epoch [52/100], Step [25/56], Loss: 0.1486\n",
      "Epoch [52/100], Step [26/56], Loss: 0.2260\n",
      "Epoch [52/100], Step [27/56], Loss: 0.0772\n",
      "Epoch [52/100], Step [28/56], Loss: 0.0942\n",
      "Epoch [52/100], Step [29/56], Loss: 0.2496\n",
      "Epoch [52/100], Step [30/56], Loss: 0.1055\n",
      "Epoch [52/100], Step [31/56], Loss: 0.0902\n",
      "Epoch [52/100], Step [32/56], Loss: 0.2043\n",
      "Epoch [52/100], Step [33/56], Loss: 0.1300\n",
      "Epoch [52/100], Step [34/56], Loss: 0.1536\n",
      "Epoch [52/100], Step [35/56], Loss: 0.3176\n",
      "Epoch [52/100], Step [36/56], Loss: 0.0588\n",
      "Epoch [52/100], Step [37/56], Loss: 0.1109\n",
      "Epoch [52/100], Step [38/56], Loss: 0.1472\n",
      "Epoch [52/100], Step [39/56], Loss: 0.1179\n",
      "Epoch [52/100], Step [40/56], Loss: 0.1672\n",
      "Epoch [52/100], Step [41/56], Loss: 0.0678\n",
      "Epoch [52/100], Step [42/56], Loss: 0.0878\n",
      "Epoch [52/100], Step [43/56], Loss: 0.1509\n",
      "Epoch [52/100], Step [44/56], Loss: 0.1146\n",
      "Epoch [52/100], Step [45/56], Loss: 0.1190\n",
      "Epoch [52/100], Step [46/56], Loss: 0.1348\n",
      "Epoch [52/100], Step [47/56], Loss: 0.2578\n",
      "Epoch [52/100], Step [48/56], Loss: 0.1452\n",
      "Epoch [52/100], Step [49/56], Loss: 0.2287\n",
      "Epoch [52/100], Step [50/56], Loss: 0.0877\n",
      "Epoch [52/100], Step [51/56], Loss: 0.1200\n",
      "Epoch [52/100], Step [52/56], Loss: 0.1244\n",
      "Epoch [52/100], Step [53/56], Loss: 0.2133\n",
      "Epoch [52/100], Step [54/56], Loss: 0.0840\n",
      "Epoch [52/100], Step [55/56], Loss: 0.0674\n",
      "Epoch [52/100], Step [56/56], Loss: 0.0587\n",
      "Val. loss :0.0947\n",
      "Epoch [53/100], Step [1/56], Loss: 0.1642\n",
      "Epoch [53/100], Step [2/56], Loss: 0.1063\n",
      "Epoch [53/100], Step [3/56], Loss: 0.0803\n",
      "Epoch [53/100], Step [4/56], Loss: 0.0557\n",
      "Epoch [53/100], Step [5/56], Loss: 0.1882\n",
      "Epoch [53/100], Step [6/56], Loss: 0.0557\n",
      "Epoch [53/100], Step [7/56], Loss: 0.0700\n",
      "Epoch [53/100], Step [8/56], Loss: 0.0787\n",
      "Epoch [53/100], Step [9/56], Loss: 0.0737\n",
      "Epoch [53/100], Step [10/56], Loss: 0.0646\n",
      "Epoch [53/100], Step [11/56], Loss: 0.0546\n",
      "Epoch [53/100], Step [12/56], Loss: 0.0697\n",
      "Epoch [53/100], Step [13/56], Loss: 0.1065\n",
      "Epoch [53/100], Step [14/56], Loss: 0.1024\n",
      "Epoch [53/100], Step [15/56], Loss: 0.1526\n",
      "Epoch [53/100], Step [16/56], Loss: 0.0812\n",
      "Epoch [53/100], Step [17/56], Loss: 0.0743\n",
      "Epoch [53/100], Step [18/56], Loss: 0.0876\n",
      "Epoch [53/100], Step [19/56], Loss: 0.1299\n",
      "Epoch [53/100], Step [20/56], Loss: 0.1451\n",
      "Epoch [53/100], Step [21/56], Loss: 0.0552\n",
      "Epoch [53/100], Step [22/56], Loss: 0.1309\n",
      "Epoch [53/100], Step [23/56], Loss: 0.1008\n",
      "Epoch [53/100], Step [24/56], Loss: 0.1528\n",
      "Epoch [53/100], Step [25/56], Loss: 0.2205\n",
      "Epoch [53/100], Step [26/56], Loss: 0.0760\n",
      "Epoch [53/100], Step [27/56], Loss: 0.1104\n",
      "Epoch [53/100], Step [28/56], Loss: 0.1358\n",
      "Epoch [53/100], Step [29/56], Loss: 0.1278\n",
      "Epoch [53/100], Step [30/56], Loss: 0.0552\n",
      "Epoch [53/100], Step [31/56], Loss: 0.2970\n",
      "Epoch [53/100], Step [32/56], Loss: 0.1052\n",
      "Epoch [53/100], Step [33/56], Loss: 0.1414\n",
      "Epoch [53/100], Step [34/56], Loss: 0.1648\n",
      "Epoch [53/100], Step [35/56], Loss: 0.1340\n",
      "Epoch [53/100], Step [36/56], Loss: 0.2432\n",
      "Epoch [53/100], Step [37/56], Loss: 0.1409\n",
      "Epoch [53/100], Step [38/56], Loss: 0.1091\n",
      "Epoch [53/100], Step [39/56], Loss: 0.2254\n",
      "Epoch [53/100], Step [40/56], Loss: 0.0959\n",
      "Epoch [53/100], Step [41/56], Loss: 0.1122\n",
      "Epoch [53/100], Step [42/56], Loss: 0.0894\n",
      "Epoch [53/100], Step [43/56], Loss: 0.1103\n",
      "Epoch [53/100], Step [44/56], Loss: 0.2631\n",
      "Epoch [53/100], Step [45/56], Loss: 0.1486\n",
      "Epoch [53/100], Step [46/56], Loss: 0.1465\n",
      "Epoch [53/100], Step [47/56], Loss: 0.2540\n",
      "Epoch [53/100], Step [48/56], Loss: 0.0986\n",
      "Epoch [53/100], Step [49/56], Loss: 0.0652\n",
      "Epoch [53/100], Step [50/56], Loss: 0.1016\n",
      "Epoch [53/100], Step [51/56], Loss: 0.1048\n",
      "Epoch [53/100], Step [52/56], Loss: 0.0757\n",
      "Epoch [53/100], Step [53/56], Loss: 0.0718\n",
      "Epoch [53/100], Step [54/56], Loss: 0.1635\n",
      "Epoch [53/100], Step [55/56], Loss: 0.1439\n",
      "Epoch [53/100], Step [56/56], Loss: 0.0433\n",
      "Val. loss :0.0723\n",
      "Epoch [54/100], Step [1/56], Loss: 0.0635\n",
      "Epoch [54/100], Step [2/56], Loss: 0.0902\n",
      "Epoch [54/100], Step [3/56], Loss: 0.0734\n",
      "Epoch [54/100], Step [4/56], Loss: 0.0746\n",
      "Epoch [54/100], Step [5/56], Loss: 0.0412\n",
      "Epoch [54/100], Step [6/56], Loss: 0.0750\n",
      "Epoch [54/100], Step [7/56], Loss: 0.0648\n",
      "Epoch [54/100], Step [8/56], Loss: 0.1049\n",
      "Epoch [54/100], Step [9/56], Loss: 0.1622\n",
      "Epoch [54/100], Step [10/56], Loss: 0.0589\n",
      "Epoch [54/100], Step [11/56], Loss: 0.1153\n",
      "Epoch [54/100], Step [12/56], Loss: 0.1946\n",
      "Epoch [54/100], Step [13/56], Loss: 0.0638\n",
      "Epoch [54/100], Step [14/56], Loss: 0.0538\n",
      "Epoch [54/100], Step [15/56], Loss: 0.0692\n",
      "Epoch [54/100], Step [16/56], Loss: 0.0795\n",
      "Epoch [54/100], Step [17/56], Loss: 0.0588\n",
      "Epoch [54/100], Step [18/56], Loss: 0.0602\n",
      "Epoch [54/100], Step [19/56], Loss: 0.1058\n",
      "Epoch [54/100], Step [20/56], Loss: 0.0592\n",
      "Epoch [54/100], Step [21/56], Loss: 0.1243\n",
      "Epoch [54/100], Step [22/56], Loss: 0.0620\n",
      "Epoch [54/100], Step [23/56], Loss: 0.1105\n",
      "Epoch [54/100], Step [24/56], Loss: 0.2176\n",
      "Epoch [54/100], Step [25/56], Loss: 0.1153\n",
      "Epoch [54/100], Step [26/56], Loss: 0.0649\n",
      "Epoch [54/100], Step [27/56], Loss: 0.0615\n",
      "Epoch [54/100], Step [28/56], Loss: 0.1439\n",
      "Epoch [54/100], Step [29/56], Loss: 0.0788\n",
      "Epoch [54/100], Step [30/56], Loss: 0.2369\n",
      "Epoch [54/100], Step [31/56], Loss: 0.1048\n",
      "Epoch [54/100], Step [32/56], Loss: 0.0724\n",
      "Epoch [54/100], Step [33/56], Loss: 0.1806\n",
      "Epoch [54/100], Step [34/56], Loss: 0.0921\n",
      "Epoch [54/100], Step [35/56], Loss: 0.1032\n",
      "Epoch [54/100], Step [36/56], Loss: 0.1154\n",
      "Epoch [54/100], Step [37/56], Loss: 0.0905\n",
      "Epoch [54/100], Step [38/56], Loss: 0.1429\n",
      "Epoch [54/100], Step [39/56], Loss: 0.0612\n",
      "Epoch [54/100], Step [40/56], Loss: 0.0690\n",
      "Epoch [54/100], Step [41/56], Loss: 0.1166\n",
      "Epoch [54/100], Step [42/56], Loss: 0.1049\n",
      "Epoch [54/100], Step [43/56], Loss: 0.0517\n",
      "Epoch [54/100], Step [44/56], Loss: 0.0657\n",
      "Epoch [54/100], Step [45/56], Loss: 0.0818\n",
      "Epoch [54/100], Step [46/56], Loss: 0.0734\n",
      "Epoch [54/100], Step [47/56], Loss: 0.1093\n",
      "Epoch [54/100], Step [48/56], Loss: 0.2055\n",
      "Epoch [54/100], Step [49/56], Loss: 0.1307\n",
      "Epoch [54/100], Step [50/56], Loss: 0.1009\n",
      "Epoch [54/100], Step [51/56], Loss: 0.1772\n",
      "Epoch [54/100], Step [52/56], Loss: 0.0677\n",
      "Epoch [54/100], Step [53/56], Loss: 0.1865\n",
      "Epoch [54/100], Step [54/56], Loss: 0.0678\n",
      "Epoch [54/100], Step [55/56], Loss: 0.0846\n",
      "Epoch [54/100], Step [56/56], Loss: 0.0280\n",
      "Val. loss :0.1041\n",
      "Epoch [55/100], Step [1/56], Loss: 0.2015\n",
      "Epoch [55/100], Step [2/56], Loss: 0.1438\n",
      "Epoch [55/100], Step [3/56], Loss: 0.0809\n",
      "Epoch [55/100], Step [4/56], Loss: 0.2533\n",
      "Epoch [55/100], Step [5/56], Loss: 0.1018\n",
      "Epoch [55/100], Step [6/56], Loss: 0.2215\n",
      "Epoch [55/100], Step [7/56], Loss: 0.1256\n",
      "Epoch [55/100], Step [8/56], Loss: 0.0851\n",
      "Epoch [55/100], Step [9/56], Loss: 0.0815\n",
      "Epoch [55/100], Step [10/56], Loss: 0.0611\n",
      "Epoch [55/100], Step [11/56], Loss: 0.0989\n",
      "Epoch [55/100], Step [12/56], Loss: 0.1185\n",
      "Epoch [55/100], Step [13/56], Loss: 0.0507\n",
      "Epoch [55/100], Step [14/56], Loss: 0.1136\n",
      "Epoch [55/100], Step [15/56], Loss: 0.1194\n",
      "Epoch [55/100], Step [16/56], Loss: 0.0575\n",
      "Epoch [55/100], Step [17/56], Loss: 0.0684\n",
      "Epoch [55/100], Step [18/56], Loss: 0.0718\n",
      "Epoch [55/100], Step [19/56], Loss: 0.1907\n",
      "Epoch [55/100], Step [20/56], Loss: 0.0611\n",
      "Epoch [55/100], Step [21/56], Loss: 0.0956\n",
      "Epoch [55/100], Step [22/56], Loss: 0.1012\n",
      "Epoch [55/100], Step [23/56], Loss: 0.0607\n",
      "Epoch [55/100], Step [24/56], Loss: 0.0749\n",
      "Epoch [55/100], Step [25/56], Loss: 0.0626\n",
      "Epoch [55/100], Step [26/56], Loss: 0.0589\n",
      "Epoch [55/100], Step [27/56], Loss: 0.0576\n",
      "Epoch [55/100], Step [28/56], Loss: 0.1712\n",
      "Epoch [55/100], Step [29/56], Loss: 0.1152\n",
      "Epoch [55/100], Step [30/56], Loss: 0.0825\n",
      "Epoch [55/100], Step [31/56], Loss: 0.0613\n",
      "Epoch [55/100], Step [32/56], Loss: 0.0616\n",
      "Epoch [55/100], Step [33/56], Loss: 0.0858\n",
      "Epoch [55/100], Step [34/56], Loss: 0.0580\n",
      "Epoch [55/100], Step [35/56], Loss: 0.1690\n",
      "Epoch [55/100], Step [36/56], Loss: 0.1347\n",
      "Epoch [55/100], Step [37/56], Loss: 0.0799\n",
      "Epoch [55/100], Step [38/56], Loss: 0.0664\n",
      "Epoch [55/100], Step [39/56], Loss: 0.0831\n",
      "Epoch [55/100], Step [40/56], Loss: 0.0760\n",
      "Epoch [55/100], Step [41/56], Loss: 0.0708\n",
      "Epoch [55/100], Step [42/56], Loss: 0.0619\n",
      "Epoch [55/100], Step [43/56], Loss: 0.3718\n",
      "Epoch [55/100], Step [44/56], Loss: 0.0733\n",
      "Epoch [55/100], Step [45/56], Loss: 0.1359\n",
      "Epoch [55/100], Step [46/56], Loss: 0.0778\n",
      "Epoch [55/100], Step [47/56], Loss: 0.1468\n",
      "Epoch [55/100], Step [48/56], Loss: 0.1029\n",
      "Epoch [55/100], Step [49/56], Loss: 0.0861\n",
      "Epoch [55/100], Step [50/56], Loss: 0.0818\n",
      "Epoch [55/100], Step [51/56], Loss: 0.1021\n",
      "Epoch [55/100], Step [52/56], Loss: 0.0945\n",
      "Epoch [55/100], Step [53/56], Loss: 0.1761\n",
      "Epoch [55/100], Step [54/56], Loss: 0.2726\n",
      "Epoch [55/100], Step [55/56], Loss: 0.0758\n",
      "Epoch [55/100], Step [56/56], Loss: 0.0589\n",
      "Val. loss :0.0723\n",
      "Epoch [56/100], Step [1/56], Loss: 0.0705\n",
      "Epoch [56/100], Step [2/56], Loss: 0.2274\n",
      "Epoch [56/100], Step [3/56], Loss: 0.1193\n",
      "Epoch [56/100], Step [4/56], Loss: 0.1901\n",
      "Epoch [56/100], Step [5/56], Loss: 0.1259\n",
      "Epoch [56/100], Step [6/56], Loss: 0.0989\n",
      "Epoch [56/100], Step [7/56], Loss: 0.0577\n",
      "Epoch [56/100], Step [8/56], Loss: 0.0908\n",
      "Epoch [56/100], Step [9/56], Loss: 0.0970\n",
      "Epoch [56/100], Step [10/56], Loss: 0.0539\n",
      "Epoch [56/100], Step [11/56], Loss: 0.1224\n",
      "Epoch [56/100], Step [12/56], Loss: 0.0873\n",
      "Epoch [56/100], Step [13/56], Loss: 0.0507\n",
      "Epoch [56/100], Step [14/56], Loss: 0.0594\n",
      "Epoch [56/100], Step [15/56], Loss: 0.1184\n",
      "Epoch [56/100], Step [16/56], Loss: 0.0914\n",
      "Epoch [56/100], Step [17/56], Loss: 0.1285\n",
      "Epoch [56/100], Step [18/56], Loss: 0.0563\n",
      "Epoch [56/100], Step [19/56], Loss: 0.0683\n",
      "Epoch [56/100], Step [20/56], Loss: 0.0843\n",
      "Epoch [56/100], Step [21/56], Loss: 0.0672\n",
      "Epoch [56/100], Step [22/56], Loss: 0.0806\n",
      "Epoch [56/100], Step [23/56], Loss: 0.0475\n",
      "Epoch [56/100], Step [24/56], Loss: 0.0692\n",
      "Epoch [56/100], Step [25/56], Loss: 0.1033\n",
      "Epoch [56/100], Step [26/56], Loss: 0.0767\n",
      "Epoch [56/100], Step [27/56], Loss: 0.1107\n",
      "Epoch [56/100], Step [28/56], Loss: 0.2511\n",
      "Epoch [56/100], Step [29/56], Loss: 0.0657\n",
      "Epoch [56/100], Step [30/56], Loss: 0.1706\n",
      "Epoch [56/100], Step [31/56], Loss: 0.1635\n",
      "Epoch [56/100], Step [32/56], Loss: 0.0578\n",
      "Epoch [56/100], Step [33/56], Loss: 0.0591\n",
      "Epoch [56/100], Step [34/56], Loss: 0.0565\n",
      "Epoch [56/100], Step [35/56], Loss: 0.1071\n",
      "Epoch [56/100], Step [36/56], Loss: 0.2503\n",
      "Epoch [56/100], Step [37/56], Loss: 0.1072\n",
      "Epoch [56/100], Step [38/56], Loss: 0.0690\n",
      "Epoch [56/100], Step [39/56], Loss: 0.0856\n",
      "Epoch [56/100], Step [40/56], Loss: 0.0960\n",
      "Epoch [56/100], Step [41/56], Loss: 0.0546\n",
      "Epoch [56/100], Step [42/56], Loss: 0.1266\n",
      "Epoch [56/100], Step [43/56], Loss: 0.0799\n",
      "Epoch [56/100], Step [44/56], Loss: 0.0678\n",
      "Epoch [56/100], Step [45/56], Loss: 0.0724\n",
      "Epoch [56/100], Step [46/56], Loss: 0.0951\n",
      "Epoch [56/100], Step [47/56], Loss: 0.1202\n",
      "Epoch [56/100], Step [48/56], Loss: 0.1454\n",
      "Epoch [56/100], Step [49/56], Loss: 0.1674\n",
      "Epoch [56/100], Step [50/56], Loss: 0.0445\n",
      "Epoch [56/100], Step [51/56], Loss: 0.0484\n",
      "Epoch [56/100], Step [52/56], Loss: 0.0737\n",
      "Epoch [56/100], Step [53/56], Loss: 0.1087\n",
      "Epoch [56/100], Step [54/56], Loss: 0.1152\n",
      "Epoch [56/100], Step [55/56], Loss: 0.0927\n",
      "Epoch [56/100], Step [56/56], Loss: 0.0279\n",
      "Val. loss :0.0744\n",
      "Epoch [57/100], Step [1/56], Loss: 0.0545\n",
      "Epoch [57/100], Step [2/56], Loss: 0.0673\n",
      "Epoch [57/100], Step [3/56], Loss: 0.0895\n",
      "Epoch [57/100], Step [4/56], Loss: 0.0436\n",
      "Epoch [57/100], Step [5/56], Loss: 0.0555\n",
      "Epoch [57/100], Step [6/56], Loss: 0.0949\n",
      "Epoch [57/100], Step [7/56], Loss: 0.0482\n",
      "Epoch [57/100], Step [8/56], Loss: 0.0908\n",
      "Epoch [57/100], Step [9/56], Loss: 0.0848\n",
      "Epoch [57/100], Step [10/56], Loss: 0.0569\n",
      "Epoch [57/100], Step [11/56], Loss: 0.0838\n",
      "Epoch [57/100], Step [12/56], Loss: 0.0877\n",
      "Epoch [57/100], Step [13/56], Loss: 0.0999\n",
      "Epoch [57/100], Step [14/56], Loss: 0.0489\n",
      "Epoch [57/100], Step [15/56], Loss: 0.0848\n",
      "Epoch [57/100], Step [16/56], Loss: 0.1788\n",
      "Epoch [57/100], Step [17/56], Loss: 0.1210\n",
      "Epoch [57/100], Step [18/56], Loss: 0.0677\n",
      "Epoch [57/100], Step [19/56], Loss: 0.1961\n",
      "Epoch [57/100], Step [20/56], Loss: 0.0815\n",
      "Epoch [57/100], Step [21/56], Loss: 0.1414\n",
      "Epoch [57/100], Step [22/56], Loss: 0.0737\n",
      "Epoch [57/100], Step [23/56], Loss: 0.0632\n",
      "Epoch [57/100], Step [24/56], Loss: 0.0938\n",
      "Epoch [57/100], Step [25/56], Loss: 0.0911\n",
      "Epoch [57/100], Step [26/56], Loss: 0.0554\n",
      "Epoch [57/100], Step [27/56], Loss: 0.0634\n",
      "Epoch [57/100], Step [28/56], Loss: 0.0818\n",
      "Epoch [57/100], Step [29/56], Loss: 0.1855\n",
      "Epoch [57/100], Step [30/56], Loss: 0.1976\n",
      "Epoch [57/100], Step [31/56], Loss: 0.0989\n",
      "Epoch [57/100], Step [32/56], Loss: 0.0744\n",
      "Epoch [57/100], Step [33/56], Loss: 0.0768\n",
      "Epoch [57/100], Step [34/56], Loss: 0.1903\n",
      "Epoch [57/100], Step [35/56], Loss: 0.2880\n",
      "Epoch [57/100], Step [36/56], Loss: 0.0614\n",
      "Epoch [57/100], Step [37/56], Loss: 0.0660\n",
      "Epoch [57/100], Step [38/56], Loss: 0.1322\n",
      "Epoch [57/100], Step [39/56], Loss: 0.1795\n",
      "Epoch [57/100], Step [40/56], Loss: 0.0792\n",
      "Epoch [57/100], Step [41/56], Loss: 0.0554\n",
      "Epoch [57/100], Step [42/56], Loss: 0.1169\n",
      "Epoch [57/100], Step [43/56], Loss: 0.0663\n",
      "Epoch [57/100], Step [44/56], Loss: 0.0596\n",
      "Epoch [57/100], Step [45/56], Loss: 0.2565\n",
      "Epoch [57/100], Step [46/56], Loss: 0.0743\n",
      "Epoch [57/100], Step [47/56], Loss: 0.0700\n",
      "Epoch [57/100], Step [48/56], Loss: 0.0875\n",
      "Epoch [57/100], Step [49/56], Loss: 0.0623\n",
      "Epoch [57/100], Step [50/56], Loss: 0.0572\n",
      "Epoch [57/100], Step [51/56], Loss: 0.1047\n",
      "Epoch [57/100], Step [52/56], Loss: 0.1944\n",
      "Epoch [57/100], Step [53/56], Loss: 0.0530\n",
      "Epoch [57/100], Step [54/56], Loss: 0.0812\n",
      "Epoch [57/100], Step [55/56], Loss: 0.1028\n",
      "Epoch [57/100], Step [56/56], Loss: 0.0330\n",
      "Val. loss :0.0811\n",
      "Epoch [58/100], Step [1/56], Loss: 0.1227\n",
      "Epoch [58/100], Step [2/56], Loss: 0.0528\n",
      "Epoch [58/100], Step [3/56], Loss: 0.0868\n",
      "Epoch [58/100], Step [4/56], Loss: 0.0551\n",
      "Epoch [58/100], Step [5/56], Loss: 0.1593\n",
      "Epoch [58/100], Step [6/56], Loss: 0.0410\n",
      "Epoch [58/100], Step [7/56], Loss: 0.1063\n",
      "Epoch [58/100], Step [8/56], Loss: 0.0625\n",
      "Epoch [58/100], Step [9/56], Loss: 0.0689\n",
      "Epoch [58/100], Step [10/56], Loss: 0.0537\n",
      "Epoch [58/100], Step [11/56], Loss: 0.1250\n",
      "Epoch [58/100], Step [12/56], Loss: 0.1909\n",
      "Epoch [58/100], Step [13/56], Loss: 0.0732\n",
      "Epoch [58/100], Step [14/56], Loss: 0.1318\n",
      "Epoch [58/100], Step [15/56], Loss: 0.0607\n",
      "Epoch [58/100], Step [16/56], Loss: 0.1013\n",
      "Epoch [58/100], Step [17/56], Loss: 0.0836\n",
      "Epoch [58/100], Step [18/56], Loss: 0.0642\n",
      "Epoch [58/100], Step [19/56], Loss: 0.0639\n",
      "Epoch [58/100], Step [20/56], Loss: 0.0444\n",
      "Epoch [58/100], Step [21/56], Loss: 0.0708\n",
      "Epoch [58/100], Step [22/56], Loss: 0.0474\n",
      "Epoch [58/100], Step [23/56], Loss: 0.0745\n",
      "Epoch [58/100], Step [24/56], Loss: 0.1075\n",
      "Epoch [58/100], Step [25/56], Loss: 0.0507\n",
      "Epoch [58/100], Step [26/56], Loss: 0.0515\n",
      "Epoch [58/100], Step [27/56], Loss: 0.1910\n",
      "Epoch [58/100], Step [28/56], Loss: 0.0911\n",
      "Epoch [58/100], Step [29/56], Loss: 0.0650\n",
      "Epoch [58/100], Step [30/56], Loss: 0.4747\n",
      "Epoch [58/100], Step [31/56], Loss: 0.0698\n",
      "Epoch [58/100], Step [32/56], Loss: 0.0748\n",
      "Epoch [58/100], Step [33/56], Loss: 0.0819\n",
      "Epoch [58/100], Step [34/56], Loss: 0.1783\n",
      "Epoch [58/100], Step [35/56], Loss: 0.0628\n",
      "Epoch [58/100], Step [36/56], Loss: 0.2473\n",
      "Epoch [58/100], Step [37/56], Loss: 0.0709\n",
      "Epoch [58/100], Step [38/56], Loss: 0.0854\n",
      "Epoch [58/100], Step [39/56], Loss: 0.1364\n",
      "Epoch [58/100], Step [40/56], Loss: 0.1399\n",
      "Epoch [58/100], Step [41/56], Loss: 0.0942\n",
      "Epoch [58/100], Step [42/56], Loss: 0.0732\n",
      "Epoch [58/100], Step [43/56], Loss: 0.2515\n",
      "Epoch [58/100], Step [44/56], Loss: 0.0794\n",
      "Epoch [58/100], Step [45/56], Loss: 0.0638\n",
      "Epoch [58/100], Step [46/56], Loss: 0.3620\n",
      "Epoch [58/100], Step [47/56], Loss: 0.1643\n",
      "Epoch [58/100], Step [48/56], Loss: 0.1701\n",
      "Epoch [58/100], Step [49/56], Loss: 0.0640\n",
      "Epoch [58/100], Step [50/56], Loss: 0.3300\n",
      "Epoch [58/100], Step [51/56], Loss: 0.1361\n",
      "Epoch [58/100], Step [52/56], Loss: 0.0884\n",
      "Epoch [58/100], Step [53/56], Loss: 0.1402\n",
      "Epoch [58/100], Step [54/56], Loss: 0.1044\n",
      "Epoch [58/100], Step [55/56], Loss: 0.1735\n",
      "Epoch [58/100], Step [56/56], Loss: 0.1859\n",
      "Val. loss :0.1134\n",
      "Epoch [59/100], Step [1/56], Loss: 0.1214\n",
      "Epoch [59/100], Step [2/56], Loss: 0.1562\n",
      "Epoch [59/100], Step [3/56], Loss: 0.0571\n",
      "Epoch [59/100], Step [4/56], Loss: 0.1504\n",
      "Epoch [59/100], Step [5/56], Loss: 0.1783\n",
      "Epoch [59/100], Step [6/56], Loss: 0.1241\n",
      "Epoch [59/100], Step [7/56], Loss: 0.1177\n",
      "Epoch [59/100], Step [8/56], Loss: 0.1897\n",
      "Epoch [59/100], Step [9/56], Loss: 0.1363\n",
      "Epoch [59/100], Step [10/56], Loss: 0.1096\n",
      "Epoch [59/100], Step [11/56], Loss: 0.1987\n",
      "Epoch [59/100], Step [12/56], Loss: 0.0950\n",
      "Epoch [59/100], Step [13/56], Loss: 0.1014\n",
      "Epoch [59/100], Step [14/56], Loss: 0.0573\n",
      "Epoch [59/100], Step [15/56], Loss: 0.1082\n",
      "Epoch [59/100], Step [16/56], Loss: 0.0596\n",
      "Epoch [59/100], Step [17/56], Loss: 0.1608\n",
      "Epoch [59/100], Step [18/56], Loss: 0.0559\n",
      "Epoch [59/100], Step [19/56], Loss: 0.0984\n",
      "Epoch [59/100], Step [20/56], Loss: 0.0800\n",
      "Epoch [59/100], Step [21/56], Loss: 0.0511\n",
      "Epoch [59/100], Step [22/56], Loss: 0.0953\n",
      "Epoch [59/100], Step [23/56], Loss: 0.0984\n",
      "Epoch [59/100], Step [24/56], Loss: 0.0660\n",
      "Epoch [59/100], Step [25/56], Loss: 0.0915\n",
      "Epoch [59/100], Step [26/56], Loss: 0.2166\n",
      "Epoch [59/100], Step [27/56], Loss: 0.1356\n",
      "Epoch [59/100], Step [28/56], Loss: 0.0631\n",
      "Epoch [59/100], Step [29/56], Loss: 0.0997\n",
      "Epoch [59/100], Step [30/56], Loss: 0.0690\n",
      "Epoch [59/100], Step [31/56], Loss: 0.0602\n",
      "Epoch [59/100], Step [32/56], Loss: 0.1029\n",
      "Epoch [59/100], Step [33/56], Loss: 0.0679\n",
      "Epoch [59/100], Step [34/56], Loss: 0.0717\n",
      "Epoch [59/100], Step [35/56], Loss: 0.0685\n",
      "Epoch [59/100], Step [36/56], Loss: 0.1060\n",
      "Epoch [59/100], Step [37/56], Loss: 0.1118\n",
      "Epoch [59/100], Step [38/56], Loss: 0.0832\n",
      "Epoch [59/100], Step [39/56], Loss: 0.1378\n",
      "Epoch [59/100], Step [40/56], Loss: 0.0826\n",
      "Epoch [59/100], Step [41/56], Loss: 0.0709\n",
      "Epoch [59/100], Step [42/56], Loss: 0.0594\n",
      "Epoch [59/100], Step [43/56], Loss: 0.1304\n",
      "Epoch [59/100], Step [44/56], Loss: 0.1887\n",
      "Epoch [59/100], Step [45/56], Loss: 0.0477\n",
      "Epoch [59/100], Step [46/56], Loss: 0.0948\n",
      "Epoch [59/100], Step [47/56], Loss: 0.0597\n",
      "Epoch [59/100], Step [48/56], Loss: 0.0479\n",
      "Epoch [59/100], Step [49/56], Loss: 0.1446\n",
      "Epoch [59/100], Step [50/56], Loss: 0.2903\n",
      "Epoch [59/100], Step [51/56], Loss: 0.0508\n",
      "Epoch [59/100], Step [52/56], Loss: 0.1619\n",
      "Epoch [59/100], Step [53/56], Loss: 0.0692\n",
      "Epoch [59/100], Step [54/56], Loss: 0.0518\n",
      "Epoch [59/100], Step [55/56], Loss: 0.1908\n",
      "Epoch [59/100], Step [56/56], Loss: 0.2515\n",
      "Val. loss :0.0900\n",
      "Epoch [60/100], Step [1/56], Loss: 0.1452\n",
      "Epoch [60/100], Step [2/56], Loss: 0.1439\n",
      "Epoch [60/100], Step [3/56], Loss: 0.0980\n",
      "Epoch [60/100], Step [4/56], Loss: 0.1159\n",
      "Epoch [60/100], Step [5/56], Loss: 0.1338\n",
      "Epoch [60/100], Step [6/56], Loss: 0.3124\n",
      "Epoch [60/100], Step [7/56], Loss: 0.0997\n",
      "Epoch [60/100], Step [8/56], Loss: 0.1793\n",
      "Epoch [60/100], Step [9/56], Loss: 0.2896\n",
      "Epoch [60/100], Step [10/56], Loss: 0.0575\n",
      "Epoch [60/100], Step [11/56], Loss: 0.1992\n",
      "Epoch [60/100], Step [12/56], Loss: 0.0834\n",
      "Epoch [60/100], Step [13/56], Loss: 0.1047\n",
      "Epoch [60/100], Step [14/56], Loss: 0.2178\n",
      "Epoch [60/100], Step [15/56], Loss: 0.0788\n",
      "Epoch [60/100], Step [16/56], Loss: 0.1303\n",
      "Epoch [60/100], Step [17/56], Loss: 0.1783\n",
      "Epoch [60/100], Step [18/56], Loss: 0.0838\n",
      "Epoch [60/100], Step [19/56], Loss: 0.0912\n",
      "Epoch [60/100], Step [20/56], Loss: 0.0810\n",
      "Epoch [60/100], Step [21/56], Loss: 0.0596\n",
      "Epoch [60/100], Step [22/56], Loss: 0.0811\n",
      "Epoch [60/100], Step [23/56], Loss: 0.2466\n",
      "Epoch [60/100], Step [24/56], Loss: 0.2709\n",
      "Epoch [60/100], Step [25/56], Loss: 0.0628\n",
      "Epoch [60/100], Step [26/56], Loss: 0.0973\n",
      "Epoch [60/100], Step [27/56], Loss: 0.0812\n",
      "Epoch [60/100], Step [28/56], Loss: 0.1607\n",
      "Epoch [60/100], Step [29/56], Loss: 0.0677\n",
      "Epoch [60/100], Step [30/56], Loss: 0.1823\n",
      "Epoch [60/100], Step [31/56], Loss: 0.0996\n",
      "Epoch [60/100], Step [32/56], Loss: 0.0890\n",
      "Epoch [60/100], Step [33/56], Loss: 0.1312\n",
      "Epoch [60/100], Step [34/56], Loss: 0.0683\n",
      "Epoch [60/100], Step [35/56], Loss: 0.0708\n",
      "Epoch [60/100], Step [36/56], Loss: 0.0683\n",
      "Epoch [60/100], Step [37/56], Loss: 0.2380\n",
      "Epoch [60/100], Step [38/56], Loss: 0.2265\n",
      "Epoch [60/100], Step [39/56], Loss: 0.0714\n",
      "Epoch [60/100], Step [40/56], Loss: 0.0540\n",
      "Epoch [60/100], Step [41/56], Loss: 0.1134\n",
      "Epoch [60/100], Step [42/56], Loss: 0.1340\n",
      "Epoch [60/100], Step [43/56], Loss: 0.1246\n",
      "Epoch [60/100], Step [44/56], Loss: 0.0808\n",
      "Epoch [60/100], Step [45/56], Loss: 0.1980\n",
      "Epoch [60/100], Step [46/56], Loss: 0.0815\n",
      "Epoch [60/100], Step [47/56], Loss: 0.2133\n",
      "Epoch [60/100], Step [48/56], Loss: 0.0547\n",
      "Epoch [60/100], Step [49/56], Loss: 0.0932\n",
      "Epoch [60/100], Step [50/56], Loss: 0.0929\n",
      "Epoch [60/100], Step [51/56], Loss: 0.0899\n",
      "Epoch [60/100], Step [52/56], Loss: 0.1163\n",
      "Epoch [60/100], Step [53/56], Loss: 0.1690\n",
      "Epoch [60/100], Step [54/56], Loss: 0.0805\n",
      "Epoch [60/100], Step [55/56], Loss: 0.0896\n",
      "Epoch [60/100], Step [56/56], Loss: 0.0394\n",
      "Val. loss :0.1398\n",
      "Epoch [61/100], Step [1/56], Loss: 0.2383\n",
      "Epoch [61/100], Step [2/56], Loss: 0.1542\n",
      "Epoch [61/100], Step [3/56], Loss: 0.1228\n",
      "Epoch [61/100], Step [4/56], Loss: 0.1276\n",
      "Epoch [61/100], Step [5/56], Loss: 0.0786\n",
      "Epoch [61/100], Step [6/56], Loss: 0.1137\n",
      "Epoch [61/100], Step [7/56], Loss: 0.0654\n",
      "Epoch [61/100], Step [8/56], Loss: 0.0812\n",
      "Epoch [61/100], Step [9/56], Loss: 0.2335\n",
      "Epoch [61/100], Step [10/56], Loss: 0.0599\n",
      "Epoch [61/100], Step [11/56], Loss: 0.0638\n",
      "Epoch [61/100], Step [12/56], Loss: 0.2985\n",
      "Epoch [61/100], Step [13/56], Loss: 0.0832\n",
      "Epoch [61/100], Step [14/56], Loss: 0.0754\n",
      "Epoch [61/100], Step [15/56], Loss: 0.0846\n",
      "Epoch [61/100], Step [16/56], Loss: 0.1198\n",
      "Epoch [61/100], Step [17/56], Loss: 0.0928\n",
      "Epoch [61/100], Step [18/56], Loss: 0.0834\n",
      "Epoch [61/100], Step [19/56], Loss: 0.0505\n",
      "Epoch [61/100], Step [20/56], Loss: 0.0784\n",
      "Epoch [61/100], Step [21/56], Loss: 0.1110\n",
      "Epoch [61/100], Step [22/56], Loss: 0.0487\n",
      "Epoch [61/100], Step [23/56], Loss: 0.0555\n",
      "Epoch [61/100], Step [24/56], Loss: 0.0508\n",
      "Epoch [61/100], Step [25/56], Loss: 0.2035\n",
      "Epoch [61/100], Step [26/56], Loss: 0.2094\n",
      "Epoch [61/100], Step [27/56], Loss: 0.1822\n",
      "Epoch [61/100], Step [28/56], Loss: 0.0755\n",
      "Epoch [61/100], Step [29/56], Loss: 0.0800\n",
      "Epoch [61/100], Step [30/56], Loss: 0.1074\n",
      "Epoch [61/100], Step [31/56], Loss: 0.0819\n",
      "Epoch [61/100], Step [32/56], Loss: 0.0892\n",
      "Epoch [61/100], Step [33/56], Loss: 0.1185\n",
      "Epoch [61/100], Step [34/56], Loss: 0.0644\n",
      "Epoch [61/100], Step [35/56], Loss: 0.0903\n",
      "Epoch [61/100], Step [36/56], Loss: 0.1109\n",
      "Epoch [61/100], Step [37/56], Loss: 0.1573\n",
      "Epoch [61/100], Step [38/56], Loss: 0.1382\n",
      "Epoch [61/100], Step [39/56], Loss: 0.0622\n",
      "Epoch [61/100], Step [40/56], Loss: 0.0969\n",
      "Epoch [61/100], Step [41/56], Loss: 0.1358\n",
      "Epoch [61/100], Step [42/56], Loss: 0.0601\n",
      "Epoch [61/100], Step [43/56], Loss: 0.1044\n",
      "Epoch [61/100], Step [44/56], Loss: 0.3107\n",
      "Epoch [61/100], Step [45/56], Loss: 0.0494\n",
      "Epoch [61/100], Step [46/56], Loss: 0.0568\n",
      "Epoch [61/100], Step [47/56], Loss: 0.0837\n",
      "Epoch [61/100], Step [48/56], Loss: 0.0665\n",
      "Epoch [61/100], Step [49/56], Loss: 0.1190\n",
      "Epoch [61/100], Step [50/56], Loss: 0.1234\n",
      "Epoch [61/100], Step [51/56], Loss: 0.1037\n",
      "Epoch [61/100], Step [52/56], Loss: 0.1318\n",
      "Epoch [61/100], Step [53/56], Loss: 0.0900\n",
      "Epoch [61/100], Step [54/56], Loss: 0.1467\n",
      "Epoch [61/100], Step [55/56], Loss: 0.0514\n",
      "Epoch [61/100], Step [56/56], Loss: 0.0520\n",
      "Val. loss :0.0932\n",
      "Epoch [62/100], Step [1/56], Loss: 0.0822\n",
      "Epoch [62/100], Step [2/56], Loss: 0.0726\n",
      "Epoch [62/100], Step [3/56], Loss: 0.0906\n",
      "Epoch [62/100], Step [4/56], Loss: 0.1747\n",
      "Epoch [62/100], Step [5/56], Loss: 0.0726\n",
      "Epoch [62/100], Step [6/56], Loss: 0.0761\n",
      "Epoch [62/100], Step [7/56], Loss: 0.1781\n",
      "Epoch [62/100], Step [8/56], Loss: 0.0861\n",
      "Epoch [62/100], Step [9/56], Loss: 0.0942\n",
      "Epoch [62/100], Step [10/56], Loss: 0.0826\n",
      "Epoch [62/100], Step [11/56], Loss: 0.0878\n",
      "Epoch [62/100], Step [12/56], Loss: 0.0773\n",
      "Epoch [62/100], Step [13/56], Loss: 0.0801\n",
      "Epoch [62/100], Step [14/56], Loss: 0.0924\n",
      "Epoch [62/100], Step [15/56], Loss: 0.0640\n",
      "Epoch [62/100], Step [16/56], Loss: 0.1318\n",
      "Epoch [62/100], Step [17/56], Loss: 0.0849\n",
      "Epoch [62/100], Step [18/56], Loss: 0.1695\n",
      "Epoch [62/100], Step [19/56], Loss: 0.0546\n",
      "Epoch [62/100], Step [20/56], Loss: 0.0939\n",
      "Epoch [62/100], Step [21/56], Loss: 0.0550\n",
      "Epoch [62/100], Step [22/56], Loss: 0.0656\n",
      "Epoch [62/100], Step [23/56], Loss: 0.0624\n",
      "Epoch [62/100], Step [24/56], Loss: 0.0603\n",
      "Epoch [62/100], Step [25/56], Loss: 0.0756\n",
      "Epoch [62/100], Step [26/56], Loss: 0.0471\n",
      "Epoch [62/100], Step [27/56], Loss: 0.0565\n",
      "Epoch [62/100], Step [28/56], Loss: 0.1701\n",
      "Epoch [62/100], Step [29/56], Loss: 0.1012\n",
      "Epoch [62/100], Step [30/56], Loss: 0.1469\n",
      "Epoch [62/100], Step [31/56], Loss: 0.0863\n",
      "Epoch [62/100], Step [32/56], Loss: 0.2199\n",
      "Epoch [62/100], Step [33/56], Loss: 0.0850\n",
      "Epoch [62/100], Step [34/56], Loss: 0.0803\n",
      "Epoch [62/100], Step [35/56], Loss: 0.0537\n",
      "Epoch [62/100], Step [36/56], Loss: 0.1449\n",
      "Epoch [62/100], Step [37/56], Loss: 0.1111\n",
      "Epoch [62/100], Step [38/56], Loss: 0.0970\n",
      "Epoch [62/100], Step [39/56], Loss: 0.0856\n",
      "Epoch [62/100], Step [40/56], Loss: 0.0530\n",
      "Epoch [62/100], Step [41/56], Loss: 0.1359\n",
      "Epoch [62/100], Step [42/56], Loss: 0.0653\n",
      "Epoch [62/100], Step [43/56], Loss: 0.1180\n",
      "Epoch [62/100], Step [44/56], Loss: 0.0819\n",
      "Epoch [62/100], Step [45/56], Loss: 0.0789\n",
      "Epoch [62/100], Step [46/56], Loss: 0.0974\n",
      "Epoch [62/100], Step [47/56], Loss: 0.0409\n",
      "Epoch [62/100], Step [48/56], Loss: 0.0517\n",
      "Epoch [62/100], Step [49/56], Loss: 0.0673\n",
      "Epoch [62/100], Step [50/56], Loss: 0.0630\n",
      "Epoch [62/100], Step [51/56], Loss: 0.0984\n",
      "Epoch [62/100], Step [52/56], Loss: 0.1198\n",
      "Epoch [62/100], Step [53/56], Loss: 0.0907\n",
      "Epoch [62/100], Step [54/56], Loss: 0.0849\n",
      "Epoch [62/100], Step [55/56], Loss: 0.0486\n",
      "Epoch [62/100], Step [56/56], Loss: 0.0187\n",
      "Val. loss :0.0632\n",
      "Epoch [63/100], Step [1/56], Loss: 0.2623\n",
      "Epoch [63/100], Step [2/56], Loss: 0.0632\n",
      "Epoch [63/100], Step [3/56], Loss: 0.1209\n",
      "Epoch [63/100], Step [4/56], Loss: 0.1094\n",
      "Epoch [63/100], Step [5/56], Loss: 0.0669\n",
      "Epoch [63/100], Step [6/56], Loss: 0.0689\n",
      "Epoch [63/100], Step [7/56], Loss: 0.0884\n",
      "Epoch [63/100], Step [8/56], Loss: 0.1234\n",
      "Epoch [63/100], Step [9/56], Loss: 0.0558\n",
      "Epoch [63/100], Step [10/56], Loss: 0.0947\n",
      "Epoch [63/100], Step [11/56], Loss: 0.0494\n",
      "Epoch [63/100], Step [12/56], Loss: 0.2181\n",
      "Epoch [63/100], Step [13/56], Loss: 0.0583\n",
      "Epoch [63/100], Step [14/56], Loss: 0.0568\n",
      "Epoch [63/100], Step [15/56], Loss: 0.0756\n",
      "Epoch [63/100], Step [16/56], Loss: 0.0564\n",
      "Epoch [63/100], Step [17/56], Loss: 0.0819\n",
      "Epoch [63/100], Step [18/56], Loss: 0.2384\n",
      "Epoch [63/100], Step [19/56], Loss: 0.1093\n",
      "Epoch [63/100], Step [20/56], Loss: 0.0446\n",
      "Epoch [63/100], Step [21/56], Loss: 0.1982\n",
      "Epoch [63/100], Step [22/56], Loss: 0.0701\n",
      "Epoch [63/100], Step [23/56], Loss: 0.0991\n",
      "Epoch [63/100], Step [24/56], Loss: 0.0846\n",
      "Epoch [63/100], Step [25/56], Loss: 0.0809\n",
      "Epoch [63/100], Step [26/56], Loss: 0.0814\n",
      "Epoch [63/100], Step [27/56], Loss: 0.0657\n",
      "Epoch [63/100], Step [28/56], Loss: 0.0637\n",
      "Epoch [63/100], Step [29/56], Loss: 0.0920\n",
      "Epoch [63/100], Step [30/56], Loss: 0.0469\n",
      "Epoch [63/100], Step [31/56], Loss: 0.0813\n",
      "Epoch [63/100], Step [32/56], Loss: 0.0509\n",
      "Epoch [63/100], Step [33/56], Loss: 0.0701\n",
      "Epoch [63/100], Step [34/56], Loss: 0.0785\n",
      "Epoch [63/100], Step [35/56], Loss: 0.0965\n",
      "Epoch [63/100], Step [36/56], Loss: 0.0653\n",
      "Epoch [63/100], Step [37/56], Loss: 0.1838\n",
      "Epoch [63/100], Step [38/56], Loss: 0.0582\n",
      "Epoch [63/100], Step [39/56], Loss: 0.0783\n",
      "Epoch [63/100], Step [40/56], Loss: 0.0758\n",
      "Epoch [63/100], Step [41/56], Loss: 0.0710\n",
      "Epoch [63/100], Step [42/56], Loss: 0.0803\n",
      "Epoch [63/100], Step [43/56], Loss: 0.0531\n",
      "Epoch [63/100], Step [44/56], Loss: 0.0359\n",
      "Epoch [63/100], Step [45/56], Loss: 0.0662\n",
      "Epoch [63/100], Step [46/56], Loss: 0.1188\n",
      "Epoch [63/100], Step [47/56], Loss: 0.1058\n",
      "Epoch [63/100], Step [48/56], Loss: 0.0458\n",
      "Epoch [63/100], Step [49/56], Loss: 0.0759\n",
      "Epoch [63/100], Step [50/56], Loss: 0.0694\n",
      "Epoch [63/100], Step [51/56], Loss: 0.0547\n",
      "Epoch [63/100], Step [52/56], Loss: 0.0755\n",
      "Epoch [63/100], Step [53/56], Loss: 0.0581\n",
      "Epoch [63/100], Step [54/56], Loss: 0.0679\n",
      "Epoch [63/100], Step [55/56], Loss: 0.0460\n",
      "Epoch [63/100], Step [56/56], Loss: 0.0455\n",
      "Val. loss :0.0856\n",
      "Epoch [64/100], Step [1/56], Loss: 0.0489\n",
      "Epoch [64/100], Step [2/56], Loss: 0.1299\n",
      "Epoch [64/100], Step [3/56], Loss: 0.1049\n",
      "Epoch [64/100], Step [4/56], Loss: 0.0503\n",
      "Epoch [64/100], Step [5/56], Loss: 0.0851\n",
      "Epoch [64/100], Step [6/56], Loss: 0.0705\n",
      "Epoch [64/100], Step [7/56], Loss: 0.0520\n",
      "Epoch [64/100], Step [8/56], Loss: 0.0458\n",
      "Epoch [64/100], Step [9/56], Loss: 0.1051\n",
      "Epoch [64/100], Step [10/56], Loss: 0.0855\n",
      "Epoch [64/100], Step [11/56], Loss: 0.2471\n",
      "Epoch [64/100], Step [12/56], Loss: 0.0837\n",
      "Epoch [64/100], Step [13/56], Loss: 0.1552\n",
      "Epoch [64/100], Step [14/56], Loss: 0.0894\n",
      "Epoch [64/100], Step [15/56], Loss: 0.0467\n",
      "Epoch [64/100], Step [16/56], Loss: 0.0637\n",
      "Epoch [64/100], Step [17/56], Loss: 0.0938\n",
      "Epoch [64/100], Step [18/56], Loss: 0.1125\n",
      "Epoch [64/100], Step [19/56], Loss: 0.1350\n",
      "Epoch [64/100], Step [20/56], Loss: 0.1219\n",
      "Epoch [64/100], Step [21/56], Loss: 0.0593\n",
      "Epoch [64/100], Step [22/56], Loss: 0.0735\n",
      "Epoch [64/100], Step [23/56], Loss: 0.0645\n",
      "Epoch [64/100], Step [24/56], Loss: 0.2031\n",
      "Epoch [64/100], Step [25/56], Loss: 0.0769\n",
      "Epoch [64/100], Step [26/56], Loss: 0.0711\n",
      "Epoch [64/100], Step [27/56], Loss: 0.0778\n",
      "Epoch [64/100], Step [28/56], Loss: 0.0746\n",
      "Epoch [64/100], Step [29/56], Loss: 0.0705\n",
      "Epoch [64/100], Step [30/56], Loss: 0.0895\n",
      "Epoch [64/100], Step [31/56], Loss: 0.0731\n",
      "Epoch [64/100], Step [32/56], Loss: 0.1643\n",
      "Epoch [64/100], Step [33/56], Loss: 0.0742\n",
      "Epoch [64/100], Step [34/56], Loss: 0.0570\n",
      "Epoch [64/100], Step [35/56], Loss: 0.0787\n",
      "Epoch [64/100], Step [36/56], Loss: 0.0430\n",
      "Epoch [64/100], Step [37/56], Loss: 0.0575\n",
      "Epoch [64/100], Step [38/56], Loss: 0.1010\n",
      "Epoch [64/100], Step [39/56], Loss: 0.1342\n",
      "Epoch [64/100], Step [40/56], Loss: 0.0477\n",
      "Epoch [64/100], Step [41/56], Loss: 0.1204\n",
      "Epoch [64/100], Step [42/56], Loss: 0.0787\n",
      "Epoch [64/100], Step [43/56], Loss: 0.1367\n",
      "Epoch [64/100], Step [44/56], Loss: 0.0596\n",
      "Epoch [64/100], Step [45/56], Loss: 0.0807\n",
      "Epoch [64/100], Step [46/56], Loss: 0.0947\n",
      "Epoch [64/100], Step [47/56], Loss: 0.0479\n",
      "Epoch [64/100], Step [48/56], Loss: 0.1702\n",
      "Epoch [64/100], Step [49/56], Loss: 0.1377\n",
      "Epoch [64/100], Step [50/56], Loss: 0.0748\n",
      "Epoch [64/100], Step [51/56], Loss: 0.0880\n",
      "Epoch [64/100], Step [52/56], Loss: 0.0492\n",
      "Epoch [64/100], Step [53/56], Loss: 0.0587\n",
      "Epoch [64/100], Step [54/56], Loss: 0.0767\n",
      "Epoch [64/100], Step [55/56], Loss: 0.0729\n",
      "Epoch [64/100], Step [56/56], Loss: 0.0315\n",
      "Val. loss :0.0691\n",
      "Epoch [65/100], Step [1/56], Loss: 0.1711\n",
      "Epoch [65/100], Step [2/56], Loss: 0.0535\n",
      "Epoch [65/100], Step [3/56], Loss: 0.2602\n",
      "Epoch [65/100], Step [4/56], Loss: 0.0763\n",
      "Epoch [65/100], Step [5/56], Loss: 0.0834\n",
      "Epoch [65/100], Step [6/56], Loss: 0.0633\n",
      "Epoch [65/100], Step [7/56], Loss: 0.1165\n",
      "Epoch [65/100], Step [8/56], Loss: 0.0474\n",
      "Epoch [65/100], Step [9/56], Loss: 0.0571\n",
      "Epoch [65/100], Step [10/56], Loss: 0.0737\n",
      "Epoch [65/100], Step [11/56], Loss: 0.0760\n",
      "Epoch [65/100], Step [12/56], Loss: 0.0458\n",
      "Epoch [65/100], Step [13/56], Loss: 0.0572\n",
      "Epoch [65/100], Step [14/56], Loss: 0.1409\n",
      "Epoch [65/100], Step [15/56], Loss: 0.0609\n",
      "Epoch [65/100], Step [16/56], Loss: 0.0566\n",
      "Epoch [65/100], Step [17/56], Loss: 0.1727\n",
      "Epoch [65/100], Step [18/56], Loss: 0.1246\n",
      "Epoch [65/100], Step [19/56], Loss: 0.0436\n",
      "Epoch [65/100], Step [20/56], Loss: 0.1048\n",
      "Epoch [65/100], Step [21/56], Loss: 0.1824\n",
      "Epoch [65/100], Step [22/56], Loss: 0.0601\n",
      "Epoch [65/100], Step [23/56], Loss: 0.0535\n",
      "Epoch [65/100], Step [24/56], Loss: 0.1089\n",
      "Epoch [65/100], Step [25/56], Loss: 0.0869\n",
      "Epoch [65/100], Step [26/56], Loss: 0.1609\n",
      "Epoch [65/100], Step [27/56], Loss: 0.1514\n",
      "Epoch [65/100], Step [28/56], Loss: 0.1056\n",
      "Epoch [65/100], Step [29/56], Loss: 0.0892\n",
      "Epoch [65/100], Step [30/56], Loss: 0.0975\n",
      "Epoch [65/100], Step [31/56], Loss: 0.1135\n",
      "Epoch [65/100], Step [32/56], Loss: 0.0457\n",
      "Epoch [65/100], Step [33/56], Loss: 0.0836\n",
      "Epoch [65/100], Step [34/56], Loss: 0.1290\n",
      "Epoch [65/100], Step [35/56], Loss: 0.1466\n",
      "Epoch [65/100], Step [36/56], Loss: 0.0795\n",
      "Epoch [65/100], Step [37/56], Loss: 0.0426\n",
      "Epoch [65/100], Step [38/56], Loss: 0.0640\n",
      "Epoch [65/100], Step [39/56], Loss: 0.0795\n",
      "Epoch [65/100], Step [40/56], Loss: 0.1576\n",
      "Epoch [65/100], Step [41/56], Loss: 0.0529\n",
      "Epoch [65/100], Step [42/56], Loss: 0.0504\n",
      "Epoch [65/100], Step [43/56], Loss: 0.0925\n",
      "Epoch [65/100], Step [44/56], Loss: 0.1176\n",
      "Epoch [65/100], Step [45/56], Loss: 0.0863\n",
      "Epoch [65/100], Step [46/56], Loss: 0.1579\n",
      "Epoch [65/100], Step [47/56], Loss: 0.1536\n",
      "Epoch [65/100], Step [48/56], Loss: 0.0595\n",
      "Epoch [65/100], Step [49/56], Loss: 0.1067\n",
      "Epoch [65/100], Step [50/56], Loss: 0.1409\n",
      "Epoch [65/100], Step [51/56], Loss: 0.0698\n",
      "Epoch [65/100], Step [52/56], Loss: 0.1668\n",
      "Epoch [65/100], Step [53/56], Loss: 0.0640\n",
      "Epoch [65/100], Step [54/56], Loss: 0.1466\n",
      "Epoch [65/100], Step [55/56], Loss: 0.0568\n",
      "Epoch [65/100], Step [56/56], Loss: 0.0326\n",
      "Val. loss :0.0732\n",
      "Epoch [66/100], Step [1/56], Loss: 0.0681\n",
      "Epoch [66/100], Step [2/56], Loss: 0.1138\n",
      "Epoch [66/100], Step [3/56], Loss: 0.0598\n",
      "Epoch [66/100], Step [4/56], Loss: 0.0612\n",
      "Epoch [66/100], Step [5/56], Loss: 0.0764\n",
      "Epoch [66/100], Step [6/56], Loss: 0.1382\n",
      "Epoch [66/100], Step [7/56], Loss: 0.1035\n",
      "Epoch [66/100], Step [8/56], Loss: 0.1085\n",
      "Epoch [66/100], Step [9/56], Loss: 0.0729\n",
      "Epoch [66/100], Step [10/56], Loss: 0.0748\n",
      "Epoch [66/100], Step [11/56], Loss: 0.0944\n",
      "Epoch [66/100], Step [12/56], Loss: 0.0608\n",
      "Epoch [66/100], Step [13/56], Loss: 0.0903\n",
      "Epoch [66/100], Step [14/56], Loss: 0.0489\n",
      "Epoch [66/100], Step [15/56], Loss: 0.0458\n",
      "Epoch [66/100], Step [16/56], Loss: 0.0733\n",
      "Epoch [66/100], Step [17/56], Loss: 0.1618\n",
      "Epoch [66/100], Step [18/56], Loss: 0.0718\n",
      "Epoch [66/100], Step [19/56], Loss: 0.0989\n",
      "Epoch [66/100], Step [20/56], Loss: 0.0542\n",
      "Epoch [66/100], Step [21/56], Loss: 0.0618\n",
      "Epoch [66/100], Step [22/56], Loss: 0.0628\n",
      "Epoch [66/100], Step [23/56], Loss: 0.0948\n",
      "Epoch [66/100], Step [24/56], Loss: 0.1502\n",
      "Epoch [66/100], Step [25/56], Loss: 0.0609\n",
      "Epoch [66/100], Step [26/56], Loss: 0.1412\n",
      "Epoch [66/100], Step [27/56], Loss: 0.0981\n",
      "Epoch [66/100], Step [28/56], Loss: 0.0635\n",
      "Epoch [66/100], Step [29/56], Loss: 0.0931\n",
      "Epoch [66/100], Step [30/56], Loss: 0.1247\n",
      "Epoch [66/100], Step [31/56], Loss: 0.1847\n",
      "Epoch [66/100], Step [32/56], Loss: 0.0761\n",
      "Epoch [66/100], Step [33/56], Loss: 0.0675\n",
      "Epoch [66/100], Step [34/56], Loss: 0.0730\n",
      "Epoch [66/100], Step [35/56], Loss: 0.0583\n",
      "Epoch [66/100], Step [36/56], Loss: 0.0994\n",
      "Epoch [66/100], Step [37/56], Loss: 0.0839\n",
      "Epoch [66/100], Step [38/56], Loss: 0.0574\n",
      "Epoch [66/100], Step [39/56], Loss: 0.0694\n",
      "Epoch [66/100], Step [40/56], Loss: 0.1176\n",
      "Epoch [66/100], Step [41/56], Loss: 0.0661\n",
      "Epoch [66/100], Step [42/56], Loss: 0.0409\n",
      "Epoch [66/100], Step [43/56], Loss: 0.1323\n",
      "Epoch [66/100], Step [44/56], Loss: 0.1002\n",
      "Epoch [66/100], Step [45/56], Loss: 0.0730\n",
      "Epoch [66/100], Step [46/56], Loss: 0.0577\n",
      "Epoch [66/100], Step [47/56], Loss: 0.0498\n",
      "Epoch [66/100], Step [48/56], Loss: 0.0817\n",
      "Epoch [66/100], Step [49/56], Loss: 0.1030\n",
      "Epoch [66/100], Step [50/56], Loss: 0.0610\n",
      "Epoch [66/100], Step [51/56], Loss: 0.1322\n",
      "Epoch [66/100], Step [52/56], Loss: 0.2151\n",
      "Epoch [66/100], Step [53/56], Loss: 0.0665\n",
      "Epoch [66/100], Step [54/56], Loss: 0.0770\n",
      "Epoch [66/100], Step [55/56], Loss: 0.0982\n",
      "Epoch [66/100], Step [56/56], Loss: 0.0240\n",
      "Val. loss :0.0970\n",
      "Epoch [67/100], Step [1/56], Loss: 0.0680\n",
      "Epoch [67/100], Step [2/56], Loss: 0.0595\n",
      "Epoch [67/100], Step [3/56], Loss: 0.0805\n",
      "Epoch [67/100], Step [4/56], Loss: 0.0693\n",
      "Epoch [67/100], Step [5/56], Loss: 0.1347\n",
      "Epoch [67/100], Step [6/56], Loss: 0.0881\n",
      "Epoch [67/100], Step [7/56], Loss: 0.0692\n",
      "Epoch [67/100], Step [8/56], Loss: 0.1106\n",
      "Epoch [67/100], Step [9/56], Loss: 0.1033\n",
      "Epoch [67/100], Step [10/56], Loss: 0.2283\n",
      "Epoch [67/100], Step [11/56], Loss: 0.1245\n",
      "Epoch [67/100], Step [12/56], Loss: 0.0462\n",
      "Epoch [67/100], Step [13/56], Loss: 0.2218\n",
      "Epoch [67/100], Step [14/56], Loss: 0.1823\n",
      "Epoch [67/100], Step [15/56], Loss: 0.0742\n",
      "Epoch [67/100], Step [16/56], Loss: 0.0651\n",
      "Epoch [67/100], Step [17/56], Loss: 0.1991\n",
      "Epoch [67/100], Step [18/56], Loss: 0.0661\n",
      "Epoch [67/100], Step [19/56], Loss: 0.0754\n",
      "Epoch [67/100], Step [20/56], Loss: 0.0790\n",
      "Epoch [67/100], Step [21/56], Loss: 0.1450\n",
      "Epoch [67/100], Step [22/56], Loss: 0.0862\n",
      "Epoch [67/100], Step [23/56], Loss: 0.0705\n",
      "Epoch [67/100], Step [24/56], Loss: 0.0583\n",
      "Epoch [67/100], Step [25/56], Loss: 0.0664\n",
      "Epoch [67/100], Step [26/56], Loss: 0.0604\n",
      "Epoch [67/100], Step [27/56], Loss: 0.0673\n",
      "Epoch [67/100], Step [28/56], Loss: 0.2458\n",
      "Epoch [67/100], Step [29/56], Loss: 0.1328\n",
      "Epoch [67/100], Step [30/56], Loss: 0.0511\n",
      "Epoch [67/100], Step [31/56], Loss: 0.0503\n",
      "Epoch [67/100], Step [32/56], Loss: 0.0844\n",
      "Epoch [67/100], Step [33/56], Loss: 0.1349\n",
      "Epoch [67/100], Step [34/56], Loss: 0.1080\n",
      "Epoch [67/100], Step [35/56], Loss: 0.0461\n",
      "Epoch [67/100], Step [36/56], Loss: 0.1956\n",
      "Epoch [67/100], Step [37/56], Loss: 0.0685\n",
      "Epoch [67/100], Step [38/56], Loss: 0.0855\n",
      "Epoch [67/100], Step [39/56], Loss: 0.0765\n",
      "Epoch [67/100], Step [40/56], Loss: 0.0931\n",
      "Epoch [67/100], Step [41/56], Loss: 0.0732\n",
      "Epoch [67/100], Step [42/56], Loss: 0.1522\n",
      "Epoch [67/100], Step [43/56], Loss: 0.0602\n",
      "Epoch [67/100], Step [44/56], Loss: 0.0650\n",
      "Epoch [67/100], Step [45/56], Loss: 0.0783\n",
      "Epoch [67/100], Step [46/56], Loss: 0.0767\n",
      "Epoch [67/100], Step [47/56], Loss: 0.1066\n",
      "Epoch [67/100], Step [48/56], Loss: 0.0522\n",
      "Epoch [67/100], Step [49/56], Loss: 0.1337\n",
      "Epoch [67/100], Step [50/56], Loss: 0.0715\n",
      "Epoch [67/100], Step [51/56], Loss: 0.1800\n",
      "Epoch [67/100], Step [52/56], Loss: 0.0690\n",
      "Epoch [67/100], Step [53/56], Loss: 0.0607\n",
      "Epoch [67/100], Step [54/56], Loss: 0.0484\n",
      "Epoch [67/100], Step [55/56], Loss: 0.1543\n",
      "Epoch [67/100], Step [56/56], Loss: 0.0229\n",
      "Val. loss :0.0836\n",
      "Epoch [68/100], Step [1/56], Loss: 0.0908\n",
      "Epoch [68/100], Step [2/56], Loss: 0.0624\n",
      "Epoch [68/100], Step [3/56], Loss: 0.0484\n",
      "Epoch [68/100], Step [4/56], Loss: 0.0951\n",
      "Epoch [68/100], Step [5/56], Loss: 0.0634\n",
      "Epoch [68/100], Step [6/56], Loss: 0.0565\n",
      "Epoch [68/100], Step [7/56], Loss: 0.0853\n",
      "Epoch [68/100], Step [8/56], Loss: 0.0496\n",
      "Epoch [68/100], Step [9/56], Loss: 0.1393\n",
      "Epoch [68/100], Step [10/56], Loss: 0.1332\n",
      "Epoch [68/100], Step [11/56], Loss: 0.0521\n",
      "Epoch [68/100], Step [12/56], Loss: 0.0959\n",
      "Epoch [68/100], Step [13/56], Loss: 0.0521\n",
      "Epoch [68/100], Step [14/56], Loss: 0.0571\n",
      "Epoch [68/100], Step [15/56], Loss: 0.0751\n",
      "Epoch [68/100], Step [16/56], Loss: 0.0468\n",
      "Epoch [68/100], Step [17/56], Loss: 0.0445\n",
      "Epoch [68/100], Step [18/56], Loss: 0.1361\n",
      "Epoch [68/100], Step [19/56], Loss: 0.0934\n",
      "Epoch [68/100], Step [20/56], Loss: 0.0943\n",
      "Epoch [68/100], Step [21/56], Loss: 0.0497\n",
      "Epoch [68/100], Step [22/56], Loss: 0.0892\n",
      "Epoch [68/100], Step [23/56], Loss: 0.0947\n",
      "Epoch [68/100], Step [24/56], Loss: 0.0640\n",
      "Epoch [68/100], Step [25/56], Loss: 0.1857\n",
      "Epoch [68/100], Step [26/56], Loss: 0.1209\n",
      "Epoch [68/100], Step [27/56], Loss: 0.0549\n",
      "Epoch [68/100], Step [28/56], Loss: 0.1531\n",
      "Epoch [68/100], Step [29/56], Loss: 0.0815\n",
      "Epoch [68/100], Step [30/56], Loss: 0.0531\n",
      "Epoch [68/100], Step [31/56], Loss: 0.0660\n",
      "Epoch [68/100], Step [32/56], Loss: 0.1590\n",
      "Epoch [68/100], Step [33/56], Loss: 0.1285\n",
      "Epoch [68/100], Step [34/56], Loss: 0.1198\n",
      "Epoch [68/100], Step [35/56], Loss: 0.0765\n",
      "Epoch [68/100], Step [36/56], Loss: 0.0725\n",
      "Epoch [68/100], Step [37/56], Loss: 0.0845\n",
      "Epoch [68/100], Step [38/56], Loss: 0.0891\n",
      "Epoch [68/100], Step [39/56], Loss: 0.0667\n",
      "Epoch [68/100], Step [40/56], Loss: 0.1252\n",
      "Epoch [68/100], Step [41/56], Loss: 0.0871\n",
      "Epoch [68/100], Step [42/56], Loss: 0.0961\n",
      "Epoch [68/100], Step [43/56], Loss: 0.1171\n",
      "Epoch [68/100], Step [44/56], Loss: 0.2797\n",
      "Epoch [68/100], Step [45/56], Loss: 0.1024\n",
      "Epoch [68/100], Step [46/56], Loss: 0.0812\n",
      "Epoch [68/100], Step [47/56], Loss: 0.0800\n",
      "Epoch [68/100], Step [48/56], Loss: 0.0591\n",
      "Epoch [68/100], Step [49/56], Loss: 0.1318\n",
      "Epoch [68/100], Step [50/56], Loss: 0.0735\n",
      "Epoch [68/100], Step [51/56], Loss: 0.2556\n",
      "Epoch [68/100], Step [52/56], Loss: 0.0521\n",
      "Epoch [68/100], Step [53/56], Loss: 0.0662\n",
      "Epoch [68/100], Step [54/56], Loss: 0.0658\n",
      "Epoch [68/100], Step [55/56], Loss: 0.0551\n",
      "Epoch [68/100], Step [56/56], Loss: 0.0244\n",
      "Val. loss :0.0729\n",
      "Epoch [69/100], Step [1/56], Loss: 0.0575\n",
      "Epoch [69/100], Step [2/56], Loss: 0.1177\n",
      "Epoch [69/100], Step [3/56], Loss: 0.0807\n",
      "Epoch [69/100], Step [4/56], Loss: 0.0499\n",
      "Epoch [69/100], Step [5/56], Loss: 0.1174\n",
      "Epoch [69/100], Step [6/56], Loss: 0.1429\n",
      "Epoch [69/100], Step [7/56], Loss: 0.0447\n",
      "Epoch [69/100], Step [8/56], Loss: 0.0868\n",
      "Epoch [69/100], Step [9/56], Loss: 0.1379\n",
      "Epoch [69/100], Step [10/56], Loss: 0.0534\n",
      "Epoch [69/100], Step [11/56], Loss: 0.0952\n",
      "Epoch [69/100], Step [12/56], Loss: 0.0402\n",
      "Epoch [69/100], Step [13/56], Loss: 0.0672\n",
      "Epoch [69/100], Step [14/56], Loss: 0.0452\n",
      "Epoch [69/100], Step [15/56], Loss: 0.0895\n",
      "Epoch [69/100], Step [16/56], Loss: 0.0637\n",
      "Epoch [69/100], Step [17/56], Loss: 0.0715\n",
      "Epoch [69/100], Step [18/56], Loss: 0.0883\n",
      "Epoch [69/100], Step [19/56], Loss: 0.1440\n",
      "Epoch [69/100], Step [20/56], Loss: 0.1888\n",
      "Epoch [69/100], Step [21/56], Loss: 0.0944\n",
      "Epoch [69/100], Step [22/56], Loss: 0.0919\n",
      "Epoch [69/100], Step [23/56], Loss: 0.1069\n",
      "Epoch [69/100], Step [24/56], Loss: 0.1038\n",
      "Epoch [69/100], Step [25/56], Loss: 0.0621\n",
      "Epoch [69/100], Step [26/56], Loss: 0.0678\n",
      "Epoch [69/100], Step [27/56], Loss: 0.0487\n",
      "Epoch [69/100], Step [28/56], Loss: 0.1555\n",
      "Epoch [69/100], Step [29/56], Loss: 0.1191\n",
      "Epoch [69/100], Step [30/56], Loss: 0.0501\n",
      "Epoch [69/100], Step [31/56], Loss: 0.1172\n",
      "Epoch [69/100], Step [32/56], Loss: 0.0629\n",
      "Epoch [69/100], Step [33/56], Loss: 0.1538\n",
      "Epoch [69/100], Step [34/56], Loss: 0.1132\n",
      "Epoch [69/100], Step [35/56], Loss: 0.0512\n",
      "Epoch [69/100], Step [36/56], Loss: 0.1344\n",
      "Epoch [69/100], Step [37/56], Loss: 0.2105\n",
      "Epoch [69/100], Step [38/56], Loss: 0.0683\n",
      "Epoch [69/100], Step [39/56], Loss: 0.0567\n",
      "Epoch [69/100], Step [40/56], Loss: 0.2306\n",
      "Epoch [69/100], Step [41/56], Loss: 0.1360\n",
      "Epoch [69/100], Step [42/56], Loss: 0.3260\n",
      "Epoch [69/100], Step [43/56], Loss: 0.0999\n",
      "Epoch [69/100], Step [44/56], Loss: 0.0676\n",
      "Epoch [69/100], Step [45/56], Loss: 0.0638\n",
      "Epoch [69/100], Step [46/56], Loss: 0.1172\n",
      "Epoch [69/100], Step [47/56], Loss: 0.1135\n",
      "Epoch [69/100], Step [48/56], Loss: 0.0559\n",
      "Epoch [69/100], Step [49/56], Loss: 0.0816\n",
      "Epoch [69/100], Step [50/56], Loss: 0.0464\n",
      "Epoch [69/100], Step [51/56], Loss: 0.2073\n",
      "Epoch [69/100], Step [52/56], Loss: 0.2546\n",
      "Epoch [69/100], Step [53/56], Loss: 0.1162\n",
      "Epoch [69/100], Step [54/56], Loss: 0.1416\n",
      "Epoch [69/100], Step [55/56], Loss: 0.0664\n",
      "Epoch [69/100], Step [56/56], Loss: 0.0452\n",
      "Val. loss :0.0738\n",
      "Epoch [70/100], Step [1/56], Loss: 0.1337\n",
      "Epoch [70/100], Step [2/56], Loss: 0.0752\n",
      "Epoch [70/100], Step [3/56], Loss: 0.0501\n",
      "Epoch [70/100], Step [4/56], Loss: 0.1394\n",
      "Epoch [70/100], Step [5/56], Loss: 0.2142\n",
      "Epoch [70/100], Step [6/56], Loss: 0.2147\n",
      "Epoch [70/100], Step [7/56], Loss: 0.1217\n",
      "Epoch [70/100], Step [8/56], Loss: 0.0909\n",
      "Epoch [70/100], Step [9/56], Loss: 0.0857\n",
      "Epoch [70/100], Step [10/56], Loss: 0.1193\n",
      "Epoch [70/100], Step [11/56], Loss: 0.1201\n",
      "Epoch [70/100], Step [12/56], Loss: 0.0830\n",
      "Epoch [70/100], Step [13/56], Loss: 0.0599\n",
      "Epoch [70/100], Step [14/56], Loss: 0.0991\n",
      "Epoch [70/100], Step [15/56], Loss: 0.0534\n",
      "Epoch [70/100], Step [16/56], Loss: 0.0717\n",
      "Epoch [70/100], Step [17/56], Loss: 0.0404\n",
      "Epoch [70/100], Step [18/56], Loss: 0.0925\n",
      "Epoch [70/100], Step [19/56], Loss: 0.0600\n",
      "Epoch [70/100], Step [20/56], Loss: 0.1368\n",
      "Epoch [70/100], Step [21/56], Loss: 0.0470\n",
      "Epoch [70/100], Step [22/56], Loss: 0.0700\n",
      "Epoch [70/100], Step [23/56], Loss: 0.2309\n",
      "Epoch [70/100], Step [24/56], Loss: 0.0751\n",
      "Epoch [70/100], Step [25/56], Loss: 0.1043\n",
      "Epoch [70/100], Step [26/56], Loss: 0.0644\n",
      "Epoch [70/100], Step [27/56], Loss: 0.0642\n",
      "Epoch [70/100], Step [28/56], Loss: 0.0511\n",
      "Epoch [70/100], Step [29/56], Loss: 0.0828\n",
      "Epoch [70/100], Step [30/56], Loss: 0.2086\n",
      "Epoch [70/100], Step [31/56], Loss: 0.0613\n",
      "Epoch [70/100], Step [32/56], Loss: 0.0946\n",
      "Epoch [70/100], Step [33/56], Loss: 0.0499\n",
      "Epoch [70/100], Step [34/56], Loss: 0.0615\n",
      "Epoch [70/100], Step [35/56], Loss: 0.0994\n",
      "Epoch [70/100], Step [36/56], Loss: 0.0568\n",
      "Epoch [70/100], Step [37/56], Loss: 0.0495\n",
      "Epoch [70/100], Step [38/56], Loss: 0.0667\n",
      "Epoch [70/100], Step [39/56], Loss: 0.1110\n",
      "Epoch [70/100], Step [40/56], Loss: 0.1137\n",
      "Epoch [70/100], Step [41/56], Loss: 0.2301\n",
      "Epoch [70/100], Step [42/56], Loss: 0.2468\n",
      "Epoch [70/100], Step [43/56], Loss: 0.1566\n",
      "Epoch [70/100], Step [44/56], Loss: 0.0667\n",
      "Epoch [70/100], Step [45/56], Loss: 0.0884\n",
      "Epoch [70/100], Step [46/56], Loss: 0.0952\n",
      "Epoch [70/100], Step [47/56], Loss: 0.0717\n",
      "Epoch [70/100], Step [48/56], Loss: 0.2104\n",
      "Epoch [70/100], Step [49/56], Loss: 0.1393\n",
      "Epoch [70/100], Step [50/56], Loss: 0.2361\n",
      "Epoch [70/100], Step [51/56], Loss: 0.0763\n",
      "Epoch [70/100], Step [52/56], Loss: 0.0686\n",
      "Epoch [70/100], Step [53/56], Loss: 0.0880\n",
      "Epoch [70/100], Step [54/56], Loss: 0.0604\n",
      "Epoch [70/100], Step [55/56], Loss: 0.1215\n",
      "Epoch [70/100], Step [56/56], Loss: 0.0572\n",
      "Val. loss :0.0699\n",
      "Epoch [71/100], Step [1/56], Loss: 0.0706\n",
      "Epoch [71/100], Step [2/56], Loss: 0.0514\n",
      "Epoch [71/100], Step [3/56], Loss: 0.1280\n",
      "Epoch [71/100], Step [4/56], Loss: 0.0873\n",
      "Epoch [71/100], Step [5/56], Loss: 0.0752\n",
      "Epoch [71/100], Step [6/56], Loss: 0.0718\n",
      "Epoch [71/100], Step [7/56], Loss: 0.0538\n",
      "Epoch [71/100], Step [8/56], Loss: 0.1311\n",
      "Epoch [71/100], Step [9/56], Loss: 0.0731\n",
      "Epoch [71/100], Step [10/56], Loss: 0.0636\n",
      "Epoch [71/100], Step [11/56], Loss: 0.0699\n",
      "Epoch [71/100], Step [12/56], Loss: 0.0655\n",
      "Epoch [71/100], Step [13/56], Loss: 0.0684\n",
      "Epoch [71/100], Step [14/56], Loss: 0.2199\n",
      "Epoch [71/100], Step [15/56], Loss: 0.0890\n",
      "Epoch [71/100], Step [16/56], Loss: 0.0462\n",
      "Epoch [71/100], Step [17/56], Loss: 0.0457\n",
      "Epoch [71/100], Step [18/56], Loss: 0.0738\n",
      "Epoch [71/100], Step [19/56], Loss: 0.0488\n",
      "Epoch [71/100], Step [20/56], Loss: 0.0620\n",
      "Epoch [71/100], Step [21/56], Loss: 0.1016\n",
      "Epoch [71/100], Step [22/56], Loss: 0.0674\n",
      "Epoch [71/100], Step [23/56], Loss: 0.0495\n",
      "Epoch [71/100], Step [24/56], Loss: 0.1028\n",
      "Epoch [71/100], Step [25/56], Loss: 0.0875\n",
      "Epoch [71/100], Step [26/56], Loss: 0.1311\n",
      "Epoch [71/100], Step [27/56], Loss: 0.0738\n",
      "Epoch [71/100], Step [28/56], Loss: 0.0702\n",
      "Epoch [71/100], Step [29/56], Loss: 0.0421\n",
      "Epoch [71/100], Step [30/56], Loss: 0.0499\n",
      "Epoch [71/100], Step [31/56], Loss: 0.1010\n",
      "Epoch [71/100], Step [32/56], Loss: 0.1074\n",
      "Epoch [71/100], Step [33/56], Loss: 0.0530\n",
      "Epoch [71/100], Step [34/56], Loss: 0.0834\n",
      "Epoch [71/100], Step [35/56], Loss: 0.0430\n",
      "Epoch [71/100], Step [36/56], Loss: 0.0927\n",
      "Epoch [71/100], Step [37/56], Loss: 0.1778\n",
      "Epoch [71/100], Step [38/56], Loss: 0.1643\n",
      "Epoch [71/100], Step [39/56], Loss: 0.0677\n",
      "Epoch [71/100], Step [40/56], Loss: 0.0907\n",
      "Epoch [71/100], Step [41/56], Loss: 0.0666\n",
      "Epoch [71/100], Step [42/56], Loss: 0.1024\n",
      "Epoch [71/100], Step [43/56], Loss: 0.1022\n",
      "Epoch [71/100], Step [44/56], Loss: 0.0488\n",
      "Epoch [71/100], Step [45/56], Loss: 0.0512\n",
      "Epoch [71/100], Step [46/56], Loss: 0.0760\n",
      "Epoch [71/100], Step [47/56], Loss: 0.1166\n",
      "Epoch [71/100], Step [48/56], Loss: 0.0416\n",
      "Epoch [71/100], Step [49/56], Loss: 0.0922\n",
      "Epoch [71/100], Step [50/56], Loss: 0.0618\n",
      "Epoch [71/100], Step [51/56], Loss: 0.0485\n",
      "Epoch [71/100], Step [52/56], Loss: 0.2509\n",
      "Epoch [71/100], Step [53/56], Loss: 0.0506\n",
      "Epoch [71/100], Step [54/56], Loss: 0.2803\n",
      "Epoch [71/100], Step [55/56], Loss: 0.0541\n",
      "Epoch [71/100], Step [56/56], Loss: 0.0206\n",
      "Val. loss :0.0535\n",
      "Epoch [72/100], Step [1/56], Loss: 0.0424\n",
      "Epoch [72/100], Step [2/56], Loss: 0.0653\n",
      "Epoch [72/100], Step [3/56], Loss: 0.1180\n",
      "Epoch [72/100], Step [4/56], Loss: 0.0980\n",
      "Epoch [72/100], Step [5/56], Loss: 0.1259\n",
      "Epoch [72/100], Step [6/56], Loss: 0.0574\n",
      "Epoch [72/100], Step [7/56], Loss: 0.1223\n",
      "Epoch [72/100], Step [8/56], Loss: 0.0646\n",
      "Epoch [72/100], Step [9/56], Loss: 0.0707\n",
      "Epoch [72/100], Step [10/56], Loss: 0.0568\n",
      "Epoch [72/100], Step [11/56], Loss: 0.0395\n",
      "Epoch [72/100], Step [12/56], Loss: 0.0584\n",
      "Epoch [72/100], Step [13/56], Loss: 0.1221\n",
      "Epoch [72/100], Step [14/56], Loss: 0.0510\n",
      "Epoch [72/100], Step [15/56], Loss: 0.0759\n",
      "Epoch [72/100], Step [16/56], Loss: 0.0448\n",
      "Epoch [72/100], Step [17/56], Loss: 0.0603\n",
      "Epoch [72/100], Step [18/56], Loss: 0.0766\n",
      "Epoch [72/100], Step [19/56], Loss: 0.0621\n",
      "Epoch [72/100], Step [20/56], Loss: 0.0657\n",
      "Epoch [72/100], Step [21/56], Loss: 0.0461\n",
      "Epoch [72/100], Step [22/56], Loss: 0.0894\n",
      "Epoch [72/100], Step [23/56], Loss: 0.0865\n",
      "Epoch [72/100], Step [24/56], Loss: 0.0432\n",
      "Epoch [72/100], Step [25/56], Loss: 0.0555\n",
      "Epoch [72/100], Step [26/56], Loss: 0.0630\n",
      "Epoch [72/100], Step [27/56], Loss: 0.0505\n",
      "Epoch [72/100], Step [28/56], Loss: 0.0559\n",
      "Epoch [72/100], Step [29/56], Loss: 0.1086\n",
      "Epoch [72/100], Step [30/56], Loss: 0.0630\n",
      "Epoch [72/100], Step [31/56], Loss: 0.0550\n",
      "Epoch [72/100], Step [32/56], Loss: 0.1232\n",
      "Epoch [72/100], Step [33/56], Loss: 0.0429\n",
      "Epoch [72/100], Step [34/56], Loss: 0.0927\n",
      "Epoch [72/100], Step [35/56], Loss: 0.0708\n",
      "Epoch [72/100], Step [36/56], Loss: 0.0913\n",
      "Epoch [72/100], Step [37/56], Loss: 0.0682\n",
      "Epoch [72/100], Step [38/56], Loss: 0.0628\n",
      "Epoch [72/100], Step [39/56], Loss: 0.0627\n",
      "Epoch [72/100], Step [40/56], Loss: 0.0766\n",
      "Epoch [72/100], Step [41/56], Loss: 0.0888\n",
      "Epoch [72/100], Step [42/56], Loss: 0.0417\n",
      "Epoch [72/100], Step [43/56], Loss: 0.0664\n",
      "Epoch [72/100], Step [44/56], Loss: 0.0504\n",
      "Epoch [72/100], Step [45/56], Loss: 0.0964\n",
      "Epoch [72/100], Step [46/56], Loss: 0.0588\n",
      "Epoch [72/100], Step [47/56], Loss: 0.0388\n",
      "Epoch [72/100], Step [48/56], Loss: 0.0496\n",
      "Epoch [72/100], Step [49/56], Loss: 0.0505\n",
      "Epoch [72/100], Step [50/56], Loss: 0.0475\n",
      "Epoch [72/100], Step [51/56], Loss: 0.0488\n",
      "Epoch [72/100], Step [52/56], Loss: 0.0542\n",
      "Epoch [72/100], Step [53/56], Loss: 0.0959\n",
      "Epoch [72/100], Step [54/56], Loss: 0.1105\n",
      "Epoch [72/100], Step [55/56], Loss: 0.0698\n",
      "Epoch [72/100], Step [56/56], Loss: 0.0200\n",
      "Val. loss :0.0600\n",
      "Epoch [73/100], Step [1/56], Loss: 0.1280\n",
      "Epoch [73/100], Step [2/56], Loss: 0.0421\n",
      "Epoch [73/100], Step [3/56], Loss: 0.0607\n",
      "Epoch [73/100], Step [4/56], Loss: 0.2017\n",
      "Epoch [73/100], Step [5/56], Loss: 0.0821\n",
      "Epoch [73/100], Step [6/56], Loss: 0.0575\n",
      "Epoch [73/100], Step [7/56], Loss: 0.1198\n",
      "Epoch [73/100], Step [8/56], Loss: 0.0634\n",
      "Epoch [73/100], Step [9/56], Loss: 0.0788\n",
      "Epoch [73/100], Step [10/56], Loss: 0.0559\n",
      "Epoch [73/100], Step [11/56], Loss: 0.0353\n",
      "Epoch [73/100], Step [12/56], Loss: 0.0469\n",
      "Epoch [73/100], Step [13/56], Loss: 0.0556\n",
      "Epoch [73/100], Step [14/56], Loss: 0.0808\n",
      "Epoch [73/100], Step [15/56], Loss: 0.0582\n",
      "Epoch [73/100], Step [16/56], Loss: 0.0871\n",
      "Epoch [73/100], Step [17/56], Loss: 0.0642\n",
      "Epoch [73/100], Step [18/56], Loss: 0.0811\n",
      "Epoch [73/100], Step [19/56], Loss: 0.0454\n",
      "Epoch [73/100], Step [20/56], Loss: 0.0382\n",
      "Epoch [73/100], Step [21/56], Loss: 0.0660\n",
      "Epoch [73/100], Step [22/56], Loss: 0.0631\n",
      "Epoch [73/100], Step [23/56], Loss: 0.0563\n",
      "Epoch [73/100], Step [24/56], Loss: 0.0495\n",
      "Epoch [73/100], Step [25/56], Loss: 0.0486\n",
      "Epoch [73/100], Step [26/56], Loss: 0.1237\n",
      "Epoch [73/100], Step [27/56], Loss: 0.0399\n",
      "Epoch [73/100], Step [28/56], Loss: 0.1948\n",
      "Epoch [73/100], Step [29/56], Loss: 0.0802\n",
      "Epoch [73/100], Step [30/56], Loss: 0.2634\n",
      "Epoch [73/100], Step [31/56], Loss: 0.0535\n",
      "Epoch [73/100], Step [32/56], Loss: 0.0657\n",
      "Epoch [73/100], Step [33/56], Loss: 0.0637\n",
      "Epoch [73/100], Step [34/56], Loss: 0.0859\n",
      "Epoch [73/100], Step [35/56], Loss: 0.1110\n",
      "Epoch [73/100], Step [36/56], Loss: 0.0533\n",
      "Epoch [73/100], Step [37/56], Loss: 0.1409\n",
      "Epoch [73/100], Step [38/56], Loss: 0.1268\n",
      "Epoch [73/100], Step [39/56], Loss: 0.1576\n",
      "Epoch [73/100], Step [40/56], Loss: 0.0602\n",
      "Epoch [73/100], Step [41/56], Loss: 0.0427\n",
      "Epoch [73/100], Step [42/56], Loss: 0.0481\n",
      "Epoch [73/100], Step [43/56], Loss: 0.0746\n",
      "Epoch [73/100], Step [44/56], Loss: 0.1177\n",
      "Epoch [73/100], Step [45/56], Loss: 0.1328\n",
      "Epoch [73/100], Step [46/56], Loss: 0.0463\n",
      "Epoch [73/100], Step [47/56], Loss: 0.2591\n",
      "Epoch [73/100], Step [48/56], Loss: 0.1721\n",
      "Epoch [73/100], Step [49/56], Loss: 0.0924\n",
      "Epoch [73/100], Step [50/56], Loss: 0.0877\n",
      "Epoch [73/100], Step [51/56], Loss: 0.1445\n",
      "Epoch [73/100], Step [52/56], Loss: 0.1009\n",
      "Epoch [73/100], Step [53/56], Loss: 0.0748\n",
      "Epoch [73/100], Step [54/56], Loss: 0.0973\n",
      "Epoch [73/100], Step [55/56], Loss: 0.0561\n",
      "Epoch [73/100], Step [56/56], Loss: 0.0234\n",
      "Val. loss :0.0741\n",
      "Epoch [74/100], Step [1/56], Loss: 0.0886\n",
      "Epoch [74/100], Step [2/56], Loss: 0.0620\n",
      "Epoch [74/100], Step [3/56], Loss: 0.1611\n",
      "Epoch [74/100], Step [4/56], Loss: 0.1525\n",
      "Epoch [74/100], Step [5/56], Loss: 0.1712\n",
      "Epoch [74/100], Step [6/56], Loss: 0.1894\n",
      "Epoch [74/100], Step [7/56], Loss: 0.0909\n",
      "Epoch [74/100], Step [8/56], Loss: 0.0912\n",
      "Epoch [74/100], Step [9/56], Loss: 0.1283\n",
      "Epoch [74/100], Step [10/56], Loss: 0.0939\n",
      "Epoch [74/100], Step [11/56], Loss: 0.1274\n",
      "Epoch [74/100], Step [12/56], Loss: 0.0900\n",
      "Epoch [74/100], Step [13/56], Loss: 0.0562\n",
      "Epoch [74/100], Step [14/56], Loss: 0.1160\n",
      "Epoch [74/100], Step [15/56], Loss: 0.0513\n",
      "Epoch [74/100], Step [16/56], Loss: 0.1776\n",
      "Epoch [74/100], Step [17/56], Loss: 0.0718\n",
      "Epoch [74/100], Step [18/56], Loss: 0.1333\n",
      "Epoch [74/100], Step [19/56], Loss: 0.1642\n",
      "Epoch [74/100], Step [20/56], Loss: 0.1249\n",
      "Epoch [74/100], Step [21/56], Loss: 0.0605\n",
      "Epoch [74/100], Step [22/56], Loss: 0.0463\n",
      "Epoch [74/100], Step [23/56], Loss: 0.0843\n",
      "Epoch [74/100], Step [24/56], Loss: 0.1138\n",
      "Epoch [74/100], Step [25/56], Loss: 0.1066\n",
      "Epoch [74/100], Step [26/56], Loss: 0.1299\n",
      "Epoch [74/100], Step [27/56], Loss: 0.0517\n",
      "Epoch [74/100], Step [28/56], Loss: 0.0718\n",
      "Epoch [74/100], Step [29/56], Loss: 0.0709\n",
      "Epoch [74/100], Step [30/56], Loss: 0.0569\n",
      "Epoch [74/100], Step [31/56], Loss: 0.1191\n",
      "Epoch [74/100], Step [32/56], Loss: 0.0577\n",
      "Epoch [74/100], Step [33/56], Loss: 0.0583\n",
      "Epoch [74/100], Step [34/56], Loss: 0.0587\n",
      "Epoch [74/100], Step [35/56], Loss: 0.0777\n",
      "Epoch [74/100], Step [36/56], Loss: 0.0591\n",
      "Epoch [74/100], Step [37/56], Loss: 0.1667\n",
      "Epoch [74/100], Step [38/56], Loss: 0.0501\n",
      "Epoch [74/100], Step [39/56], Loss: 0.0658\n",
      "Epoch [74/100], Step [40/56], Loss: 0.1409\n",
      "Epoch [74/100], Step [41/56], Loss: 0.0686\n",
      "Epoch [74/100], Step [42/56], Loss: 0.0757\n",
      "Epoch [74/100], Step [43/56], Loss: 0.0759\n",
      "Epoch [74/100], Step [44/56], Loss: 0.1105\n",
      "Epoch [74/100], Step [45/56], Loss: 0.0597\n",
      "Epoch [74/100], Step [46/56], Loss: 0.0673\n",
      "Epoch [74/100], Step [47/56], Loss: 0.0571\n",
      "Epoch [74/100], Step [48/56], Loss: 0.0789\n",
      "Epoch [74/100], Step [49/56], Loss: 0.0502\n",
      "Epoch [74/100], Step [50/56], Loss: 0.0881\n",
      "Epoch [74/100], Step [51/56], Loss: 0.0528\n",
      "Epoch [74/100], Step [52/56], Loss: 0.0524\n",
      "Epoch [74/100], Step [53/56], Loss: 0.0789\n",
      "Epoch [74/100], Step [54/56], Loss: 0.0452\n",
      "Epoch [74/100], Step [55/56], Loss: 0.0662\n",
      "Epoch [74/100], Step [56/56], Loss: 0.0623\n",
      "Val. loss :0.0704\n",
      "Epoch [75/100], Step [1/56], Loss: 0.0733\n",
      "Epoch [75/100], Step [2/56], Loss: 0.0525\n",
      "Epoch [75/100], Step [3/56], Loss: 0.0550\n",
      "Epoch [75/100], Step [4/56], Loss: 0.0570\n",
      "Epoch [75/100], Step [5/56], Loss: 0.2875\n",
      "Epoch [75/100], Step [6/56], Loss: 0.0709\n",
      "Epoch [75/100], Step [7/56], Loss: 0.0898\n",
      "Epoch [75/100], Step [8/56], Loss: 0.0996\n",
      "Epoch [75/100], Step [9/56], Loss: 0.0738\n",
      "Epoch [75/100], Step [10/56], Loss: 0.0380\n",
      "Epoch [75/100], Step [11/56], Loss: 0.0664\n",
      "Epoch [75/100], Step [12/56], Loss: 0.0590\n",
      "Epoch [75/100], Step [13/56], Loss: 0.0583\n",
      "Epoch [75/100], Step [14/56], Loss: 0.1036\n",
      "Epoch [75/100], Step [15/56], Loss: 0.1055\n",
      "Epoch [75/100], Step [16/56], Loss: 0.0468\n",
      "Epoch [75/100], Step [17/56], Loss: 0.1980\n",
      "Epoch [75/100], Step [18/56], Loss: 0.2947\n",
      "Epoch [75/100], Step [19/56], Loss: 0.1463\n",
      "Epoch [75/100], Step [20/56], Loss: 0.2971\n",
      "Epoch [75/100], Step [21/56], Loss: 0.1349\n",
      "Epoch [75/100], Step [22/56], Loss: 0.1158\n",
      "Epoch [75/100], Step [23/56], Loss: 0.1403\n",
      "Epoch [75/100], Step [24/56], Loss: 0.1414\n",
      "Epoch [75/100], Step [25/56], Loss: 0.0775\n",
      "Epoch [75/100], Step [26/56], Loss: 0.0683\n",
      "Epoch [75/100], Step [27/56], Loss: 0.0676\n",
      "Epoch [75/100], Step [28/56], Loss: 0.1057\n",
      "Epoch [75/100], Step [29/56], Loss: 0.0578\n",
      "Epoch [75/100], Step [30/56], Loss: 0.0657\n",
      "Epoch [75/100], Step [31/56], Loss: 0.0501\n",
      "Epoch [75/100], Step [32/56], Loss: 0.0739\n",
      "Epoch [75/100], Step [33/56], Loss: 0.0824\n",
      "Epoch [75/100], Step [34/56], Loss: 0.0725\n",
      "Epoch [75/100], Step [35/56], Loss: 0.0817\n",
      "Epoch [75/100], Step [36/56], Loss: 0.1172\n",
      "Epoch [75/100], Step [37/56], Loss: 0.0728\n",
      "Epoch [75/100], Step [38/56], Loss: 0.0845\n",
      "Epoch [75/100], Step [39/56], Loss: 0.0466\n",
      "Epoch [75/100], Step [40/56], Loss: 0.0726\n",
      "Epoch [75/100], Step [41/56], Loss: 0.0666\n",
      "Epoch [75/100], Step [42/56], Loss: 0.0537\n",
      "Epoch [75/100], Step [43/56], Loss: 0.0470\n",
      "Epoch [75/100], Step [44/56], Loss: 0.1009\n",
      "Epoch [75/100], Step [45/56], Loss: 0.0395\n",
      "Epoch [75/100], Step [46/56], Loss: 0.0413\n",
      "Epoch [75/100], Step [47/56], Loss: 0.0535\n",
      "Epoch [75/100], Step [48/56], Loss: 0.0475\n",
      "Epoch [75/100], Step [49/56], Loss: 0.0430\n",
      "Epoch [75/100], Step [50/56], Loss: 0.1216\n",
      "Epoch [75/100], Step [51/56], Loss: 0.0851\n",
      "Epoch [75/100], Step [52/56], Loss: 0.0491\n",
      "Epoch [75/100], Step [53/56], Loss: 0.0484\n",
      "Epoch [75/100], Step [54/56], Loss: 0.0736\n",
      "Epoch [75/100], Step [55/56], Loss: 0.0800\n",
      "Epoch [75/100], Step [56/56], Loss: 0.0597\n",
      "Val. loss :0.0522\n",
      "Epoch [76/100], Step [1/56], Loss: 0.0560\n",
      "Epoch [76/100], Step [2/56], Loss: 0.0872\n",
      "Epoch [76/100], Step [3/56], Loss: 0.0449\n",
      "Epoch [76/100], Step [4/56], Loss: 0.1244\n",
      "Epoch [76/100], Step [5/56], Loss: 0.0571\n",
      "Epoch [76/100], Step [6/56], Loss: 0.0411\n",
      "Epoch [76/100], Step [7/56], Loss: 0.0497\n",
      "Epoch [76/100], Step [8/56], Loss: 0.0728\n",
      "Epoch [76/100], Step [9/56], Loss: 0.0434\n",
      "Epoch [76/100], Step [10/56], Loss: 0.0643\n",
      "Epoch [76/100], Step [11/56], Loss: 0.0463\n",
      "Epoch [76/100], Step [12/56], Loss: 0.0861\n",
      "Epoch [76/100], Step [13/56], Loss: 0.0483\n",
      "Epoch [76/100], Step [14/56], Loss: 0.0516\n",
      "Epoch [76/100], Step [15/56], Loss: 0.0949\n",
      "Epoch [76/100], Step [16/56], Loss: 0.0641\n",
      "Epoch [76/100], Step [17/56], Loss: 0.1021\n",
      "Epoch [76/100], Step [18/56], Loss: 0.0538\n",
      "Epoch [76/100], Step [19/56], Loss: 0.0403\n",
      "Epoch [76/100], Step [20/56], Loss: 0.1114\n",
      "Epoch [76/100], Step [21/56], Loss: 0.0464\n",
      "Epoch [76/100], Step [22/56], Loss: 0.0429\n",
      "Epoch [76/100], Step [23/56], Loss: 0.0896\n",
      "Epoch [76/100], Step [24/56], Loss: 0.0475\n",
      "Epoch [76/100], Step [25/56], Loss: 0.0524\n",
      "Epoch [76/100], Step [26/56], Loss: 0.0480\n",
      "Epoch [76/100], Step [27/56], Loss: 0.0494\n",
      "Epoch [76/100], Step [28/56], Loss: 0.0569\n",
      "Epoch [76/100], Step [29/56], Loss: 0.0498\n",
      "Epoch [76/100], Step [30/56], Loss: 0.1835\n",
      "Epoch [76/100], Step [31/56], Loss: 0.0743\n",
      "Epoch [76/100], Step [32/56], Loss: 0.0501\n",
      "Epoch [76/100], Step [33/56], Loss: 0.0937\n",
      "Epoch [76/100], Step [34/56], Loss: 0.0461\n",
      "Epoch [76/100], Step [35/56], Loss: 0.1102\n",
      "Epoch [76/100], Step [36/56], Loss: 0.0376\n",
      "Epoch [76/100], Step [37/56], Loss: 0.0693\n",
      "Epoch [76/100], Step [38/56], Loss: 0.0539\n",
      "Epoch [76/100], Step [39/56], Loss: 0.0845\n",
      "Epoch [76/100], Step [40/56], Loss: 0.1109\n",
      "Epoch [76/100], Step [41/56], Loss: 0.0464\n",
      "Epoch [76/100], Step [42/56], Loss: 0.0525\n",
      "Epoch [76/100], Step [43/56], Loss: 0.0577\n",
      "Epoch [76/100], Step [44/56], Loss: 0.2163\n",
      "Epoch [76/100], Step [45/56], Loss: 0.0660\n",
      "Epoch [76/100], Step [46/56], Loss: 0.0948\n",
      "Epoch [76/100], Step [47/56], Loss: 0.2151\n",
      "Epoch [76/100], Step [48/56], Loss: 0.0603\n",
      "Epoch [76/100], Step [49/56], Loss: 0.0824\n",
      "Epoch [76/100], Step [50/56], Loss: 0.0519\n",
      "Epoch [76/100], Step [51/56], Loss: 0.2942\n",
      "Epoch [76/100], Step [52/56], Loss: 0.0822\n",
      "Epoch [76/100], Step [53/56], Loss: 0.0509\n",
      "Epoch [76/100], Step [54/56], Loss: 0.0733\n",
      "Epoch [76/100], Step [55/56], Loss: 0.0539\n",
      "Epoch [76/100], Step [56/56], Loss: 0.0350\n",
      "Val. loss :0.0869\n",
      "Epoch [77/100], Step [1/56], Loss: 0.1035\n",
      "Epoch [77/100], Step [2/56], Loss: 0.0577\n",
      "Epoch [77/100], Step [3/56], Loss: 0.0491\n",
      "Epoch [77/100], Step [4/56], Loss: 0.2278\n",
      "Epoch [77/100], Step [5/56], Loss: 0.0631\n",
      "Epoch [77/100], Step [6/56], Loss: 0.0390\n",
      "Epoch [77/100], Step [7/56], Loss: 0.0434\n",
      "Epoch [77/100], Step [8/56], Loss: 0.0448\n",
      "Epoch [77/100], Step [9/56], Loss: 0.0762\n",
      "Epoch [77/100], Step [10/56], Loss: 0.0523\n",
      "Epoch [77/100], Step [11/56], Loss: 0.0540\n",
      "Epoch [77/100], Step [12/56], Loss: 0.0818\n",
      "Epoch [77/100], Step [13/56], Loss: 0.0464\n",
      "Epoch [77/100], Step [14/56], Loss: 0.0720\n",
      "Epoch [77/100], Step [15/56], Loss: 0.0759\n",
      "Epoch [77/100], Step [16/56], Loss: 0.0519\n",
      "Epoch [77/100], Step [17/56], Loss: 0.0471\n",
      "Epoch [77/100], Step [18/56], Loss: 0.0566\n",
      "Epoch [77/100], Step [19/56], Loss: 0.0743\n",
      "Epoch [77/100], Step [20/56], Loss: 0.0721\n",
      "Epoch [77/100], Step [21/56], Loss: 0.0358\n",
      "Epoch [77/100], Step [22/56], Loss: 0.0885\n",
      "Epoch [77/100], Step [23/56], Loss: 0.0624\n",
      "Epoch [77/100], Step [24/56], Loss: 0.0557\n",
      "Epoch [77/100], Step [25/56], Loss: 0.0774\n",
      "Epoch [77/100], Step [26/56], Loss: 0.2212\n",
      "Epoch [77/100], Step [27/56], Loss: 0.0820\n",
      "Epoch [77/100], Step [28/56], Loss: 0.0981\n",
      "Epoch [77/100], Step [29/56], Loss: 0.0879\n",
      "Epoch [77/100], Step [30/56], Loss: 0.0611\n",
      "Epoch [77/100], Step [31/56], Loss: 0.0963\n",
      "Epoch [77/100], Step [32/56], Loss: 0.0726\n",
      "Epoch [77/100], Step [33/56], Loss: 0.1557\n",
      "Epoch [77/100], Step [34/56], Loss: 0.1370\n",
      "Epoch [77/100], Step [35/56], Loss: 0.0614\n",
      "Epoch [77/100], Step [36/56], Loss: 0.0597\n",
      "Epoch [77/100], Step [37/56], Loss: 0.2050\n",
      "Epoch [77/100], Step [38/56], Loss: 0.1093\n",
      "Epoch [77/100], Step [39/56], Loss: 0.0697\n",
      "Epoch [77/100], Step [40/56], Loss: 0.0850\n",
      "Epoch [77/100], Step [41/56], Loss: 0.1543\n",
      "Epoch [77/100], Step [42/56], Loss: 0.0711\n",
      "Epoch [77/100], Step [43/56], Loss: 0.0628\n",
      "Epoch [77/100], Step [44/56], Loss: 0.0446\n",
      "Epoch [77/100], Step [45/56], Loss: 0.0481\n",
      "Epoch [77/100], Step [46/56], Loss: 0.2830\n",
      "Epoch [77/100], Step [47/56], Loss: 0.1282\n",
      "Epoch [77/100], Step [48/56], Loss: 0.0503\n",
      "Epoch [77/100], Step [49/56], Loss: 0.0632\n",
      "Epoch [77/100], Step [50/56], Loss: 0.0906\n",
      "Epoch [77/100], Step [51/56], Loss: 0.0773\n",
      "Epoch [77/100], Step [52/56], Loss: 0.0522\n",
      "Epoch [77/100], Step [53/56], Loss: 0.0731\n",
      "Epoch [77/100], Step [54/56], Loss: 0.1876\n",
      "Epoch [77/100], Step [55/56], Loss: 0.0603\n",
      "Epoch [77/100], Step [56/56], Loss: 0.0393\n",
      "Val. loss :0.0838\n",
      "Epoch [78/100], Step [1/56], Loss: 0.1535\n",
      "Epoch [78/100], Step [2/56], Loss: 0.0607\n",
      "Epoch [78/100], Step [3/56], Loss: 0.0729\n",
      "Epoch [78/100], Step [4/56], Loss: 0.0561\n",
      "Epoch [78/100], Step [5/56], Loss: 0.0704\n",
      "Epoch [78/100], Step [6/56], Loss: 0.0552\n",
      "Epoch [78/100], Step [7/56], Loss: 0.0614\n",
      "Epoch [78/100], Step [8/56], Loss: 0.0918\n",
      "Epoch [78/100], Step [9/56], Loss: 0.1677\n",
      "Epoch [78/100], Step [10/56], Loss: 0.1140\n",
      "Epoch [78/100], Step [11/56], Loss: 0.0582\n",
      "Epoch [78/100], Step [12/56], Loss: 0.0643\n",
      "Epoch [78/100], Step [13/56], Loss: 0.0692\n",
      "Epoch [78/100], Step [14/56], Loss: 0.1067\n",
      "Epoch [78/100], Step [15/56], Loss: 0.1617\n",
      "Epoch [78/100], Step [16/56], Loss: 0.0500\n",
      "Epoch [78/100], Step [17/56], Loss: 0.0998\n",
      "Epoch [78/100], Step [18/56], Loss: 0.0707\n",
      "Epoch [78/100], Step [19/56], Loss: 0.0657\n",
      "Epoch [78/100], Step [20/56], Loss: 0.0522\n",
      "Epoch [78/100], Step [21/56], Loss: 0.1507\n",
      "Epoch [78/100], Step [22/56], Loss: 0.0913\n",
      "Epoch [78/100], Step [23/56], Loss: 0.0502\n",
      "Epoch [78/100], Step [24/56], Loss: 0.0495\n",
      "Epoch [78/100], Step [25/56], Loss: 0.0813\n",
      "Epoch [78/100], Step [26/56], Loss: 0.2020\n",
      "Epoch [78/100], Step [27/56], Loss: 0.1027\n",
      "Epoch [78/100], Step [28/56], Loss: 0.1469\n",
      "Epoch [78/100], Step [29/56], Loss: 0.0530\n",
      "Epoch [78/100], Step [30/56], Loss: 0.0484\n",
      "Epoch [78/100], Step [31/56], Loss: 0.0727\n",
      "Epoch [78/100], Step [32/56], Loss: 0.0875\n",
      "Epoch [78/100], Step [33/56], Loss: 0.1004\n",
      "Epoch [78/100], Step [34/56], Loss: 0.0608\n",
      "Epoch [78/100], Step [35/56], Loss: 0.1043\n",
      "Epoch [78/100], Step [36/56], Loss: 0.0400\n",
      "Epoch [78/100], Step [37/56], Loss: 0.0894\n",
      "Epoch [78/100], Step [38/56], Loss: 0.0761\n",
      "Epoch [78/100], Step [39/56], Loss: 0.0479\n",
      "Epoch [78/100], Step [40/56], Loss: 0.1517\n",
      "Epoch [78/100], Step [41/56], Loss: 0.0728\n",
      "Epoch [78/100], Step [42/56], Loss: 0.0535\n",
      "Epoch [78/100], Step [43/56], Loss: 0.0968\n",
      "Epoch [78/100], Step [44/56], Loss: 0.0687\n",
      "Epoch [78/100], Step [45/56], Loss: 0.1014\n",
      "Epoch [78/100], Step [46/56], Loss: 0.0610\n",
      "Epoch [78/100], Step [47/56], Loss: 0.1830\n",
      "Epoch [78/100], Step [48/56], Loss: 0.0726\n",
      "Epoch [78/100], Step [49/56], Loss: 0.0651\n",
      "Epoch [78/100], Step [50/56], Loss: 0.0726\n",
      "Epoch [78/100], Step [51/56], Loss: 0.0506\n",
      "Epoch [78/100], Step [52/56], Loss: 0.0551\n",
      "Epoch [78/100], Step [53/56], Loss: 0.0817\n",
      "Epoch [78/100], Step [54/56], Loss: 0.0554\n",
      "Epoch [78/100], Step [55/56], Loss: 0.0491\n",
      "Epoch [78/100], Step [56/56], Loss: 0.0451\n",
      "Val. loss :0.0600\n",
      "Epoch [79/100], Step [1/56], Loss: 0.0614\n",
      "Epoch [79/100], Step [2/56], Loss: 0.0680\n",
      "Epoch [79/100], Step [3/56], Loss: 0.0684\n",
      "Epoch [79/100], Step [4/56], Loss: 0.0628\n",
      "Epoch [79/100], Step [5/56], Loss: 0.0479\n",
      "Epoch [79/100], Step [6/56], Loss: 0.0958\n",
      "Epoch [79/100], Step [7/56], Loss: 0.0561\n",
      "Epoch [79/100], Step [8/56], Loss: 0.0941\n",
      "Epoch [79/100], Step [9/56], Loss: 0.1257\n",
      "Epoch [79/100], Step [10/56], Loss: 0.0721\n",
      "Epoch [79/100], Step [11/56], Loss: 0.0703\n",
      "Epoch [79/100], Step [12/56], Loss: 0.1190\n",
      "Epoch [79/100], Step [13/56], Loss: 0.0424\n",
      "Epoch [79/100], Step [14/56], Loss: 0.0412\n",
      "Epoch [79/100], Step [15/56], Loss: 0.0516\n",
      "Epoch [79/100], Step [16/56], Loss: 0.0712\n",
      "Epoch [79/100], Step [17/56], Loss: 0.0852\n",
      "Epoch [79/100], Step [18/56], Loss: 0.0513\n",
      "Epoch [79/100], Step [19/56], Loss: 0.1404\n",
      "Epoch [79/100], Step [20/56], Loss: 0.0407\n",
      "Epoch [79/100], Step [21/56], Loss: 0.0506\n",
      "Epoch [79/100], Step [22/56], Loss: 0.1682\n",
      "Epoch [79/100], Step [23/56], Loss: 0.1282\n",
      "Epoch [79/100], Step [24/56], Loss: 0.0466\n",
      "Epoch [79/100], Step [25/56], Loss: 0.0758\n",
      "Epoch [79/100], Step [26/56], Loss: 0.0873\n",
      "Epoch [79/100], Step [27/56], Loss: 0.0744\n",
      "Epoch [79/100], Step [28/56], Loss: 0.0465\n",
      "Epoch [79/100], Step [29/56], Loss: 0.0498\n",
      "Epoch [79/100], Step [30/56], Loss: 0.0412\n",
      "Epoch [79/100], Step [31/56], Loss: 0.0691\n",
      "Epoch [79/100], Step [32/56], Loss: 0.0622\n",
      "Epoch [79/100], Step [33/56], Loss: 0.1007\n",
      "Epoch [79/100], Step [34/56], Loss: 0.0388\n",
      "Epoch [79/100], Step [35/56], Loss: 0.0396\n",
      "Epoch [79/100], Step [36/56], Loss: 0.0545\n",
      "Epoch [79/100], Step [37/56], Loss: 0.0438\n",
      "Epoch [79/100], Step [38/56], Loss: 0.1309\n",
      "Epoch [79/100], Step [39/56], Loss: 0.0668\n",
      "Epoch [79/100], Step [40/56], Loss: 0.0663\n",
      "Epoch [79/100], Step [41/56], Loss: 0.0587\n",
      "Epoch [79/100], Step [42/56], Loss: 0.0843\n",
      "Epoch [79/100], Step [43/56], Loss: 0.2772\n",
      "Epoch [79/100], Step [44/56], Loss: 0.0659\n",
      "Epoch [79/100], Step [45/56], Loss: 0.1138\n",
      "Epoch [79/100], Step [46/56], Loss: 0.0449\n",
      "Epoch [79/100], Step [47/56], Loss: 0.1091\n",
      "Epoch [79/100], Step [48/56], Loss: 0.0725\n",
      "Epoch [79/100], Step [49/56], Loss: 0.0596\n",
      "Epoch [79/100], Step [50/56], Loss: 0.1296\n",
      "Epoch [79/100], Step [51/56], Loss: 0.0632\n",
      "Epoch [79/100], Step [52/56], Loss: 0.1252\n",
      "Epoch [79/100], Step [53/56], Loss: 0.0608\n",
      "Epoch [79/100], Step [54/56], Loss: 0.2097\n",
      "Epoch [79/100], Step [55/56], Loss: 0.0795\n",
      "Epoch [79/100], Step [56/56], Loss: 0.0702\n",
      "Val. loss :0.0897\n",
      "Epoch [80/100], Step [1/56], Loss: 0.0983\n",
      "Epoch [80/100], Step [2/56], Loss: 0.2128\n",
      "Epoch [80/100], Step [3/56], Loss: 0.0616\n",
      "Epoch [80/100], Step [4/56], Loss: 0.0622\n",
      "Epoch [80/100], Step [5/56], Loss: 0.0541\n",
      "Epoch [80/100], Step [6/56], Loss: 0.1185\n",
      "Epoch [80/100], Step [7/56], Loss: 0.1770\n",
      "Epoch [80/100], Step [8/56], Loss: 0.1087\n",
      "Epoch [80/100], Step [9/56], Loss: 0.0519\n",
      "Epoch [80/100], Step [10/56], Loss: 0.0531\n",
      "Epoch [80/100], Step [11/56], Loss: 0.0674\n",
      "Epoch [80/100], Step [12/56], Loss: 0.0669\n",
      "Epoch [80/100], Step [13/56], Loss: 0.0917\n",
      "Epoch [80/100], Step [14/56], Loss: 0.0738\n",
      "Epoch [80/100], Step [15/56], Loss: 0.0972\n",
      "Epoch [80/100], Step [16/56], Loss: 0.0978\n",
      "Epoch [80/100], Step [17/56], Loss: 0.0746\n",
      "Epoch [80/100], Step [18/56], Loss: 0.0524\n",
      "Epoch [80/100], Step [19/56], Loss: 0.1229\n",
      "Epoch [80/100], Step [20/56], Loss: 0.0588\n",
      "Epoch [80/100], Step [21/56], Loss: 0.0663\n",
      "Epoch [80/100], Step [22/56], Loss: 0.1740\n",
      "Epoch [80/100], Step [23/56], Loss: 0.0946\n",
      "Epoch [80/100], Step [24/56], Loss: 0.1074\n",
      "Epoch [80/100], Step [25/56], Loss: 0.0591\n",
      "Epoch [80/100], Step [26/56], Loss: 0.0790\n",
      "Epoch [80/100], Step [27/56], Loss: 0.1095\n",
      "Epoch [80/100], Step [28/56], Loss: 0.0574\n",
      "Epoch [80/100], Step [29/56], Loss: 0.0549\n",
      "Epoch [80/100], Step [30/56], Loss: 0.0743\n",
      "Epoch [80/100], Step [31/56], Loss: 0.0830\n",
      "Epoch [80/100], Step [32/56], Loss: 0.0767\n",
      "Epoch [80/100], Step [33/56], Loss: 0.0740\n",
      "Epoch [80/100], Step [34/56], Loss: 0.0701\n",
      "Epoch [80/100], Step [35/56], Loss: 0.0583\n",
      "Epoch [80/100], Step [36/56], Loss: 0.0574\n",
      "Epoch [80/100], Step [37/56], Loss: 0.1758\n",
      "Epoch [80/100], Step [38/56], Loss: 0.1913\n",
      "Epoch [80/100], Step [39/56], Loss: 0.0964\n",
      "Epoch [80/100], Step [40/56], Loss: 0.0808\n",
      "Epoch [80/100], Step [41/56], Loss: 0.0990\n",
      "Epoch [80/100], Step [42/56], Loss: 0.1644\n",
      "Epoch [80/100], Step [43/56], Loss: 0.0723\n",
      "Epoch [80/100], Step [44/56], Loss: 0.1534\n",
      "Epoch [80/100], Step [45/56], Loss: 0.0867\n",
      "Epoch [80/100], Step [46/56], Loss: 0.1092\n",
      "Epoch [80/100], Step [47/56], Loss: 0.0449\n",
      "Epoch [80/100], Step [48/56], Loss: 0.0471\n",
      "Epoch [80/100], Step [49/56], Loss: 0.1152\n",
      "Epoch [80/100], Step [50/56], Loss: 0.0727\n",
      "Epoch [80/100], Step [51/56], Loss: 0.0653\n",
      "Epoch [80/100], Step [52/56], Loss: 0.2113\n",
      "Epoch [80/100], Step [53/56], Loss: 0.0926\n",
      "Epoch [80/100], Step [54/56], Loss: 0.1057\n",
      "Epoch [80/100], Step [55/56], Loss: 0.0554\n",
      "Epoch [80/100], Step [56/56], Loss: 0.0457\n",
      "Val. loss :0.0799\n",
      "Epoch [81/100], Step [1/56], Loss: 0.1143\n",
      "Epoch [81/100], Step [2/56], Loss: 0.1613\n",
      "Epoch [81/100], Step [3/56], Loss: 0.1024\n",
      "Epoch [81/100], Step [4/56], Loss: 0.1301\n",
      "Epoch [81/100], Step [5/56], Loss: 0.0445\n",
      "Epoch [81/100], Step [6/56], Loss: 0.0430\n",
      "Epoch [81/100], Step [7/56], Loss: 0.0427\n",
      "Epoch [81/100], Step [8/56], Loss: 0.1377\n",
      "Epoch [81/100], Step [9/56], Loss: 0.0963\n",
      "Epoch [81/100], Step [10/56], Loss: 0.0863\n",
      "Epoch [81/100], Step [11/56], Loss: 0.0675\n",
      "Epoch [81/100], Step [12/56], Loss: 0.0439\n",
      "Epoch [81/100], Step [13/56], Loss: 0.0596\n",
      "Epoch [81/100], Step [14/56], Loss: 0.0751\n",
      "Epoch [81/100], Step [15/56], Loss: 0.0669\n",
      "Epoch [81/100], Step [16/56], Loss: 0.0591\n",
      "Epoch [81/100], Step [17/56], Loss: 0.2081\n",
      "Epoch [81/100], Step [18/56], Loss: 0.0924\n",
      "Epoch [81/100], Step [19/56], Loss: 0.0658\n",
      "Epoch [81/100], Step [20/56], Loss: 0.0882\n",
      "Epoch [81/100], Step [21/56], Loss: 0.0860\n",
      "Epoch [81/100], Step [22/56], Loss: 0.0573\n",
      "Epoch [81/100], Step [23/56], Loss: 0.0967\n",
      "Epoch [81/100], Step [24/56], Loss: 0.0403\n",
      "Epoch [81/100], Step [25/56], Loss: 0.0538\n",
      "Epoch [81/100], Step [26/56], Loss: 0.0604\n",
      "Epoch [81/100], Step [27/56], Loss: 0.0641\n",
      "Epoch [81/100], Step [28/56], Loss: 0.0900\n",
      "Epoch [81/100], Step [29/56], Loss: 0.0447\n",
      "Epoch [81/100], Step [30/56], Loss: 0.0861\n",
      "Epoch [81/100], Step [31/56], Loss: 0.0524\n",
      "Epoch [81/100], Step [32/56], Loss: 0.0680\n",
      "Epoch [81/100], Step [33/56], Loss: 0.0494\n",
      "Epoch [81/100], Step [34/56], Loss: 0.0751\n",
      "Epoch [81/100], Step [35/56], Loss: 0.0694\n",
      "Epoch [81/100], Step [36/56], Loss: 0.0632\n",
      "Epoch [81/100], Step [37/56], Loss: 0.0488\n",
      "Epoch [81/100], Step [38/56], Loss: 0.1550\n",
      "Epoch [81/100], Step [39/56], Loss: 0.0488\n",
      "Epoch [81/100], Step [40/56], Loss: 0.0663\n",
      "Epoch [81/100], Step [41/56], Loss: 0.0928\n",
      "Epoch [81/100], Step [42/56], Loss: 0.0520\n",
      "Epoch [81/100], Step [43/56], Loss: 0.0422\n",
      "Epoch [81/100], Step [44/56], Loss: 0.0732\n",
      "Epoch [81/100], Step [45/56], Loss: 0.0728\n",
      "Epoch [81/100], Step [46/56], Loss: 0.0706\n",
      "Epoch [81/100], Step [47/56], Loss: 0.1002\n",
      "Epoch [81/100], Step [48/56], Loss: 0.0802\n",
      "Epoch [81/100], Step [49/56], Loss: 0.0475\n",
      "Epoch [81/100], Step [50/56], Loss: 0.0599\n",
      "Epoch [81/100], Step [51/56], Loss: 0.0731\n",
      "Epoch [81/100], Step [52/56], Loss: 0.0495\n",
      "Epoch [81/100], Step [53/56], Loss: 0.0862\n",
      "Epoch [81/100], Step [54/56], Loss: 0.0567\n",
      "Epoch [81/100], Step [55/56], Loss: 0.0442\n",
      "Epoch [81/100], Step [56/56], Loss: 0.0211\n",
      "Val. loss :0.0580\n",
      "Epoch [82/100], Step [1/56], Loss: 0.0603\n",
      "Epoch [82/100], Step [2/56], Loss: 0.0586\n",
      "Epoch [82/100], Step [3/56], Loss: 0.0796\n",
      "Epoch [82/100], Step [4/56], Loss: 0.0676\n",
      "Epoch [82/100], Step [5/56], Loss: 0.0512\n",
      "Epoch [82/100], Step [6/56], Loss: 0.0975\n",
      "Epoch [82/100], Step [7/56], Loss: 0.0563\n",
      "Epoch [82/100], Step [8/56], Loss: 0.0823\n",
      "Epoch [82/100], Step [9/56], Loss: 0.1019\n",
      "Epoch [82/100], Step [10/56], Loss: 0.0424\n",
      "Epoch [82/100], Step [11/56], Loss: 0.0539\n",
      "Epoch [82/100], Step [12/56], Loss: 0.0698\n",
      "Epoch [82/100], Step [13/56], Loss: 0.0457\n",
      "Epoch [82/100], Step [14/56], Loss: 0.0432\n",
      "Epoch [82/100], Step [15/56], Loss: 0.0361\n",
      "Epoch [82/100], Step [16/56], Loss: 0.0401\n",
      "Epoch [82/100], Step [17/56], Loss: 0.0377\n",
      "Epoch [82/100], Step [18/56], Loss: 0.1032\n",
      "Epoch [82/100], Step [19/56], Loss: 0.0746\n",
      "Epoch [82/100], Step [20/56], Loss: 0.0852\n",
      "Epoch [82/100], Step [21/56], Loss: 0.0501\n",
      "Epoch [82/100], Step [22/56], Loss: 0.1207\n",
      "Epoch [82/100], Step [23/56], Loss: 0.1208\n",
      "Epoch [82/100], Step [24/56], Loss: 0.1784\n",
      "Epoch [82/100], Step [25/56], Loss: 0.0501\n",
      "Epoch [82/100], Step [26/56], Loss: 0.0476\n",
      "Epoch [82/100], Step [27/56], Loss: 0.0802\n",
      "Epoch [82/100], Step [28/56], Loss: 0.0585\n",
      "Epoch [82/100], Step [29/56], Loss: 0.0617\n",
      "Epoch [82/100], Step [30/56], Loss: 0.0399\n",
      "Epoch [82/100], Step [31/56], Loss: 0.0602\n",
      "Epoch [82/100], Step [32/56], Loss: 0.0442\n",
      "Epoch [82/100], Step [33/56], Loss: 0.0841\n",
      "Epoch [82/100], Step [34/56], Loss: 0.0405\n",
      "Epoch [82/100], Step [35/56], Loss: 0.0477\n",
      "Epoch [82/100], Step [36/56], Loss: 0.0727\n",
      "Epoch [82/100], Step [37/56], Loss: 0.0802\n",
      "Epoch [82/100], Step [38/56], Loss: 0.1836\n",
      "Epoch [82/100], Step [39/56], Loss: 0.0618\n",
      "Epoch [82/100], Step [40/56], Loss: 0.0492\n",
      "Epoch [82/100], Step [41/56], Loss: 0.0861\n",
      "Epoch [82/100], Step [42/56], Loss: 0.0525\n",
      "Epoch [82/100], Step [43/56], Loss: 0.0629\n",
      "Epoch [82/100], Step [44/56], Loss: 0.1009\n",
      "Epoch [82/100], Step [45/56], Loss: 0.0605\n",
      "Epoch [82/100], Step [46/56], Loss: 0.1542\n",
      "Epoch [82/100], Step [47/56], Loss: 0.1563\n",
      "Epoch [82/100], Step [48/56], Loss: 0.0895\n",
      "Epoch [82/100], Step [49/56], Loss: 0.0724\n",
      "Epoch [82/100], Step [50/56], Loss: 0.0572\n",
      "Epoch [82/100], Step [51/56], Loss: 0.0744\n",
      "Epoch [82/100], Step [52/56], Loss: 0.0688\n",
      "Epoch [82/100], Step [53/56], Loss: 0.0852\n",
      "Epoch [82/100], Step [54/56], Loss: 0.0450\n",
      "Epoch [82/100], Step [55/56], Loss: 0.1182\n",
      "Epoch [82/100], Step [56/56], Loss: 0.0562\n",
      "Val. loss :0.0725\n",
      "Epoch [83/100], Step [1/56], Loss: 0.0729\n",
      "Epoch [83/100], Step [2/56], Loss: 0.0435\n",
      "Epoch [83/100], Step [3/56], Loss: 0.0569\n",
      "Epoch [83/100], Step [4/56], Loss: 0.0719\n",
      "Epoch [83/100], Step [5/56], Loss: 0.0668\n",
      "Epoch [83/100], Step [6/56], Loss: 0.0583\n",
      "Epoch [83/100], Step [7/56], Loss: 0.0541\n",
      "Epoch [83/100], Step [8/56], Loss: 0.0755\n",
      "Epoch [83/100], Step [9/56], Loss: 0.0670\n",
      "Epoch [83/100], Step [10/56], Loss: 0.1773\n",
      "Epoch [83/100], Step [11/56], Loss: 0.0500\n",
      "Epoch [83/100], Step [12/56], Loss: 0.0525\n",
      "Epoch [83/100], Step [13/56], Loss: 0.0434\n",
      "Epoch [83/100], Step [14/56], Loss: 0.0604\n",
      "Epoch [83/100], Step [15/56], Loss: 0.1271\n",
      "Epoch [83/100], Step [16/56], Loss: 0.0693\n",
      "Epoch [83/100], Step [17/56], Loss: 0.1481\n",
      "Epoch [83/100], Step [18/56], Loss: 0.0526\n",
      "Epoch [83/100], Step [19/56], Loss: 0.0838\n",
      "Epoch [83/100], Step [20/56], Loss: 0.0637\n",
      "Epoch [83/100], Step [21/56], Loss: 0.2076\n",
      "Epoch [83/100], Step [22/56], Loss: 0.1622\n",
      "Epoch [83/100], Step [23/56], Loss: 0.0998\n",
      "Epoch [83/100], Step [24/56], Loss: 0.0655\n",
      "Epoch [83/100], Step [25/56], Loss: 0.0505\n",
      "Epoch [83/100], Step [26/56], Loss: 0.0456\n",
      "Epoch [83/100], Step [27/56], Loss: 0.1479\n",
      "Epoch [83/100], Step [28/56], Loss: 0.0483\n",
      "Epoch [83/100], Step [29/56], Loss: 0.0558\n",
      "Epoch [83/100], Step [30/56], Loss: 0.0856\n",
      "Epoch [83/100], Step [31/56], Loss: 0.0554\n",
      "Epoch [83/100], Step [32/56], Loss: 0.0583\n",
      "Epoch [83/100], Step [33/56], Loss: 0.0888\n",
      "Epoch [83/100], Step [34/56], Loss: 0.0671\n",
      "Epoch [83/100], Step [35/56], Loss: 0.0439\n",
      "Epoch [83/100], Step [36/56], Loss: 0.0476\n",
      "Epoch [83/100], Step [37/56], Loss: 0.0598\n",
      "Epoch [83/100], Step [38/56], Loss: 0.0809\n",
      "Epoch [83/100], Step [39/56], Loss: 0.1215\n",
      "Epoch [83/100], Step [40/56], Loss: 0.1128\n",
      "Epoch [83/100], Step [41/56], Loss: 0.0403\n",
      "Epoch [83/100], Step [42/56], Loss: 0.1829\n",
      "Epoch [83/100], Step [43/56], Loss: 0.0941\n",
      "Epoch [83/100], Step [44/56], Loss: 0.1018\n",
      "Epoch [83/100], Step [45/56], Loss: 0.0435\n",
      "Epoch [83/100], Step [46/56], Loss: 0.0475\n",
      "Epoch [83/100], Step [47/56], Loss: 0.0500\n",
      "Epoch [83/100], Step [48/56], Loss: 0.0500\n",
      "Epoch [83/100], Step [49/56], Loss: 0.1557\n",
      "Epoch [83/100], Step [50/56], Loss: 0.0441\n",
      "Epoch [83/100], Step [51/56], Loss: 0.0650\n",
      "Epoch [83/100], Step [52/56], Loss: 0.1086\n",
      "Epoch [83/100], Step [53/56], Loss: 0.0560\n",
      "Epoch [83/100], Step [54/56], Loss: 0.0689\n",
      "Epoch [83/100], Step [55/56], Loss: 0.0569\n",
      "Epoch [83/100], Step [56/56], Loss: 0.0346\n",
      "Val. loss :0.0825\n",
      "Epoch [84/100], Step [1/56], Loss: 0.0464\n",
      "Epoch [84/100], Step [2/56], Loss: 0.0611\n",
      "Epoch [84/100], Step [3/56], Loss: 0.0679\n",
      "Epoch [84/100], Step [4/56], Loss: 0.0522\n",
      "Epoch [84/100], Step [5/56], Loss: 0.0633\n",
      "Epoch [84/100], Step [6/56], Loss: 0.0820\n",
      "Epoch [84/100], Step [7/56], Loss: 0.0402\n",
      "Epoch [84/100], Step [8/56], Loss: 0.0527\n",
      "Epoch [84/100], Step [9/56], Loss: 0.0390\n",
      "Epoch [84/100], Step [10/56], Loss: 0.0572\n",
      "Epoch [84/100], Step [11/56], Loss: 0.0508\n",
      "Epoch [84/100], Step [12/56], Loss: 0.0740\n",
      "Epoch [84/100], Step [13/56], Loss: 0.0439\n",
      "Epoch [84/100], Step [14/56], Loss: 0.0580\n",
      "Epoch [84/100], Step [15/56], Loss: 0.0392\n",
      "Epoch [84/100], Step [16/56], Loss: 0.0568\n",
      "Epoch [84/100], Step [17/56], Loss: 0.1226\n",
      "Epoch [84/100], Step [18/56], Loss: 0.0435\n",
      "Epoch [84/100], Step [19/56], Loss: 0.0493\n",
      "Epoch [84/100], Step [20/56], Loss: 0.0937\n",
      "Epoch [84/100], Step [21/56], Loss: 0.0446\n",
      "Epoch [84/100], Step [22/56], Loss: 0.0419\n",
      "Epoch [84/100], Step [23/56], Loss: 0.1349\n",
      "Epoch [84/100], Step [24/56], Loss: 0.0494\n",
      "Epoch [84/100], Step [25/56], Loss: 0.0420\n",
      "Epoch [84/100], Step [26/56], Loss: 0.0807\n",
      "Epoch [84/100], Step [27/56], Loss: 0.1145\n",
      "Epoch [84/100], Step [28/56], Loss: 0.0767\n",
      "Epoch [84/100], Step [29/56], Loss: 0.0495\n",
      "Epoch [84/100], Step [30/56], Loss: 0.0402\n",
      "Epoch [84/100], Step [31/56], Loss: 0.0606\n",
      "Epoch [84/100], Step [32/56], Loss: 0.0958\n",
      "Epoch [84/100], Step [33/56], Loss: 0.0698\n",
      "Epoch [84/100], Step [34/56], Loss: 0.0541\n",
      "Epoch [84/100], Step [35/56], Loss: 0.0787\n",
      "Epoch [84/100], Step [36/56], Loss: 0.0627\n",
      "Epoch [84/100], Step [37/56], Loss: 0.0490\n",
      "Epoch [84/100], Step [38/56], Loss: 0.0996\n",
      "Epoch [84/100], Step [39/56], Loss: 0.1432\n",
      "Epoch [84/100], Step [40/56], Loss: 0.0470\n",
      "Epoch [84/100], Step [41/56], Loss: 0.0498\n",
      "Epoch [84/100], Step [42/56], Loss: 0.0915\n",
      "Epoch [84/100], Step [43/56], Loss: 0.0799\n",
      "Epoch [84/100], Step [44/56], Loss: 0.0472\n",
      "Epoch [84/100], Step [45/56], Loss: 0.0544\n",
      "Epoch [84/100], Step [46/56], Loss: 0.0458\n",
      "Epoch [84/100], Step [47/56], Loss: 0.0421\n",
      "Epoch [84/100], Step [48/56], Loss: 0.0522\n",
      "Epoch [84/100], Step [49/56], Loss: 0.0627\n",
      "Epoch [84/100], Step [50/56], Loss: 0.0690\n",
      "Epoch [84/100], Step [51/56], Loss: 0.0502\n",
      "Epoch [84/100], Step [52/56], Loss: 0.0382\n",
      "Epoch [84/100], Step [53/56], Loss: 0.0439\n",
      "Epoch [84/100], Step [54/56], Loss: 0.0598\n",
      "Epoch [84/100], Step [55/56], Loss: 0.0637\n",
      "Epoch [84/100], Step [56/56], Loss: 0.0312\n",
      "Val. loss :0.0436\n",
      "Epoch [85/100], Step [1/56], Loss: 0.0543\n",
      "Epoch [85/100], Step [2/56], Loss: 0.0670\n",
      "Epoch [85/100], Step [3/56], Loss: 0.0505\n",
      "Epoch [85/100], Step [4/56], Loss: 0.0774\n",
      "Epoch [85/100], Step [5/56], Loss: 0.1344\n",
      "Epoch [85/100], Step [6/56], Loss: 0.0562\n",
      "Epoch [85/100], Step [7/56], Loss: 0.1732\n",
      "Epoch [85/100], Step [8/56], Loss: 0.0574\n",
      "Epoch [85/100], Step [9/56], Loss: 0.0608\n",
      "Epoch [85/100], Step [10/56], Loss: 0.0608\n",
      "Epoch [85/100], Step [11/56], Loss: 0.0610\n",
      "Epoch [85/100], Step [12/56], Loss: 0.0578\n",
      "Epoch [85/100], Step [13/56], Loss: 0.0667\n",
      "Epoch [85/100], Step [14/56], Loss: 0.0431\n",
      "Epoch [85/100], Step [15/56], Loss: 0.0490\n",
      "Epoch [85/100], Step [16/56], Loss: 0.0553\n",
      "Epoch [85/100], Step [17/56], Loss: 0.0421\n",
      "Epoch [85/100], Step [18/56], Loss: 0.0488\n",
      "Epoch [85/100], Step [19/56], Loss: 0.0608\n",
      "Epoch [85/100], Step [20/56], Loss: 0.0673\n",
      "Epoch [85/100], Step [21/56], Loss: 0.0331\n",
      "Epoch [85/100], Step [22/56], Loss: 0.1098\n",
      "Epoch [85/100], Step [23/56], Loss: 0.0445\n",
      "Epoch [85/100], Step [24/56], Loss: 0.0445\n",
      "Epoch [85/100], Step [25/56], Loss: 0.0638\n",
      "Epoch [85/100], Step [26/56], Loss: 0.0503\n",
      "Epoch [85/100], Step [27/56], Loss: 0.0718\n",
      "Epoch [85/100], Step [28/56], Loss: 0.0727\n",
      "Epoch [85/100], Step [29/56], Loss: 0.1300\n",
      "Epoch [85/100], Step [30/56], Loss: 0.0480\n",
      "Epoch [85/100], Step [31/56], Loss: 0.0462\n",
      "Epoch [85/100], Step [32/56], Loss: 0.0672\n",
      "Epoch [85/100], Step [33/56], Loss: 0.1271\n",
      "Epoch [85/100], Step [34/56], Loss: 0.0497\n",
      "Epoch [85/100], Step [35/56], Loss: 0.0634\n",
      "Epoch [85/100], Step [36/56], Loss: 0.0618\n",
      "Epoch [85/100], Step [37/56], Loss: 0.0601\n",
      "Epoch [85/100], Step [38/56], Loss: 0.0469\n",
      "Epoch [85/100], Step [39/56], Loss: 0.1025\n",
      "Epoch [85/100], Step [40/56], Loss: 0.0929\n",
      "Epoch [85/100], Step [41/56], Loss: 0.1026\n",
      "Epoch [85/100], Step [42/56], Loss: 0.0687\n",
      "Epoch [85/100], Step [43/56], Loss: 0.0901\n",
      "Epoch [85/100], Step [44/56], Loss: 0.2616\n",
      "Epoch [85/100], Step [45/56], Loss: 0.1141\n",
      "Epoch [85/100], Step [46/56], Loss: 0.0700\n",
      "Epoch [85/100], Step [47/56], Loss: 0.0499\n",
      "Epoch [85/100], Step [48/56], Loss: 0.0630\n",
      "Epoch [85/100], Step [49/56], Loss: 0.0561\n",
      "Epoch [85/100], Step [50/56], Loss: 0.0986\n",
      "Epoch [85/100], Step [51/56], Loss: 0.0432\n",
      "Epoch [85/100], Step [52/56], Loss: 0.0699\n",
      "Epoch [85/100], Step [53/56], Loss: 0.0455\n",
      "Epoch [85/100], Step [54/56], Loss: 0.0438\n",
      "Epoch [85/100], Step [55/56], Loss: 0.1662\n",
      "Epoch [85/100], Step [56/56], Loss: 0.0449\n",
      "Val. loss :0.0717\n",
      "Epoch [86/100], Step [1/56], Loss: 0.1417\n",
      "Epoch [86/100], Step [2/56], Loss: 0.0568\n",
      "Epoch [86/100], Step [3/56], Loss: 0.0669\n",
      "Epoch [86/100], Step [4/56], Loss: 0.0461\n",
      "Epoch [86/100], Step [5/56], Loss: 0.1560\n",
      "Epoch [86/100], Step [6/56], Loss: 0.0496\n",
      "Epoch [86/100], Step [7/56], Loss: 0.0944\n",
      "Epoch [86/100], Step [8/56], Loss: 0.0610\n",
      "Epoch [86/100], Step [9/56], Loss: 0.0945\n",
      "Epoch [86/100], Step [10/56], Loss: 0.0896\n",
      "Epoch [86/100], Step [11/56], Loss: 0.0433\n",
      "Epoch [86/100], Step [12/56], Loss: 0.0581\n",
      "Epoch [86/100], Step [13/56], Loss: 0.1260\n",
      "Epoch [86/100], Step [14/56], Loss: 0.1100\n",
      "Epoch [86/100], Step [15/56], Loss: 0.0533\n",
      "Epoch [86/100], Step [16/56], Loss: 0.0523\n",
      "Epoch [86/100], Step [17/56], Loss: 0.0566\n",
      "Epoch [86/100], Step [18/56], Loss: 0.0941\n",
      "Epoch [86/100], Step [19/56], Loss: 0.2942\n",
      "Epoch [86/100], Step [20/56], Loss: 0.0516\n",
      "Epoch [86/100], Step [21/56], Loss: 0.0357\n",
      "Epoch [86/100], Step [22/56], Loss: 0.0489\n",
      "Epoch [86/100], Step [23/56], Loss: 0.0635\n",
      "Epoch [86/100], Step [24/56], Loss: 0.0662\n",
      "Epoch [86/100], Step [25/56], Loss: 0.1097\n",
      "Epoch [86/100], Step [26/56], Loss: 0.0692\n",
      "Epoch [86/100], Step [27/56], Loss: 0.0704\n",
      "Epoch [86/100], Step [28/56], Loss: 0.0726\n",
      "Epoch [86/100], Step [29/56], Loss: 0.0384\n",
      "Epoch [86/100], Step [30/56], Loss: 0.0556\n",
      "Epoch [86/100], Step [31/56], Loss: 0.0400\n",
      "Epoch [86/100], Step [32/56], Loss: 0.1157\n",
      "Epoch [86/100], Step [33/56], Loss: 0.0473\n",
      "Epoch [86/100], Step [34/56], Loss: 0.0882\n",
      "Epoch [86/100], Step [35/56], Loss: 0.0452\n",
      "Epoch [86/100], Step [36/56], Loss: 0.0586\n",
      "Epoch [86/100], Step [37/56], Loss: 0.1048\n",
      "Epoch [86/100], Step [38/56], Loss: 0.0491\n",
      "Epoch [86/100], Step [39/56], Loss: 0.0556\n",
      "Epoch [86/100], Step [40/56], Loss: 0.0579\n",
      "Epoch [86/100], Step [41/56], Loss: 0.0651\n",
      "Epoch [86/100], Step [42/56], Loss: 0.1260\n",
      "Epoch [86/100], Step [43/56], Loss: 0.1003\n",
      "Epoch [86/100], Step [44/56], Loss: 0.0692\n",
      "Epoch [86/100], Step [45/56], Loss: 0.0479\n",
      "Epoch [86/100], Step [46/56], Loss: 0.0424\n",
      "Epoch [86/100], Step [47/56], Loss: 0.0647\n",
      "Epoch [86/100], Step [48/56], Loss: 0.0794\n",
      "Epoch [86/100], Step [49/56], Loss: 0.0519\n",
      "Epoch [86/100], Step [50/56], Loss: 0.1011\n",
      "Epoch [86/100], Step [51/56], Loss: 0.1475\n",
      "Epoch [86/100], Step [52/56], Loss: 0.0446\n",
      "Epoch [86/100], Step [53/56], Loss: 0.0512\n",
      "Epoch [86/100], Step [54/56], Loss: 0.0664\n",
      "Epoch [86/100], Step [55/56], Loss: 0.0583\n",
      "Epoch [86/100], Step [56/56], Loss: 0.0815\n",
      "Val. loss :0.0662\n",
      "Epoch [87/100], Step [1/56], Loss: 0.0539\n",
      "Epoch [87/100], Step [2/56], Loss: 0.0496\n",
      "Epoch [87/100], Step [3/56], Loss: 0.0608\n",
      "Epoch [87/100], Step [4/56], Loss: 0.0593\n",
      "Epoch [87/100], Step [5/56], Loss: 0.0422\n",
      "Epoch [87/100], Step [6/56], Loss: 0.1466\n",
      "Epoch [87/100], Step [7/56], Loss: 0.0523\n",
      "Epoch [87/100], Step [8/56], Loss: 0.1313\n",
      "Epoch [87/100], Step [9/56], Loss: 0.0402\n",
      "Epoch [87/100], Step [10/56], Loss: 0.0495\n",
      "Epoch [87/100], Step [11/56], Loss: 0.1046\n",
      "Epoch [87/100], Step [12/56], Loss: 0.0885\n",
      "Epoch [87/100], Step [13/56], Loss: 0.0927\n",
      "Epoch [87/100], Step [14/56], Loss: 0.1144\n",
      "Epoch [87/100], Step [15/56], Loss: 0.0813\n",
      "Epoch [87/100], Step [16/56], Loss: 0.0566\n",
      "Epoch [87/100], Step [17/56], Loss: 0.1530\n",
      "Epoch [87/100], Step [18/56], Loss: 0.0652\n",
      "Epoch [87/100], Step [19/56], Loss: 0.1353\n",
      "Epoch [87/100], Step [20/56], Loss: 0.0615\n",
      "Epoch [87/100], Step [21/56], Loss: 0.0537\n",
      "Epoch [87/100], Step [22/56], Loss: 0.1681\n",
      "Epoch [87/100], Step [23/56], Loss: 0.0654\n",
      "Epoch [87/100], Step [24/56], Loss: 0.0542\n",
      "Epoch [87/100], Step [25/56], Loss: 0.1897\n",
      "Epoch [87/100], Step [26/56], Loss: 0.0804\n",
      "Epoch [87/100], Step [27/56], Loss: 0.1091\n",
      "Epoch [87/100], Step [28/56], Loss: 0.1092\n",
      "Epoch [87/100], Step [29/56], Loss: 0.0671\n",
      "Epoch [87/100], Step [30/56], Loss: 0.0574\n",
      "Epoch [87/100], Step [31/56], Loss: 0.1873\n",
      "Epoch [87/100], Step [32/56], Loss: 0.0608\n",
      "Epoch [87/100], Step [33/56], Loss: 0.0573\n",
      "Epoch [87/100], Step [34/56], Loss: 0.0505\n",
      "Epoch [87/100], Step [35/56], Loss: 0.1239\n",
      "Epoch [87/100], Step [36/56], Loss: 0.0450\n",
      "Epoch [87/100], Step [37/56], Loss: 0.0405\n",
      "Epoch [87/100], Step [38/56], Loss: 0.0829\n",
      "Epoch [87/100], Step [39/56], Loss: 0.1132\n",
      "Epoch [87/100], Step [40/56], Loss: 0.1672\n",
      "Epoch [87/100], Step [41/56], Loss: 0.0577\n",
      "Epoch [87/100], Step [42/56], Loss: 0.0557\n",
      "Epoch [87/100], Step [43/56], Loss: 0.2432\n",
      "Epoch [87/100], Step [44/56], Loss: 0.0943\n",
      "Epoch [87/100], Step [45/56], Loss: 0.0821\n",
      "Epoch [87/100], Step [46/56], Loss: 0.1773\n",
      "Epoch [87/100], Step [47/56], Loss: 0.0635\n",
      "Epoch [87/100], Step [48/56], Loss: 0.1919\n",
      "Epoch [87/100], Step [49/56], Loss: 0.0772\n",
      "Epoch [87/100], Step [50/56], Loss: 0.0577\n",
      "Epoch [87/100], Step [51/56], Loss: 0.1304\n",
      "Epoch [87/100], Step [52/56], Loss: 0.1125\n",
      "Epoch [87/100], Step [53/56], Loss: 0.1128\n",
      "Epoch [87/100], Step [54/56], Loss: 0.0669\n",
      "Epoch [87/100], Step [55/56], Loss: 0.0812\n",
      "Epoch [87/100], Step [56/56], Loss: 0.0583\n",
      "Val. loss :0.0957\n",
      "Epoch [88/100], Step [1/56], Loss: 0.0991\n",
      "Epoch [88/100], Step [2/56], Loss: 0.0577\n",
      "Epoch [88/100], Step [3/56], Loss: 0.0820\n",
      "Epoch [88/100], Step [4/56], Loss: 0.1402\n",
      "Epoch [88/100], Step [5/56], Loss: 0.0721\n",
      "Epoch [88/100], Step [6/56], Loss: 0.1878\n",
      "Epoch [88/100], Step [7/56], Loss: 0.0964\n",
      "Epoch [88/100], Step [8/56], Loss: 0.1950\n",
      "Epoch [88/100], Step [9/56], Loss: 0.0625\n",
      "Epoch [88/100], Step [10/56], Loss: 0.1412\n",
      "Epoch [88/100], Step [11/56], Loss: 0.1207\n",
      "Epoch [88/100], Step [12/56], Loss: 0.1290\n",
      "Epoch [88/100], Step [13/56], Loss: 0.0753\n",
      "Epoch [88/100], Step [14/56], Loss: 0.0903\n",
      "Epoch [88/100], Step [15/56], Loss: 0.0556\n",
      "Epoch [88/100], Step [16/56], Loss: 0.0704\n",
      "Epoch [88/100], Step [17/56], Loss: 0.0642\n",
      "Epoch [88/100], Step [18/56], Loss: 0.0704\n",
      "Epoch [88/100], Step [19/56], Loss: 0.0423\n",
      "Epoch [88/100], Step [20/56], Loss: 0.0760\n",
      "Epoch [88/100], Step [21/56], Loss: 0.0555\n",
      "Epoch [88/100], Step [22/56], Loss: 0.1177\n",
      "Epoch [88/100], Step [23/56], Loss: 0.1837\n",
      "Epoch [88/100], Step [24/56], Loss: 0.1364\n",
      "Epoch [88/100], Step [25/56], Loss: 0.0765\n",
      "Epoch [88/100], Step [26/56], Loss: 0.0513\n",
      "Epoch [88/100], Step [27/56], Loss: 0.1045\n",
      "Epoch [88/100], Step [28/56], Loss: 0.0775\n",
      "Epoch [88/100], Step [29/56], Loss: 0.0575\n",
      "Epoch [88/100], Step [30/56], Loss: 0.0561\n",
      "Epoch [88/100], Step [31/56], Loss: 0.0508\n",
      "Epoch [88/100], Step [32/56], Loss: 0.0472\n",
      "Epoch [88/100], Step [33/56], Loss: 0.0829\n",
      "Epoch [88/100], Step [34/56], Loss: 0.0766\n",
      "Epoch [88/100], Step [35/56], Loss: 0.0336\n",
      "Epoch [88/100], Step [36/56], Loss: 0.0483\n",
      "Epoch [88/100], Step [37/56], Loss: 0.1070\n",
      "Epoch [88/100], Step [38/56], Loss: 0.0615\n",
      "Epoch [88/100], Step [39/56], Loss: 0.0433\n",
      "Epoch [88/100], Step [40/56], Loss: 0.0722\n",
      "Epoch [88/100], Step [41/56], Loss: 0.0606\n",
      "Epoch [88/100], Step [42/56], Loss: 0.0642\n",
      "Epoch [88/100], Step [43/56], Loss: 0.0744\n",
      "Epoch [88/100], Step [44/56], Loss: 0.0552\n",
      "Epoch [88/100], Step [45/56], Loss: 0.0356\n",
      "Epoch [88/100], Step [46/56], Loss: 0.0544\n",
      "Epoch [88/100], Step [47/56], Loss: 0.0474\n",
      "Epoch [88/100], Step [48/56], Loss: 0.1031\n",
      "Epoch [88/100], Step [49/56], Loss: 0.0440\n",
      "Epoch [88/100], Step [50/56], Loss: 0.0759\n",
      "Epoch [88/100], Step [51/56], Loss: 0.0559\n",
      "Epoch [88/100], Step [52/56], Loss: 0.2194\n",
      "Epoch [88/100], Step [53/56], Loss: 0.0658\n",
      "Epoch [88/100], Step [54/56], Loss: 0.0419\n",
      "Epoch [88/100], Step [55/56], Loss: 0.0641\n",
      "Epoch [88/100], Step [56/56], Loss: 0.0416\n",
      "Val. loss :0.0570\n",
      "Epoch [89/100], Step [1/56], Loss: 0.0648\n",
      "Epoch [89/100], Step [2/56], Loss: 0.0464\n",
      "Epoch [89/100], Step [3/56], Loss: 0.0963\n",
      "Epoch [89/100], Step [4/56], Loss: 0.0546\n",
      "Epoch [89/100], Step [5/56], Loss: 0.0457\n",
      "Epoch [89/100], Step [6/56], Loss: 0.1378\n",
      "Epoch [89/100], Step [7/56], Loss: 0.0527\n",
      "Epoch [89/100], Step [8/56], Loss: 0.0522\n",
      "Epoch [89/100], Step [9/56], Loss: 0.0537\n",
      "Epoch [89/100], Step [10/56], Loss: 0.0951\n",
      "Epoch [89/100], Step [11/56], Loss: 0.0400\n",
      "Epoch [89/100], Step [12/56], Loss: 0.0899\n",
      "Epoch [89/100], Step [13/56], Loss: 0.1270\n",
      "Epoch [89/100], Step [14/56], Loss: 0.0384\n",
      "Epoch [89/100], Step [15/56], Loss: 0.0537\n",
      "Epoch [89/100], Step [16/56], Loss: 0.0596\n",
      "Epoch [89/100], Step [17/56], Loss: 0.0721\n",
      "Epoch [89/100], Step [18/56], Loss: 0.0542\n",
      "Epoch [89/100], Step [19/56], Loss: 0.1039\n",
      "Epoch [89/100], Step [20/56], Loss: 0.2111\n",
      "Epoch [89/100], Step [21/56], Loss: 0.0560\n",
      "Epoch [89/100], Step [22/56], Loss: 0.0589\n",
      "Epoch [89/100], Step [23/56], Loss: 0.0944\n",
      "Epoch [89/100], Step [24/56], Loss: 0.0532\n",
      "Epoch [89/100], Step [25/56], Loss: 0.1534\n",
      "Epoch [89/100], Step [26/56], Loss: 0.0713\n",
      "Epoch [89/100], Step [27/56], Loss: 0.0528\n",
      "Epoch [89/100], Step [28/56], Loss: 0.0730\n",
      "Epoch [89/100], Step [29/56], Loss: 0.0701\n",
      "Epoch [89/100], Step [30/56], Loss: 0.1161\n",
      "Epoch [89/100], Step [31/56], Loss: 0.0785\n",
      "Epoch [89/100], Step [32/56], Loss: 0.0835\n",
      "Epoch [89/100], Step [33/56], Loss: 0.0678\n",
      "Epoch [89/100], Step [34/56], Loss: 0.0641\n",
      "Epoch [89/100], Step [35/56], Loss: 0.0457\n",
      "Epoch [89/100], Step [36/56], Loss: 0.1005\n",
      "Epoch [89/100], Step [37/56], Loss: 0.0500\n",
      "Epoch [89/100], Step [38/56], Loss: 0.0842\n",
      "Epoch [89/100], Step [39/56], Loss: 0.0670\n",
      "Epoch [89/100], Step [40/56], Loss: 0.0722\n",
      "Epoch [89/100], Step [41/56], Loss: 0.0507\n",
      "Epoch [89/100], Step [42/56], Loss: 0.0444\n",
      "Epoch [89/100], Step [43/56], Loss: 0.0649\n",
      "Epoch [89/100], Step [44/56], Loss: 0.0684\n",
      "Epoch [89/100], Step [45/56], Loss: 0.0477\n",
      "Epoch [89/100], Step [46/56], Loss: 0.1095\n",
      "Epoch [89/100], Step [47/56], Loss: 0.0576\n",
      "Epoch [89/100], Step [48/56], Loss: 0.0446\n",
      "Epoch [89/100], Step [49/56], Loss: 0.0538\n",
      "Epoch [89/100], Step [50/56], Loss: 0.0943\n",
      "Epoch [89/100], Step [51/56], Loss: 0.0482\n",
      "Epoch [89/100], Step [52/56], Loss: 0.0596\n",
      "Epoch [89/100], Step [53/56], Loss: 0.0449\n",
      "Epoch [89/100], Step [54/56], Loss: 0.0413\n",
      "Epoch [89/100], Step [55/56], Loss: 0.0614\n",
      "Epoch [89/100], Step [56/56], Loss: 0.0437\n",
      "Val. loss :0.0648\n",
      "Epoch [90/100], Step [1/56], Loss: 0.1777\n",
      "Epoch [90/100], Step [2/56], Loss: 0.1039\n",
      "Epoch [90/100], Step [3/56], Loss: 0.0390\n",
      "Epoch [90/100], Step [4/56], Loss: 0.0452\n",
      "Epoch [90/100], Step [5/56], Loss: 0.0530\n",
      "Epoch [90/100], Step [6/56], Loss: 0.1612\n",
      "Epoch [90/100], Step [7/56], Loss: 0.0402\n",
      "Epoch [90/100], Step [8/56], Loss: 0.0626\n",
      "Epoch [90/100], Step [9/56], Loss: 0.0473\n",
      "Epoch [90/100], Step [10/56], Loss: 0.0965\n",
      "Epoch [90/100], Step [11/56], Loss: 0.0486\n",
      "Epoch [90/100], Step [12/56], Loss: 0.0580\n",
      "Epoch [90/100], Step [13/56], Loss: 0.0555\n",
      "Epoch [90/100], Step [14/56], Loss: 0.1020\n",
      "Epoch [90/100], Step [15/56], Loss: 0.0786\n",
      "Epoch [90/100], Step [16/56], Loss: 0.0437\n",
      "Epoch [90/100], Step [17/56], Loss: 0.1331\n",
      "Epoch [90/100], Step [18/56], Loss: 0.0560\n",
      "Epoch [90/100], Step [19/56], Loss: 0.0933\n",
      "Epoch [90/100], Step [20/56], Loss: 0.0489\n",
      "Epoch [90/100], Step [21/56], Loss: 0.0537\n",
      "Epoch [90/100], Step [22/56], Loss: 0.0558\n",
      "Epoch [90/100], Step [23/56], Loss: 0.0507\n",
      "Epoch [90/100], Step [24/56], Loss: 0.0748\n",
      "Epoch [90/100], Step [25/56], Loss: 0.0629\n",
      "Epoch [90/100], Step [26/56], Loss: 0.0782\n",
      "Epoch [90/100], Step [27/56], Loss: 0.0549\n",
      "Epoch [90/100], Step [28/56], Loss: 0.0708\n",
      "Epoch [90/100], Step [29/56], Loss: 0.0618\n",
      "Epoch [90/100], Step [30/56], Loss: 0.1158\n",
      "Epoch [90/100], Step [31/56], Loss: 0.0976\n",
      "Epoch [90/100], Step [32/56], Loss: 0.1711\n",
      "Epoch [90/100], Step [33/56], Loss: 0.1478\n",
      "Epoch [90/100], Step [34/56], Loss: 0.0526\n",
      "Epoch [90/100], Step [35/56], Loss: 0.0428\n",
      "Epoch [90/100], Step [36/56], Loss: 0.0947\n",
      "Epoch [90/100], Step [37/56], Loss: 0.0773\n",
      "Epoch [90/100], Step [38/56], Loss: 0.0494\n",
      "Epoch [90/100], Step [39/56], Loss: 0.0615\n",
      "Epoch [90/100], Step [40/56], Loss: 0.0602\n",
      "Epoch [90/100], Step [41/56], Loss: 0.0433\n",
      "Epoch [90/100], Step [42/56], Loss: 0.0550\n",
      "Epoch [90/100], Step [43/56], Loss: 0.0502\n",
      "Epoch [90/100], Step [44/56], Loss: 0.0469\n",
      "Epoch [90/100], Step [45/56], Loss: 0.0746\n",
      "Epoch [90/100], Step [46/56], Loss: 0.0451\n",
      "Epoch [90/100], Step [47/56], Loss: 0.0498\n",
      "Epoch [90/100], Step [48/56], Loss: 0.0597\n",
      "Epoch [90/100], Step [49/56], Loss: 0.0456\n",
      "Epoch [90/100], Step [50/56], Loss: 0.1334\n",
      "Epoch [90/100], Step [51/56], Loss: 0.0521\n",
      "Epoch [90/100], Step [52/56], Loss: 0.0457\n",
      "Epoch [90/100], Step [53/56], Loss: 0.0568\n",
      "Epoch [90/100], Step [54/56], Loss: 0.0754\n",
      "Epoch [90/100], Step [55/56], Loss: 0.0737\n",
      "Epoch [90/100], Step [56/56], Loss: 0.0283\n",
      "Val. loss :0.0466\n",
      "Epoch [91/100], Step [1/56], Loss: 0.0451\n",
      "Epoch [91/100], Step [2/56], Loss: 0.1133\n",
      "Epoch [91/100], Step [3/56], Loss: 0.0707\n",
      "Epoch [91/100], Step [4/56], Loss: 0.0513\n",
      "Epoch [91/100], Step [5/56], Loss: 0.0558\n",
      "Epoch [91/100], Step [6/56], Loss: 0.0377\n",
      "Epoch [91/100], Step [7/56], Loss: 0.0562\n",
      "Epoch [91/100], Step [8/56], Loss: 0.0732\n",
      "Epoch [91/100], Step [9/56], Loss: 0.1876\n",
      "Epoch [91/100], Step [10/56], Loss: 0.0569\n",
      "Epoch [91/100], Step [11/56], Loss: 0.0708\n",
      "Epoch [91/100], Step [12/56], Loss: 0.1733\n",
      "Epoch [91/100], Step [13/56], Loss: 0.1225\n",
      "Epoch [91/100], Step [14/56], Loss: 0.0639\n",
      "Epoch [91/100], Step [15/56], Loss: 0.1348\n",
      "Epoch [91/100], Step [16/56], Loss: 0.0536\n",
      "Epoch [91/100], Step [17/56], Loss: 0.2016\n",
      "Epoch [91/100], Step [18/56], Loss: 0.0802\n",
      "Epoch [91/100], Step [19/56], Loss: 0.1068\n",
      "Epoch [91/100], Step [20/56], Loss: 0.0829\n",
      "Epoch [91/100], Step [21/56], Loss: 0.1104\n",
      "Epoch [91/100], Step [22/56], Loss: 0.1254\n",
      "Epoch [91/100], Step [23/56], Loss: 0.0803\n",
      "Epoch [91/100], Step [24/56], Loss: 0.2036\n",
      "Epoch [91/100], Step [25/56], Loss: 0.0926\n",
      "Epoch [91/100], Step [26/56], Loss: 0.0643\n",
      "Epoch [91/100], Step [27/56], Loss: 0.0798\n",
      "Epoch [91/100], Step [28/56], Loss: 0.0671\n",
      "Epoch [91/100], Step [29/56], Loss: 0.1036\n",
      "Epoch [91/100], Step [30/56], Loss: 0.2933\n",
      "Epoch [91/100], Step [31/56], Loss: 0.0820\n",
      "Epoch [91/100], Step [32/56], Loss: 0.0450\n",
      "Epoch [91/100], Step [33/56], Loss: 0.0610\n",
      "Epoch [91/100], Step [34/56], Loss: 0.1139\n",
      "Epoch [91/100], Step [35/56], Loss: 0.0582\n",
      "Epoch [91/100], Step [36/56], Loss: 0.0718\n",
      "Epoch [91/100], Step [37/56], Loss: 0.0662\n",
      "Epoch [91/100], Step [38/56], Loss: 0.0801\n",
      "Epoch [91/100], Step [39/56], Loss: 0.0858\n",
      "Epoch [91/100], Step [40/56], Loss: 0.0489\n",
      "Epoch [91/100], Step [41/56], Loss: 0.0485\n",
      "Epoch [91/100], Step [42/56], Loss: 0.0671\n",
      "Epoch [91/100], Step [43/56], Loss: 0.0427\n",
      "Epoch [91/100], Step [44/56], Loss: 0.0565\n",
      "Epoch [91/100], Step [45/56], Loss: 0.1056\n",
      "Epoch [91/100], Step [46/56], Loss: 0.0502\n",
      "Epoch [91/100], Step [47/56], Loss: 0.1076\n",
      "Epoch [91/100], Step [48/56], Loss: 0.0360\n",
      "Epoch [91/100], Step [49/56], Loss: 0.0454\n",
      "Epoch [91/100], Step [50/56], Loss: 0.0613\n",
      "Epoch [91/100], Step [51/56], Loss: 0.0713\n",
      "Epoch [91/100], Step [52/56], Loss: 0.0529\n",
      "Epoch [91/100], Step [53/56], Loss: 0.1403\n",
      "Epoch [91/100], Step [54/56], Loss: 0.0994\n",
      "Epoch [91/100], Step [55/56], Loss: 0.0471\n",
      "Epoch [91/100], Step [56/56], Loss: 0.0466\n",
      "Val. loss :0.0662\n",
      "Epoch [92/100], Step [1/56], Loss: 0.0532\n",
      "Epoch [92/100], Step [2/56], Loss: 0.0965\n",
      "Epoch [92/100], Step [3/56], Loss: 0.0866\n",
      "Epoch [92/100], Step [4/56], Loss: 0.0331\n",
      "Epoch [92/100], Step [5/56], Loss: 0.1357\n",
      "Epoch [92/100], Step [6/56], Loss: 0.0902\n",
      "Epoch [92/100], Step [7/56], Loss: 0.0461\n",
      "Epoch [92/100], Step [8/56], Loss: 0.0780\n",
      "Epoch [92/100], Step [9/56], Loss: 0.0438\n",
      "Epoch [92/100], Step [10/56], Loss: 0.0470\n",
      "Epoch [92/100], Step [11/56], Loss: 0.0783\n",
      "Epoch [92/100], Step [12/56], Loss: 0.1316\n",
      "Epoch [92/100], Step [13/56], Loss: 0.1076\n",
      "Epoch [92/100], Step [14/56], Loss: 0.0395\n",
      "Epoch [92/100], Step [15/56], Loss: 0.1698\n",
      "Epoch [92/100], Step [16/56], Loss: 0.1260\n",
      "Epoch [92/100], Step [17/56], Loss: 0.0431\n",
      "Epoch [92/100], Step [18/56], Loss: 0.1344\n",
      "Epoch [92/100], Step [19/56], Loss: 0.0539\n",
      "Epoch [92/100], Step [20/56], Loss: 0.1388\n",
      "Epoch [92/100], Step [21/56], Loss: 0.0387\n",
      "Epoch [92/100], Step [22/56], Loss: 0.0447\n",
      "Epoch [92/100], Step [23/56], Loss: 0.0434\n",
      "Epoch [92/100], Step [24/56], Loss: 0.0519\n",
      "Epoch [92/100], Step [25/56], Loss: 0.0562\n",
      "Epoch [92/100], Step [26/56], Loss: 0.0486\n",
      "Epoch [92/100], Step [27/56], Loss: 0.0420\n",
      "Epoch [92/100], Step [28/56], Loss: 0.0695\n",
      "Epoch [92/100], Step [29/56], Loss: 0.0438\n",
      "Epoch [92/100], Step [30/56], Loss: 0.0835\n",
      "Epoch [92/100], Step [31/56], Loss: 0.0437\n",
      "Epoch [92/100], Step [32/56], Loss: 0.0594\n",
      "Epoch [92/100], Step [33/56], Loss: 0.0411\n",
      "Epoch [92/100], Step [34/56], Loss: 0.0550\n",
      "Epoch [92/100], Step [35/56], Loss: 0.0438\n",
      "Epoch [92/100], Step [36/56], Loss: 0.0405\n",
      "Epoch [92/100], Step [37/56], Loss: 0.0627\n",
      "Epoch [92/100], Step [38/56], Loss: 0.1009\n",
      "Epoch [92/100], Step [39/56], Loss: 0.0682\n",
      "Epoch [92/100], Step [40/56], Loss: 0.0389\n",
      "Epoch [92/100], Step [41/56], Loss: 0.1094\n",
      "Epoch [92/100], Step [42/56], Loss: 0.0606\n",
      "Epoch [92/100], Step [43/56], Loss: 0.0339\n",
      "Epoch [92/100], Step [44/56], Loss: 0.0454\n",
      "Epoch [92/100], Step [45/56], Loss: 0.0338\n",
      "Epoch [92/100], Step [46/56], Loss: 0.0410\n",
      "Epoch [92/100], Step [47/56], Loss: 0.0675\n",
      "Epoch [92/100], Step [48/56], Loss: 0.0892\n",
      "Epoch [92/100], Step [49/56], Loss: 0.0561\n",
      "Epoch [92/100], Step [50/56], Loss: 0.0837\n",
      "Epoch [92/100], Step [51/56], Loss: 0.0634\n",
      "Epoch [92/100], Step [52/56], Loss: 0.0815\n",
      "Epoch [92/100], Step [53/56], Loss: 0.2028\n",
      "Epoch [92/100], Step [54/56], Loss: 0.0904\n",
      "Epoch [92/100], Step [55/56], Loss: 0.0875\n",
      "Epoch [92/100], Step [56/56], Loss: 0.0255\n",
      "Val. loss :0.0575\n",
      "Epoch [93/100], Step [1/56], Loss: 0.0630\n",
      "Epoch [93/100], Step [2/56], Loss: 0.0386\n",
      "Epoch [93/100], Step [3/56], Loss: 0.1975\n",
      "Epoch [93/100], Step [4/56], Loss: 0.0682\n",
      "Epoch [93/100], Step [5/56], Loss: 0.0917\n",
      "Epoch [93/100], Step [6/56], Loss: 0.0455\n",
      "Epoch [93/100], Step [7/56], Loss: 0.0507\n",
      "Epoch [93/100], Step [8/56], Loss: 0.0529\n",
      "Epoch [93/100], Step [9/56], Loss: 0.0517\n",
      "Epoch [93/100], Step [10/56], Loss: 0.0663\n",
      "Epoch [93/100], Step [11/56], Loss: 0.0464\n",
      "Epoch [93/100], Step [12/56], Loss: 0.0766\n",
      "Epoch [93/100], Step [13/56], Loss: 0.2268\n",
      "Epoch [93/100], Step [14/56], Loss: 0.1878\n",
      "Epoch [93/100], Step [15/56], Loss: 0.0562\n",
      "Epoch [93/100], Step [16/56], Loss: 0.0588\n",
      "Epoch [93/100], Step [17/56], Loss: 0.0595\n",
      "Epoch [93/100], Step [18/56], Loss: 0.0900\n",
      "Epoch [93/100], Step [19/56], Loss: 0.0656\n",
      "Epoch [93/100], Step [20/56], Loss: 0.0804\n",
      "Epoch [93/100], Step [21/56], Loss: 0.0645\n",
      "Epoch [93/100], Step [22/56], Loss: 0.0703\n",
      "Epoch [93/100], Step [23/56], Loss: 0.2068\n",
      "Epoch [93/100], Step [24/56], Loss: 0.0775\n",
      "Epoch [93/100], Step [25/56], Loss: 0.0474\n",
      "Epoch [93/100], Step [26/56], Loss: 0.0615\n",
      "Epoch [93/100], Step [27/56], Loss: 0.0671\n",
      "Epoch [93/100], Step [28/56], Loss: 0.0470\n",
      "Epoch [93/100], Step [29/56], Loss: 0.0774\n",
      "Epoch [93/100], Step [30/56], Loss: 0.1315\n",
      "Epoch [93/100], Step [31/56], Loss: 0.0485\n",
      "Epoch [93/100], Step [32/56], Loss: 0.1077\n",
      "Epoch [93/100], Step [33/56], Loss: 0.0639\n",
      "Epoch [93/100], Step [34/56], Loss: 0.0593\n",
      "Epoch [93/100], Step [35/56], Loss: 0.0607\n",
      "Epoch [93/100], Step [36/56], Loss: 0.0828\n",
      "Epoch [93/100], Step [37/56], Loss: 0.1051\n",
      "Epoch [93/100], Step [38/56], Loss: 0.0686\n",
      "Epoch [93/100], Step [39/56], Loss: 0.1587\n",
      "Epoch [93/100], Step [40/56], Loss: 0.0518\n",
      "Epoch [93/100], Step [41/56], Loss: 0.0828\n",
      "Epoch [93/100], Step [42/56], Loss: 0.0606\n",
      "Epoch [93/100], Step [43/56], Loss: 0.0368\n",
      "Epoch [93/100], Step [44/56], Loss: 0.0471\n",
      "Epoch [93/100], Step [45/56], Loss: 0.0632\n",
      "Epoch [93/100], Step [46/56], Loss: 0.0456\n",
      "Epoch [93/100], Step [47/56], Loss: 0.0466\n",
      "Epoch [93/100], Step [48/56], Loss: 0.0367\n",
      "Epoch [93/100], Step [49/56], Loss: 0.0872\n",
      "Epoch [93/100], Step [50/56], Loss: 0.0693\n",
      "Epoch [93/100], Step [51/56], Loss: 0.0568\n",
      "Epoch [93/100], Step [52/56], Loss: 0.0944\n",
      "Epoch [93/100], Step [53/56], Loss: 0.0762\n",
      "Epoch [93/100], Step [54/56], Loss: 0.0449\n",
      "Epoch [93/100], Step [55/56], Loss: 0.0596\n",
      "Epoch [93/100], Step [56/56], Loss: 0.0228\n",
      "Val. loss :0.0558\n",
      "Epoch [94/100], Step [1/56], Loss: 0.1189\n",
      "Epoch [94/100], Step [2/56], Loss: 0.1257\n",
      "Epoch [94/100], Step [3/56], Loss: 0.0554\n",
      "Epoch [94/100], Step [4/56], Loss: 0.0553\n",
      "Epoch [94/100], Step [5/56], Loss: 0.1489\n",
      "Epoch [94/100], Step [6/56], Loss: 0.0611\n",
      "Epoch [94/100], Step [7/56], Loss: 0.0474\n",
      "Epoch [94/100], Step [8/56], Loss: 0.0433\n",
      "Epoch [94/100], Step [9/56], Loss: 0.0745\n",
      "Epoch [94/100], Step [10/56], Loss: 0.0347\n",
      "Epoch [94/100], Step [11/56], Loss: 0.0539\n",
      "Epoch [94/100], Step [12/56], Loss: 0.0664\n",
      "Epoch [94/100], Step [13/56], Loss: 0.0707\n",
      "Epoch [94/100], Step [14/56], Loss: 0.0742\n",
      "Epoch [94/100], Step [15/56], Loss: 0.0487\n",
      "Epoch [94/100], Step [16/56], Loss: 0.0398\n",
      "Epoch [94/100], Step [17/56], Loss: 0.0758\n",
      "Epoch [94/100], Step [18/56], Loss: 0.0727\n",
      "Epoch [94/100], Step [19/56], Loss: 0.0713\n",
      "Epoch [94/100], Step [20/56], Loss: 0.1086\n",
      "Epoch [94/100], Step [21/56], Loss: 0.0509\n",
      "Epoch [94/100], Step [22/56], Loss: 0.0529\n",
      "Epoch [94/100], Step [23/56], Loss: 0.0572\n",
      "Epoch [94/100], Step [24/56], Loss: 0.0397\n",
      "Epoch [94/100], Step [25/56], Loss: 0.0567\n",
      "Epoch [94/100], Step [26/56], Loss: 0.0426\n",
      "Epoch [94/100], Step [27/56], Loss: 0.0764\n",
      "Epoch [94/100], Step [28/56], Loss: 0.0563\n",
      "Epoch [94/100], Step [29/56], Loss: 0.0711\n",
      "Epoch [94/100], Step [30/56], Loss: 0.0406\n",
      "Epoch [94/100], Step [31/56], Loss: 0.0718\n",
      "Epoch [94/100], Step [32/56], Loss: 0.0510\n",
      "Epoch [94/100], Step [33/56], Loss: 0.0475\n",
      "Epoch [94/100], Step [34/56], Loss: 0.0557\n",
      "Epoch [94/100], Step [35/56], Loss: 0.0518\n",
      "Epoch [94/100], Step [36/56], Loss: 0.0403\n",
      "Epoch [94/100], Step [37/56], Loss: 0.1525\n",
      "Epoch [94/100], Step [38/56], Loss: 0.0500\n",
      "Epoch [94/100], Step [39/56], Loss: 0.0457\n",
      "Epoch [94/100], Step [40/56], Loss: 0.0394\n",
      "Epoch [94/100], Step [41/56], Loss: 0.0356\n",
      "Epoch [94/100], Step [42/56], Loss: 0.0809\n",
      "Epoch [94/100], Step [43/56], Loss: 0.0555\n",
      "Epoch [94/100], Step [44/56], Loss: 0.0462\n",
      "Epoch [94/100], Step [45/56], Loss: 0.3631\n",
      "Epoch [94/100], Step [46/56], Loss: 0.0687\n",
      "Epoch [94/100], Step [47/56], Loss: 0.0356\n",
      "Epoch [94/100], Step [48/56], Loss: 0.0694\n",
      "Epoch [94/100], Step [49/56], Loss: 0.0523\n",
      "Epoch [94/100], Step [50/56], Loss: 0.0793\n",
      "Epoch [94/100], Step [51/56], Loss: 0.0613\n",
      "Epoch [94/100], Step [52/56], Loss: 0.0678\n",
      "Epoch [94/100], Step [53/56], Loss: 0.1251\n",
      "Epoch [94/100], Step [54/56], Loss: 0.0812\n",
      "Epoch [94/100], Step [55/56], Loss: 0.0935\n",
      "Epoch [94/100], Step [56/56], Loss: 0.0202\n",
      "Val. loss :0.0504\n",
      "Epoch [95/100], Step [1/56], Loss: 0.0433\n",
      "Epoch [95/100], Step [2/56], Loss: 0.0572\n",
      "Epoch [95/100], Step [3/56], Loss: 0.0662\n",
      "Epoch [95/100], Step [4/56], Loss: 0.0664\n",
      "Epoch [95/100], Step [5/56], Loss: 0.1276\n",
      "Epoch [95/100], Step [6/56], Loss: 0.0409\n",
      "Epoch [95/100], Step [7/56], Loss: 0.0654\n",
      "Epoch [95/100], Step [8/56], Loss: 0.0618\n",
      "Epoch [95/100], Step [9/56], Loss: 0.0456\n",
      "Epoch [95/100], Step [10/56], Loss: 0.0410\n",
      "Epoch [95/100], Step [11/56], Loss: 0.0523\n",
      "Epoch [95/100], Step [12/56], Loss: 0.1402\n",
      "Epoch [95/100], Step [13/56], Loss: 0.0534\n",
      "Epoch [95/100], Step [14/56], Loss: 0.0627\n",
      "Epoch [95/100], Step [15/56], Loss: 0.0807\n",
      "Epoch [95/100], Step [16/56], Loss: 0.0873\n",
      "Epoch [95/100], Step [17/56], Loss: 0.0557\n",
      "Epoch [95/100], Step [18/56], Loss: 0.0465\n",
      "Epoch [95/100], Step [19/56], Loss: 0.0956\n",
      "Epoch [95/100], Step [20/56], Loss: 0.0607\n",
      "Epoch [95/100], Step [21/56], Loss: 0.0643\n",
      "Epoch [95/100], Step [22/56], Loss: 0.0864\n",
      "Epoch [95/100], Step [23/56], Loss: 0.1416\n",
      "Epoch [95/100], Step [24/56], Loss: 0.0595\n",
      "Epoch [95/100], Step [25/56], Loss: 0.0621\n",
      "Epoch [95/100], Step [26/56], Loss: 0.0551\n",
      "Epoch [95/100], Step [27/56], Loss: 0.0418\n",
      "Epoch [95/100], Step [28/56], Loss: 0.1641\n",
      "Epoch [95/100], Step [29/56], Loss: 0.0739\n",
      "Epoch [95/100], Step [30/56], Loss: 0.0628\n",
      "Epoch [95/100], Step [31/56], Loss: 0.1229\n",
      "Epoch [95/100], Step [32/56], Loss: 0.0732\n",
      "Epoch [95/100], Step [33/56], Loss: 0.0469\n",
      "Epoch [95/100], Step [34/56], Loss: 0.0465\n",
      "Epoch [95/100], Step [35/56], Loss: 0.0996\n",
      "Epoch [95/100], Step [36/56], Loss: 0.0679\n",
      "Epoch [95/100], Step [37/56], Loss: 0.0479\n",
      "Epoch [95/100], Step [38/56], Loss: 0.0614\n",
      "Epoch [95/100], Step [39/56], Loss: 0.0642\n",
      "Epoch [95/100], Step [40/56], Loss: 0.0875\n",
      "Epoch [95/100], Step [41/56], Loss: 0.2925\n",
      "Epoch [95/100], Step [42/56], Loss: 0.0410\n",
      "Epoch [95/100], Step [43/56], Loss: 0.1031\n",
      "Epoch [95/100], Step [44/56], Loss: 0.0489\n",
      "Epoch [95/100], Step [45/56], Loss: 0.0680\n",
      "Epoch [95/100], Step [46/56], Loss: 0.0684\n",
      "Epoch [95/100], Step [47/56], Loss: 0.0506\n",
      "Epoch [95/100], Step [48/56], Loss: 0.1472\n",
      "Epoch [95/100], Step [49/56], Loss: 0.0420\n",
      "Epoch [95/100], Step [50/56], Loss: 0.1139\n",
      "Epoch [95/100], Step [51/56], Loss: 0.0453\n",
      "Epoch [95/100], Step [52/56], Loss: 0.0545\n",
      "Epoch [95/100], Step [53/56], Loss: 0.0747\n",
      "Epoch [95/100], Step [54/56], Loss: 0.1280\n",
      "Epoch [95/100], Step [55/56], Loss: 0.0433\n",
      "Epoch [95/100], Step [56/56], Loss: 0.0401\n",
      "Val. loss :0.0605\n",
      "Epoch [96/100], Step [1/56], Loss: 0.1064\n",
      "Epoch [96/100], Step [2/56], Loss: 0.0434\n",
      "Epoch [96/100], Step [3/56], Loss: 0.0902\n",
      "Epoch [96/100], Step [4/56], Loss: 0.0451\n",
      "Epoch [96/100], Step [5/56], Loss: 0.0460\n",
      "Epoch [96/100], Step [6/56], Loss: 0.1433\n",
      "Epoch [96/100], Step [7/56], Loss: 0.0645\n",
      "Epoch [96/100], Step [8/56], Loss: 0.0503\n",
      "Epoch [96/100], Step [9/56], Loss: 0.0529\n",
      "Epoch [96/100], Step [10/56], Loss: 0.0879\n",
      "Epoch [96/100], Step [11/56], Loss: 0.1395\n",
      "Epoch [96/100], Step [12/56], Loss: 0.0670\n",
      "Epoch [96/100], Step [13/56], Loss: 0.0665\n",
      "Epoch [96/100], Step [14/56], Loss: 0.0494\n",
      "Epoch [96/100], Step [15/56], Loss: 0.0461\n",
      "Epoch [96/100], Step [16/56], Loss: 0.0506\n",
      "Epoch [96/100], Step [17/56], Loss: 0.0468\n",
      "Epoch [96/100], Step [18/56], Loss: 0.0614\n",
      "Epoch [96/100], Step [19/56], Loss: 0.0463\n",
      "Epoch [96/100], Step [20/56], Loss: 0.1651\n",
      "Epoch [96/100], Step [21/56], Loss: 0.0427\n",
      "Epoch [96/100], Step [22/56], Loss: 0.0978\n",
      "Epoch [96/100], Step [23/56], Loss: 0.0628\n",
      "Epoch [96/100], Step [24/56], Loss: 0.0658\n",
      "Epoch [96/100], Step [25/56], Loss: 0.0446\n",
      "Epoch [96/100], Step [26/56], Loss: 0.0445\n",
      "Epoch [96/100], Step [27/56], Loss: 0.0673\n",
      "Epoch [96/100], Step [28/56], Loss: 0.1502\n",
      "Epoch [96/100], Step [29/56], Loss: 0.0368\n",
      "Epoch [96/100], Step [30/56], Loss: 0.0408\n",
      "Epoch [96/100], Step [31/56], Loss: 0.0342\n",
      "Epoch [96/100], Step [32/56], Loss: 0.0616\n",
      "Epoch [96/100], Step [33/56], Loss: 0.1539\n",
      "Epoch [96/100], Step [34/56], Loss: 0.0733\n",
      "Epoch [96/100], Step [35/56], Loss: 0.0558\n",
      "Epoch [96/100], Step [36/56], Loss: 0.0495\n",
      "Epoch [96/100], Step [37/56], Loss: 0.1302\n",
      "Epoch [96/100], Step [38/56], Loss: 0.0647\n",
      "Epoch [96/100], Step [39/56], Loss: 0.1958\n",
      "Epoch [96/100], Step [40/56], Loss: 0.0477\n",
      "Epoch [96/100], Step [41/56], Loss: 0.1070\n",
      "Epoch [96/100], Step [42/56], Loss: 0.1345\n",
      "Epoch [96/100], Step [43/56], Loss: 0.0385\n",
      "Epoch [96/100], Step [44/56], Loss: 0.0520\n",
      "Epoch [96/100], Step [45/56], Loss: 0.0458\n",
      "Epoch [96/100], Step [46/56], Loss: 0.0524\n",
      "Epoch [96/100], Step [47/56], Loss: 0.1224\n",
      "Epoch [96/100], Step [48/56], Loss: 0.0908\n",
      "Epoch [96/100], Step [49/56], Loss: 0.1723\n",
      "Epoch [96/100], Step [50/56], Loss: 0.0593\n",
      "Epoch [96/100], Step [51/56], Loss: 0.0445\n",
      "Epoch [96/100], Step [52/56], Loss: 0.0776\n",
      "Epoch [96/100], Step [53/56], Loss: 0.0665\n",
      "Epoch [96/100], Step [54/56], Loss: 0.0409\n",
      "Epoch [96/100], Step [55/56], Loss: 0.0495\n",
      "Epoch [96/100], Step [56/56], Loss: 0.0243\n",
      "Val. loss :0.0540\n",
      "Epoch [97/100], Step [1/56], Loss: 0.1750\n",
      "Epoch [97/100], Step [2/56], Loss: 0.0709\n",
      "Epoch [97/100], Step [3/56], Loss: 0.0572\n",
      "Epoch [97/100], Step [4/56], Loss: 0.0434\n",
      "Epoch [97/100], Step [5/56], Loss: 0.0704\n",
      "Epoch [97/100], Step [6/56], Loss: 0.0702\n",
      "Epoch [97/100], Step [7/56], Loss: 0.1807\n",
      "Epoch [97/100], Step [8/56], Loss: 0.0483\n",
      "Epoch [97/100], Step [9/56], Loss: 0.0884\n",
      "Epoch [97/100], Step [10/56], Loss: 0.1445\n",
      "Epoch [97/100], Step [11/56], Loss: 0.1155\n",
      "Epoch [97/100], Step [12/56], Loss: 0.0626\n",
      "Epoch [97/100], Step [13/56], Loss: 0.1544\n",
      "Epoch [97/100], Step [14/56], Loss: 0.1843\n",
      "Epoch [97/100], Step [15/56], Loss: 0.0439\n",
      "Epoch [97/100], Step [16/56], Loss: 0.0759\n",
      "Epoch [97/100], Step [17/56], Loss: 0.0564\n",
      "Epoch [97/100], Step [18/56], Loss: 0.0621\n",
      "Epoch [97/100], Step [19/56], Loss: 0.0669\n",
      "Epoch [97/100], Step [20/56], Loss: 0.1363\n",
      "Epoch [97/100], Step [21/56], Loss: 0.0692\n",
      "Epoch [97/100], Step [22/56], Loss: 0.0512\n",
      "Epoch [97/100], Step [23/56], Loss: 0.2486\n",
      "Epoch [97/100], Step [24/56], Loss: 0.0664\n",
      "Epoch [97/100], Step [25/56], Loss: 0.1887\n",
      "Epoch [97/100], Step [26/56], Loss: 0.0376\n",
      "Epoch [97/100], Step [27/56], Loss: 0.0575\n",
      "Epoch [97/100], Step [28/56], Loss: 0.1444\n",
      "Epoch [97/100], Step [29/56], Loss: 0.1495\n",
      "Epoch [97/100], Step [30/56], Loss: 0.0653\n",
      "Epoch [97/100], Step [31/56], Loss: 0.0551\n",
      "Epoch [97/100], Step [32/56], Loss: 0.0805\n",
      "Epoch [97/100], Step [33/56], Loss: 0.1346\n",
      "Epoch [97/100], Step [34/56], Loss: 0.1633\n",
      "Epoch [97/100], Step [35/56], Loss: 0.0498\n",
      "Epoch [97/100], Step [36/56], Loss: 0.0525\n",
      "Epoch [97/100], Step [37/56], Loss: 0.0772\n",
      "Epoch [97/100], Step [38/56], Loss: 0.0644\n",
      "Epoch [97/100], Step [39/56], Loss: 0.0545\n",
      "Epoch [97/100], Step [40/56], Loss: 0.0717\n",
      "Epoch [97/100], Step [41/56], Loss: 0.0618\n",
      "Epoch [97/100], Step [42/56], Loss: 0.1004\n",
      "Epoch [97/100], Step [43/56], Loss: 0.0712\n",
      "Epoch [97/100], Step [44/56], Loss: 0.0689\n",
      "Epoch [97/100], Step [45/56], Loss: 0.0603\n",
      "Epoch [97/100], Step [46/56], Loss: 0.0927\n",
      "Epoch [97/100], Step [47/56], Loss: 0.0559\n",
      "Epoch [97/100], Step [48/56], Loss: 0.0501\n",
      "Epoch [97/100], Step [49/56], Loss: 0.1094\n",
      "Epoch [97/100], Step [50/56], Loss: 0.1094\n",
      "Epoch [97/100], Step [51/56], Loss: 0.3235\n",
      "Epoch [97/100], Step [52/56], Loss: 0.0583\n",
      "Epoch [97/100], Step [53/56], Loss: 0.0468\n",
      "Epoch [97/100], Step [54/56], Loss: 0.0442\n",
      "Epoch [97/100], Step [55/56], Loss: 0.0950\n",
      "Epoch [97/100], Step [56/56], Loss: 0.0333\n",
      "Val. loss :0.0533\n",
      "Epoch [98/100], Step [1/56], Loss: 0.0531\n",
      "Epoch [98/100], Step [2/56], Loss: 0.0607\n",
      "Epoch [98/100], Step [3/56], Loss: 0.0379\n",
      "Epoch [98/100], Step [4/56], Loss: 0.0436\n",
      "Epoch [98/100], Step [5/56], Loss: 0.0512\n",
      "Epoch [98/100], Step [6/56], Loss: 0.1750\n",
      "Epoch [98/100], Step [7/56], Loss: 0.1087\n",
      "Epoch [98/100], Step [8/56], Loss: 0.0568\n",
      "Epoch [98/100], Step [9/56], Loss: 0.0537\n",
      "Epoch [98/100], Step [10/56], Loss: 0.0567\n",
      "Epoch [98/100], Step [11/56], Loss: 0.0956\n",
      "Epoch [98/100], Step [12/56], Loss: 0.0548\n",
      "Epoch [98/100], Step [13/56], Loss: 0.1048\n",
      "Epoch [98/100], Step [14/56], Loss: 0.1063\n",
      "Epoch [98/100], Step [15/56], Loss: 0.0419\n",
      "Epoch [98/100], Step [16/56], Loss: 0.0463\n",
      "Epoch [98/100], Step [17/56], Loss: 0.0870\n",
      "Epoch [98/100], Step [18/56], Loss: 0.0508\n",
      "Epoch [98/100], Step [19/56], Loss: 0.0471\n",
      "Epoch [98/100], Step [20/56], Loss: 0.1258\n",
      "Epoch [98/100], Step [21/56], Loss: 0.0454\n",
      "Epoch [98/100], Step [22/56], Loss: 0.0922\n",
      "Epoch [98/100], Step [23/56], Loss: 0.0403\n",
      "Epoch [98/100], Step [24/56], Loss: 0.0585\n",
      "Epoch [98/100], Step [25/56], Loss: 0.0559\n",
      "Epoch [98/100], Step [26/56], Loss: 0.0977\n",
      "Epoch [98/100], Step [27/56], Loss: 0.0543\n",
      "Epoch [98/100], Step [28/56], Loss: 0.0465\n",
      "Epoch [98/100], Step [29/56], Loss: 0.0850\n",
      "Epoch [98/100], Step [30/56], Loss: 0.0429\n",
      "Epoch [98/100], Step [31/56], Loss: 0.0359\n",
      "Epoch [98/100], Step [32/56], Loss: 0.1059\n",
      "Epoch [98/100], Step [33/56], Loss: 0.1376\n",
      "Epoch [98/100], Step [34/56], Loss: 0.0448\n",
      "Epoch [98/100], Step [35/56], Loss: 0.0537\n",
      "Epoch [98/100], Step [36/56], Loss: 0.0763\n",
      "Epoch [98/100], Step [37/56], Loss: 0.0492\n",
      "Epoch [98/100], Step [38/56], Loss: 0.0588\n",
      "Epoch [98/100], Step [39/56], Loss: 0.0576\n",
      "Epoch [98/100], Step [40/56], Loss: 0.0541\n",
      "Epoch [98/100], Step [41/56], Loss: 0.2399\n",
      "Epoch [98/100], Step [42/56], Loss: 0.0641\n",
      "Epoch [98/100], Step [43/56], Loss: 0.2024\n",
      "Epoch [98/100], Step [44/56], Loss: 0.0930\n",
      "Epoch [98/100], Step [45/56], Loss: 0.0575\n",
      "Epoch [98/100], Step [46/56], Loss: 0.0445\n",
      "Epoch [98/100], Step [47/56], Loss: 0.0523\n",
      "Epoch [98/100], Step [48/56], Loss: 0.0835\n",
      "Epoch [98/100], Step [49/56], Loss: 0.0899\n",
      "Epoch [98/100], Step [50/56], Loss: 0.2247\n",
      "Epoch [98/100], Step [51/56], Loss: 0.0595\n",
      "Epoch [98/100], Step [52/56], Loss: 0.0587\n",
      "Epoch [98/100], Step [53/56], Loss: 0.0567\n",
      "Epoch [98/100], Step [54/56], Loss: 0.0895\n",
      "Epoch [98/100], Step [55/56], Loss: 0.0565\n",
      "Epoch [98/100], Step [56/56], Loss: 0.0863\n",
      "Val. loss :0.0681\n",
      "Epoch [99/100], Step [1/56], Loss: 0.0492\n",
      "Epoch [99/100], Step [2/56], Loss: 0.0608\n",
      "Epoch [99/100], Step [3/56], Loss: 0.2259\n",
      "Epoch [99/100], Step [4/56], Loss: 0.0423\n",
      "Epoch [99/100], Step [5/56], Loss: 0.0586\n",
      "Epoch [99/100], Step [6/56], Loss: 0.0697\n",
      "Epoch [99/100], Step [7/56], Loss: 0.0592\n",
      "Epoch [99/100], Step [8/56], Loss: 0.0543\n",
      "Epoch [99/100], Step [9/56], Loss: 0.0504\n",
      "Epoch [99/100], Step [10/56], Loss: 0.0622\n",
      "Epoch [99/100], Step [11/56], Loss: 0.0607\n",
      "Epoch [99/100], Step [12/56], Loss: 0.0639\n",
      "Epoch [99/100], Step [13/56], Loss: 0.0488\n",
      "Epoch [99/100], Step [14/56], Loss: 0.0386\n",
      "Epoch [99/100], Step [15/56], Loss: 0.0747\n",
      "Epoch [99/100], Step [16/56], Loss: 0.0617\n",
      "Epoch [99/100], Step [17/56], Loss: 0.0716\n",
      "Epoch [99/100], Step [18/56], Loss: 0.0596\n",
      "Epoch [99/100], Step [19/56], Loss: 0.1954\n",
      "Epoch [99/100], Step [20/56], Loss: 0.1291\n",
      "Epoch [99/100], Step [21/56], Loss: 0.0813\n",
      "Epoch [99/100], Step [22/56], Loss: 0.0499\n",
      "Epoch [99/100], Step [23/56], Loss: 0.0719\n",
      "Epoch [99/100], Step [24/56], Loss: 0.0635\n",
      "Epoch [99/100], Step [25/56], Loss: 0.0586\n",
      "Epoch [99/100], Step [26/56], Loss: 0.0684\n",
      "Epoch [99/100], Step [27/56], Loss: 0.0678\n",
      "Epoch [99/100], Step [28/56], Loss: 0.1867\n",
      "Epoch [99/100], Step [29/56], Loss: 0.1409\n",
      "Epoch [99/100], Step [30/56], Loss: 0.0422\n",
      "Epoch [99/100], Step [31/56], Loss: 0.0777\n",
      "Epoch [99/100], Step [32/56], Loss: 0.0516\n",
      "Epoch [99/100], Step [33/56], Loss: 0.0488\n",
      "Epoch [99/100], Step [34/56], Loss: 0.0444\n",
      "Epoch [99/100], Step [35/56], Loss: 0.0482\n",
      "Epoch [99/100], Step [36/56], Loss: 0.0720\n",
      "Epoch [99/100], Step [37/56], Loss: 0.0404\n",
      "Epoch [99/100], Step [38/56], Loss: 0.0669\n",
      "Epoch [99/100], Step [39/56], Loss: 0.0671\n",
      "Epoch [99/100], Step [40/56], Loss: 0.1849\n",
      "Epoch [99/100], Step [41/56], Loss: 0.0675\n",
      "Epoch [99/100], Step [42/56], Loss: 0.0629\n",
      "Epoch [99/100], Step [43/56], Loss: 0.0589\n",
      "Epoch [99/100], Step [44/56], Loss: 0.0588\n",
      "Epoch [99/100], Step [45/56], Loss: 0.0509\n",
      "Epoch [99/100], Step [46/56], Loss: 0.0830\n",
      "Epoch [99/100], Step [47/56], Loss: 0.1127\n",
      "Epoch [99/100], Step [48/56], Loss: 0.0945\n",
      "Epoch [99/100], Step [49/56], Loss: 0.0523\n",
      "Epoch [99/100], Step [50/56], Loss: 0.1742\n",
      "Epoch [99/100], Step [51/56], Loss: 0.0975\n",
      "Epoch [99/100], Step [52/56], Loss: 0.0475\n",
      "Epoch [99/100], Step [53/56], Loss: 0.0468\n",
      "Epoch [99/100], Step [54/56], Loss: 0.0724\n",
      "Epoch [99/100], Step [55/56], Loss: 0.0514\n",
      "Epoch [99/100], Step [56/56], Loss: 0.0262\n",
      "Val. loss :0.0614\n",
      "Epoch [100/100], Step [1/56], Loss: 0.0546\n",
      "Epoch [100/100], Step [2/56], Loss: 0.0453\n",
      "Epoch [100/100], Step [3/56], Loss: 0.1030\n",
      "Epoch [100/100], Step [4/56], Loss: 0.0567\n",
      "Epoch [100/100], Step [5/56], Loss: 0.1018\n",
      "Epoch [100/100], Step [6/56], Loss: 0.0601\n",
      "Epoch [100/100], Step [7/56], Loss: 0.0456\n",
      "Epoch [100/100], Step [8/56], Loss: 0.0773\n",
      "Epoch [100/100], Step [9/56], Loss: 0.0525\n",
      "Epoch [100/100], Step [10/56], Loss: 0.1239\n",
      "Epoch [100/100], Step [11/56], Loss: 0.0671\n",
      "Epoch [100/100], Step [12/56], Loss: 0.0668\n",
      "Epoch [100/100], Step [13/56], Loss: 0.0773\n",
      "Epoch [100/100], Step [14/56], Loss: 0.0686\n",
      "Epoch [100/100], Step [15/56], Loss: 0.0440\n",
      "Epoch [100/100], Step [16/56], Loss: 0.0583\n",
      "Epoch [100/100], Step [17/56], Loss: 0.0507\n",
      "Epoch [100/100], Step [18/56], Loss: 0.0605\n",
      "Epoch [100/100], Step [19/56], Loss: 0.0623\n",
      "Epoch [100/100], Step [20/56], Loss: 0.1368\n",
      "Epoch [100/100], Step [21/56], Loss: 0.0432\n",
      "Epoch [100/100], Step [22/56], Loss: 0.0410\n",
      "Epoch [100/100], Step [23/56], Loss: 0.0606\n",
      "Epoch [100/100], Step [24/56], Loss: 0.0682\n",
      "Epoch [100/100], Step [25/56], Loss: 0.0745\n",
      "Epoch [100/100], Step [26/56], Loss: 0.1347\n",
      "Epoch [100/100], Step [27/56], Loss: 0.1149\n",
      "Epoch [100/100], Step [28/56], Loss: 0.0484\n",
      "Epoch [100/100], Step [29/56], Loss: 0.1058\n",
      "Epoch [100/100], Step [30/56], Loss: 0.0438\n",
      "Epoch [100/100], Step [31/56], Loss: 0.0710\n",
      "Epoch [100/100], Step [32/56], Loss: 0.0683\n",
      "Epoch [100/100], Step [33/56], Loss: 0.0784\n",
      "Epoch [100/100], Step [34/56], Loss: 0.0322\n",
      "Epoch [100/100], Step [35/56], Loss: 0.0392\n",
      "Epoch [100/100], Step [36/56], Loss: 0.0510\n",
      "Epoch [100/100], Step [37/56], Loss: 0.0460\n",
      "Epoch [100/100], Step [38/56], Loss: 0.0947\n",
      "Epoch [100/100], Step [39/56], Loss: 0.0440\n",
      "Epoch [100/100], Step [40/56], Loss: 0.0544\n",
      "Epoch [100/100], Step [41/56], Loss: 0.1065\n",
      "Epoch [100/100], Step [42/56], Loss: 0.0687\n",
      "Epoch [100/100], Step [43/56], Loss: 0.0635\n",
      "Epoch [100/100], Step [44/56], Loss: 0.0430\n",
      "Epoch [100/100], Step [45/56], Loss: 0.1366\n",
      "Epoch [100/100], Step [46/56], Loss: 0.0495\n",
      "Epoch [100/100], Step [47/56], Loss: 0.0487\n",
      "Epoch [100/100], Step [48/56], Loss: 0.0451\n",
      "Epoch [100/100], Step [49/56], Loss: 0.0667\n",
      "Epoch [100/100], Step [50/56], Loss: 0.1424\n",
      "Epoch [100/100], Step [51/56], Loss: 0.0572\n",
      "Epoch [100/100], Step [52/56], Loss: 0.0381\n",
      "Epoch [100/100], Step [53/56], Loss: 0.0526\n",
      "Epoch [100/100], Step [54/56], Loss: 0.0368\n",
      "Epoch [100/100], Step [55/56], Loss: 0.0352\n",
      "Epoch [100/100], Step [56/56], Loss: 0.0179\n",
      "Val. loss :0.0526\n",
      "Test. loss :0.0115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pdb\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from numpy import random\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    "    Dataset,\n",
    "    SubsetRandomSampler,\n",
    "    TensorDataset,\n",
    ")\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from models import Unet\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "os.chdir(\n",
    "    r\"C:\\Users\\avs20\\Documents\\GitHub\\DeepEnsampleGUI\\napari-threshold\\Unet_training\"\n",
    ")\n",
    "\n",
    "\n",
    "def random_cutout(image, label, max_h=50, max_w=50):\n",
    "    \"\"\"\n",
    "    Apply random cutout to both image and label.\n",
    "    Args:\n",
    "        image: The input image tensor.\n",
    "        label: The label tensor.\n",
    "        max_h: Maximum height of the cutout box.\n",
    "        max_w: Maximum width of the cutout box.\n",
    "    Returns:\n",
    "        image: Image after cutout.\n",
    "        label: Label after cutout.\n",
    "    \"\"\"\n",
    "    _, h, w = image.shape\n",
    "    cutout_height = random.randint(10, max_h)\n",
    "    cutout_width = random.randint(10, max_w)\n",
    "\n",
    "    # Randomly choose the position for the cutout\n",
    "    top = random.randint(0, h - cutout_height)\n",
    "    left = random.randint(0, w - cutout_width)\n",
    "\n",
    "    # Apply the cutout to the image and label (set to 0)\n",
    "    image[:, top : top + cutout_height, left : left + cutout_width] = 0\n",
    "    label[:, top : top + cutout_height, left : left + cutout_width] = 0\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def adjust_brightness(image, label, brightness_factor=0.2):\n",
    "    \"\"\"\n",
    "    Adjust the brightness of the image and label.\n",
    "    Args:\n",
    "        image: The input image tensor.\n",
    "        label: The label tensor.\n",
    "        brightness_factor: Factor by which brightness is adjusted.\n",
    "    Returns:\n",
    "        image: Image after brightness adjustment.\n",
    "        label: Label after brightness adjustment.\n",
    "    \"\"\"\n",
    "    image = TF.adjust_brightness(\n",
    "        image, 1 + (random.random() * 2 - 1) * brightness_factor\n",
    "    )\n",
    "    # Note: Brightness doesn't affect the label, so we leave it unchanged\n",
    "    return image, label\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "def random_jitter(image, max_jitter=0.1):\n",
    "    \"\"\"\n",
    "    Apply random jittering to an image by adding noise to its pixel values.\n",
    "    Args:\n",
    "        image: The input image tensor.\n",
    "        max_jitter: The maximum amount of jitter to apply to each pixel.\n",
    "    Returns:\n",
    "        image: The image with jitter applied.\n",
    "    \"\"\"\n",
    "    # Generate random noise with a normal distribution\n",
    "    noise = torch.randn_like(image) * max_jitter  # Gaussian noise\n",
    "    image = image + noise\n",
    "\n",
    "    # Clip the values to be in the valid range [0, 1] for images\n",
    "    image = torch.clamp(image, 0, 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def motion_blur(image, kernel_size=5, angle=45):\n",
    "    \"\"\"\n",
    "    Apply motion blur to an image using a convolution with a motion blur kernel.\n",
    "    Args:\n",
    "        image: The input image tensor.\n",
    "        kernel_size: The size of the blur kernel.\n",
    "        angle: The angle of the motion.\n",
    "    Returns:\n",
    "        image: The image after motion blur.\n",
    "    \"\"\"\n",
    "    # Create motion blur kernel\n",
    "    kernel = torch.zeros((kernel_size, kernel_size))\n",
    "\n",
    "    # Define the direction of the blur (this could be any angle, here we use horizontal motion)\n",
    "    center = kernel_size // 2\n",
    "    angle_rad = torch.tensor(angle * torch.pi / 180)  # Convert to radians\n",
    "\n",
    "    # Apply a simple horizontal motion blur\n",
    "    for i in range(kernel_size):\n",
    "        kernel[center, i] = 1\n",
    "\n",
    "    # Normalize the kernel\n",
    "    kernel = kernel / kernel.sum()\n",
    "\n",
    "    # Reshape kernel for convolution (batch size, channels, kernel size)\n",
    "    kernel = kernel.unsqueeze(0).unsqueeze(\n",
    "        0\n",
    "    )  # Shape (1, 1, kernel_size, kernel_size)\n",
    "\n",
    "    # Apply the kernel using convolution\n",
    "    blurred_image = F.conv2d(\n",
    "        image.unsqueeze(0), kernel, padding=kernel_size // 2\n",
    "    )\n",
    "    return blurred_image.squeeze(0)\n",
    "\n",
    "\n",
    "class facemapdataset(Dataset):\n",
    "    # def __init__(self, data_file=\"data/dolensek_facemap_softlabels_224.pt\",\n",
    "    # def __init__(self, data_file=\"data\\dolensek_facemap_softlabels_224_TEST_DIF_KP.pt\",\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_file=r'C:\\Users\\avs20\\Documents\\GitHub\\DeepEnsampleGUI\\napari-threshold\\Unet_training\\data\\dataset2.pt',\n",
    "        transform=None,\n",
    "        rotation_degrees=(\n",
    "            15,\n",
    "            30,\n",
    "        ),  # Rotation angle range from 15 to 30 degrees\n",
    "        zoom_range=(\n",
    "            0.8,\n",
    "            1.5,\n",
    "        ),  # Zoom range from 0.8 (zoom out) to 1.5 (zoom in)\n",
    "        blur_radius=(1, 2),  # Tuple for Gaussian blur radius range\n",
    "        cutout_prob=0.2,  # Probability of applying cutout\n",
    "        brightness_prob=0.2,  # Probability of applying brightness adjustment\n",
    "        brightness_factor=0.5,  # Max factor for brightness adjustment\n",
    "        motion_blur_prob=0.2,  # Probability of applying motion blur\n",
    "        motion_blur_kernel_size=5,  # Size of the motion blur kernel\n",
    "        motion_blur_angle=45,  # Angle of the motion blur\n",
    "        jitter_prob=0.2,  # Probability of applying random jitter\n",
    "        jitter_max=0.1,\n",
    "    ):  # Maximum jitter value (standard deviation)\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        self.rotation_degrees = rotation_degrees\n",
    "        self.zoom_range = zoom_range\n",
    "        self.blur_radius = blur_radius\n",
    "        self.cutout_prob = cutout_prob\n",
    "        self.brightness_prob = brightness_prob\n",
    "        self.brightness_factor = brightness_factor\n",
    "        self.motion_blur_prob = motion_blur_prob\n",
    "        self.motion_blur_kernel_size = motion_blur_kernel_size\n",
    "        self.motion_blur_angle = motion_blur_angle\n",
    "        self.jitter_prob = jitter_prob\n",
    "        self.jitter_max = jitter_max\n",
    "        # self.data, _, self.targets = torch.load(data_file)\n",
    "        self.data, self.targets = torch.load(data_file)\n",
    "\n",
    "    # def __len__(self):\n",
    "    #    return len(self.data) * 5  # Return length * 5 for augmented versions\n",
    "    def __len__(self):\n",
    "        return len(self.data) * 10  # Return length * 10 for augmented versions\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Ensure the index stays within bounds by using modulo with the original dataset size\n",
    "        base_index = index % len(\n",
    "            self.data\n",
    "        )  # This will prevent out-of-bounds errors\n",
    "        aug_type = index // len(\n",
    "            self.data\n",
    "        )  # This will determine which augmentation to apply\n",
    "\n",
    "        # Load the original image and label\n",
    "        image, label = (\n",
    "            self.data[base_index].clone(),\n",
    "            self.targets[base_index].clone(),\n",
    "        )\n",
    "\n",
    "        # Apply the augmentation based on the `aug_type`\n",
    "        if self.transform is not None:\n",
    "            if aug_type == 1:  # Flipping\n",
    "                image = image.flip([2])\n",
    "                label = label.flip([2])\n",
    "            elif aug_type == 2:  # Rotation\n",
    "                angle = random.uniform(\n",
    "                    -self.rotation_degrees[1], self.rotation_degrees[1]\n",
    "                )\n",
    "                image = TF.rotate(image, angle)\n",
    "                label = TF.rotate(label, angle)\n",
    "            elif aug_type == 3:  # Zooming\n",
    "                scale_factor = random.uniform(\n",
    "                    self.zoom_range[0], self.zoom_range[1]\n",
    "                )\n",
    "                image = self.zoom(image, scale_factor)\n",
    "                label = self.zoom(label, scale_factor)\n",
    "            elif aug_type == 4:  # Gaussian Blur\n",
    "                radius = (\n",
    "                    torch.rand(1).item()\n",
    "                    * (self.blur_radius[1] - self.blur_radius[0])\n",
    "                    + self.blur_radius[0]\n",
    "                )\n",
    "                image = TF.gaussian_blur(image, kernel_size=int(radius))\n",
    "                # Do not apply blur to the label\n",
    "\n",
    "            # Apply random cutout with probability\n",
    "            if random.random() < self.cutout_prob:\n",
    "                image, label = random_cutout(image, label)\n",
    "\n",
    "            # Apply random brightness adjustment with probability\n",
    "            if random.random() < self.brightness_prob:\n",
    "                image, _ = adjust_brightness(\n",
    "                    image, label, self.brightness_factor\n",
    "                )\n",
    "                # Note that the label is not being adjusted, only the image\n",
    "\n",
    "            # Apply motion blur with probability\n",
    "            if random.random() < self.motion_blur_prob:\n",
    "                image = motion_blur(\n",
    "                    image, self.motion_blur_kernel_size, self.motion_blur_angle\n",
    "                )\n",
    "\n",
    "            # Apply random jittering with probability\n",
    "            if random.random() < self.jitter_prob:\n",
    "                image = random_jitter(image, self.jitter_max)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def zoom(self, img, scale_factor):\n",
    "        # Calculate new dimensions\n",
    "        _, h, w = img.shape\n",
    "        new_h, new_w = int(h * scale_factor), int(w * scale_factor)\n",
    "\n",
    "        # Resize and center-crop back to the original size\n",
    "        img = TF.resize(img, [new_h, new_w])\n",
    "        img = TF.center_crop(img, [h, w])\n",
    "        return img\n",
    "\n",
    "\n",
    "# class facemapdataset(Dataset):\n",
    "#     def __init__(self, data_file=\"data/dataset.pt\", transform=None):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.transform = transform\n",
    "#         # self.data, _, self.targets = torch.load(data_file)\n",
    "#         self.data, self.targets = torch.load(data_file)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.targets)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         image, label = self.data[index].clone(), self.targets[index].clone()\n",
    "#         if (self.transform is not None) and (torch.rand(1) > 0.5):\n",
    "#             image = image.flip([2])\n",
    "#             label = label.flip([2])\n",
    "#         return image, label\n",
    "\n",
    "\n",
    "### Make dataset\n",
    "dataset = facemapdataset(transform=\"flip\")\n",
    "\n",
    "x = dataset[0][0]\n",
    "dim = x.shape[-1]\n",
    "print(\"Using %d size of images\" % dim)\n",
    "N = len(dataset)\n",
    "train_sampler = SubsetRandomSampler(np.arange(int(0.6 * N)))\n",
    "valid_sampler = SubsetRandomSampler(np.arange(int(0.6 * N), int(0.8 * N)))\n",
    "test_sampler = SubsetRandomSampler(np.arange(int(0.8 * N), N))\n",
    "batch_size = 4\n",
    "# Initialize loss and metrics\n",
    "loss_fun = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "# Initiliaze input dimensions\n",
    "num_train = len(train_sampler)\n",
    "num_valid = len(valid_sampler)\n",
    "num_test = len(test_sampler)\n",
    "print(\n",
    "    \"Num. train = %d, Num. val = %d, Num. test = %d\"\n",
    "    % (num_train, num_valid, num_test)\n",
    ")\n",
    "\n",
    "# Initialize dataloaders\n",
    "loader_train = DataLoader(\n",
    "    dataset=dataset,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    "    sampler=train_sampler,\n",
    ")\n",
    "loader_valid = DataLoader(\n",
    "    dataset=dataset,\n",
    "    drop_last=True,\n",
    "    num_workers=0,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    "    sampler=valid_sampler,\n",
    ")\n",
    "loader_test = DataLoader(\n",
    "    dataset=dataset,\n",
    "    drop_last=True,\n",
    "    num_workers=0,\n",
    "    batch_size=1,\n",
    "    pin_memory=True,\n",
    "    sampler=test_sampler,\n",
    ")\n",
    "\n",
    "nValid = len(loader_valid)\n",
    "nTrain = len(loader_train)\n",
    "nTest = len(loader_test)\n",
    "\n",
    "### hyperparam\n",
    "lr = 5e-4\n",
    "num_epochs = 100\n",
    "\n",
    "# num_input_channels = 1  # Change this to the desired number of input channels\n",
    "# num_output_classes = 24  # Change this to the desired number of output classes\n",
    "\n",
    "\n",
    "model = Unet()\n",
    "# timm.create_model('vit_base_patch8_224',\n",
    "#        pretrained=True,in_chans=1,num_classes=num_output_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "nParam = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters:%2f M\" % (nParam / 1e6))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "minLoss = 1e6\n",
    "convIter = 0\n",
    "patience = 100\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    tr_loss = 0\n",
    "    for i, (inputs, labels) in enumerate(loader_train):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        scores, _ = model(inputs)\n",
    "\n",
    "        loss = loss_fun((scores), ((labels)))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\n",
    "            \"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}\".format(\n",
    "                epoch + 1, num_epochs, i + 1, nTrain, loss.item()\n",
    "            )\n",
    "        )\n",
    "        tr_loss += loss.item()\n",
    "    train_loss.append(tr_loss / (i + 1))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for i, (inputs, labels) in enumerate(loader_valid):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            scores, fmap = model(inputs)\n",
    "            loss = loss_fun((scores), ((labels)))\n",
    "            val_loss += loss.item()\n",
    "        val_loss = val_loss / (i + 1)\n",
    "\n",
    "        valid_loss.append(val_loss)\n",
    "\n",
    "        print(\"Val. loss :%.4f\" % val_loss)\n",
    "\n",
    "        labels = labels.squeeze().detach().cpu().numpy()\n",
    "        scores = scores.squeeze().detach().cpu().numpy()\n",
    "        img = inputs.squeeze().detach().cpu().numpy()\n",
    "        fmap = inputs.mean(1).squeeze().detach().cpu().numpy()\n",
    "\n",
    "        plt.clf()\n",
    "        plt.figure(figsize=(16, 12))\n",
    "        for i in range(batch_size):\n",
    "            plt.subplot(batch_size, 3, 3 * i + 1)\n",
    "            plt.imshow(labels[i])\n",
    "            plt.subplot(batch_size, 3, 3 * i + 2)\n",
    "            plt.imshow(scores[i] * img[i])\n",
    "            plt.subplot(batch_size, 3, 3 * i + 3)\n",
    "            plt.imshow(fmap[i])\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.savefig(\"epoch_%03d.jpg\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "        if minLoss > val_loss:\n",
    "            convEpoch = epoch\n",
    "            minLoss = val_loss\n",
    "            convIter = 0\n",
    "            # torch.save(model.state_dict(),'models/best_model.pt')\n",
    "        else:\n",
    "            convIter += 1\n",
    "\n",
    "        if convIter == patience:\n",
    "            print(\n",
    "                \"Converged at epoch %d with val. loss %.4f\"\n",
    "                % (convEpoch + 1, minLoss)\n",
    "            )\n",
    "            break\n",
    "plt.clf()\n",
    "plt.plot(train_loss, label=\"Training\")\n",
    "plt.plot(valid_loss, label=\"Valid\")\n",
    "plt.plot(convEpoch, valid_loss[convEpoch], \"x\", label=\"Final Model\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"loss_curve.pdf\")\n",
    "plt.close()\n",
    "\n",
    "### Load best model for inference\n",
    "with torch.no_grad():\n",
    "    val_loss = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(loader_test):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        scores, fmap = model(inputs)\n",
    "        loss = loss_fun((scores), ((labels)))\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        img = inputs.squeeze().detach().cpu().numpy()\n",
    "        pred = scores.squeeze().detach().cpu().numpy()\n",
    "        labels = labels.squeeze().cpu().numpy()\n",
    "        fmap = fmap.mean(1).squeeze().cpu().numpy()\n",
    "\n",
    "        plt.clf()\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(141)\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "        plt.subplot(142)\n",
    "        plt.imshow(labels)\n",
    "        plt.subplot(143)\n",
    "        plt.imshow(pred)\n",
    "        plt.subplot(144)\n",
    "        plt.imshow(fmap)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"preds/test_%03d.jpg\" % i)\n",
    "        plt.close()\n",
    "\n",
    "    val_loss = val_loss / (i + 1)\n",
    "\n",
    "    print(\"Test. loss :%.4f\" % val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test. loss :0.0139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Load best model for inference\n",
    "with torch.no_grad():\n",
    "    val_loss = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(loader_test):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        scores, fmap = model(inputs)\n",
    "        loss = loss_fun((scores), ((labels)))\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        img = inputs.squeeze().detach().cpu().numpy()\n",
    "        pred = scores.squeeze().detach().cpu().numpy()\n",
    "        labels = labels.squeeze().cpu().numpy()\n",
    "        fmap = fmap.mean(1).squeeze().cpu().numpy()\n",
    "\n",
    "        plt.clf()\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(141)\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "        plt.subplot(142)\n",
    "        plt.imshow(labels)\n",
    "        plt.subplot(143)\n",
    "        plt.imshow(pred)\n",
    "        plt.subplot(144)\n",
    "        plt.imshow(fmap)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"preds/test_%03d.jpg\" % i)\n",
    "        plt.close()\n",
    "\n",
    "    val_loss = val_loss / (i + 1)\n",
    "\n",
    "    print(\"Test. loss :%.4f\" % val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([244, 388])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "\n",
    "class facemapdataset(Dataset):\n",
    "    def __init__(self, data_file=r'C:\\Users\\avs20\\Documents\\GitHub\\DeepEnsampleGUI\\napari-threshold\\Unet_training\\data\\single_image.pt', transform=None):\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        # Load the data (single image tensor)\n",
    "        self.data= torch.load(data_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  # We are using a single image dataset, no augmentation.\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load the image and label\n",
    "        image = self.data[index].clone()\n",
    "\n",
    "        # No augmentation or transformation is applied to the image or label\n",
    "        return image\n",
    "\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset = facemapdataset()\n",
    "\n",
    "# Example of retrieving a sample from the dataset\n",
    "image = dataset[0]\n",
    "print(f\"Image shape: {image.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [244, 388]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m inputs \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#labels = labels.to(device)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m scores, fmap \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#loss = loss_fun((scores), ((labels)))\u001b[39;00m\n\u001b[0;32m     10\u001b[0m val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\avs20\\Documents\\GitHub\\DeepEnsampleGUI\\napari-threshold\\Unet_training\\models.py:99\u001b[0m, in \u001b[0;36mUnet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m#        pdb.set_trace()\u001b[39;00m\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;66;03m# Unet encoder result\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m         x_enc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;66;03m# Outputs for MSE\u001b[39;00m\n\u001b[0;32m    101\u001b[0m         xHat, fmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x_enc)\n",
      "File \u001b[1;32mc:\\Users\\avs20\\Documents\\GitHub\\DeepEnsampleGUI\\napari-threshold\\Unet_training\\models.py:73\u001b[0m, in \u001b[0;36mUnet.encoder\u001b[1;34m(self, x_in)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencoder\u001b[39m(\u001b[38;5;28mself\u001b[39m,x_in):\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m### Unet Encoder\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     x \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 73\u001b[0m     x\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muEnc12(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muEnc11(x_in)))))\n\u001b[0;32m     74\u001b[0m     x\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muEnc2(x[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     75\u001b[0m     x\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muEnc3(x[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[0;32m    551\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [244, 388]"
     ]
    }
   ],
   "source": [
    "### Load best model for inference\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_loss = 0\n",
    "\n",
    "    inputs = image.to(device)\n",
    "    #labels = labels.to(device)\n",
    "    scores, fmap = model(inputs)\n",
    "    #loss = loss_fun((scores), ((labels)))\n",
    "    val_loss += loss.item()\n",
    "\n",
    "    img = inputs.squeeze().detach().cpu().numpy()\n",
    "    pred = scores.squeeze().detach().cpu().numpy()\n",
    "    #labels = labels.squeeze().cpu().numpy()\n",
    "    fmap = fmap.mean(1).squeeze().cpu().numpy()\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(141)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    #plt.subplot(142)\n",
    "    #plt.imshow(labels)\n",
    "    plt.subplot(143)\n",
    "    plt.imshow(pred)\n",
    "    plt.subplot(144)\n",
    "    plt.imshow(fmap)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"preds/test_%03d.jpg\" % i)\n",
    "    plt.close()\n",
    "\n",
    "    val_loss = val_loss / (i + 1)\n",
    "\n",
    "    print(\"Test. loss :%.4f\" % val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test. loss :0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming image is already loaded\n",
    "image = dataset[0]  # Shape: [244, 388]\n",
    "image = image.unsqueeze(0).unsqueeze(0)  # Now the shape is [1, 1, 244, 388]\n",
    "\n",
    "# Move the image to the device (GPU or CPU)\n",
    "inputs = image.to(device)\n",
    "\n",
    "# Perform inference with the model\n",
    "with torch.no_grad():\n",
    "    scores, fmap = model(inputs)\n",
    "\n",
    "    # Optionally, process the results (e.g., loss, visualization)\n",
    "    img = inputs.squeeze().detach().cpu().numpy()\n",
    "    pred = scores.squeeze().detach().cpu().numpy()\n",
    "    fmap = fmap.mean(1).squeeze().cpu().numpy()\n",
    "\n",
    "    # Plotting the results\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(141)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.subplot(143)\n",
    "    plt.imshow(pred)\n",
    "    plt.subplot(144)\n",
    "    plt.imshow(fmap)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"preds/test_%03d.jpg\" % i)\n",
    "    plt.close()\n",
    "\n",
    "    # Compute and print the validation loss\n",
    "    val_loss = val_loss / (i + 1)\n",
    "    print(\"Test. loss :%.4f\" % val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to C:\\Users\\avs20\\Documents\\GitHub\\DeepEnsampleGUI\\napari-threshold\\Unet_training\\data\\single_image.pt\n"
     ]
    }
   ],
   "source": [
    "#create single image .pt file\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the path to your single image\n",
    "img_path = r'C:\\Users\\avs20\\Documents\\GitHub\\DeepEnsampleGUI\\napari-threshold\\Unet_training\\frame_0002.jpg'  # Replace with your image path\n",
    "\n",
    "# Define any transformations (optional, for example, converting to tensor)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "])\n",
    "\n",
    "# Load the single image\n",
    "img = Image.open(img_path).convert('L')  # Convert to grayscale ('L')\n",
    "\n",
    "# Resize the image\n",
    "resize_factor = 0.2\n",
    "min_size = 32\n",
    "new_width = max(int(img.width * resize_factor), min_size)\n",
    "new_height = max(int(img.height * resize_factor), min_size)\n",
    "\n",
    "# Ensure the resized dimensions are even\n",
    "new_width += new_width % 2  # Make width even\n",
    "new_height += new_height % 2  # Make height even\n",
    "\n",
    "img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "\n",
    "# Apply the transformation (e.g., converting to tensor)\n",
    "img_tensor = transform(img)\n",
    "\n",
    "# Define the save path for the .pt file\n",
    "save_path = r'C:\\Users\\avs20\\Documents\\GitHub\\DeepEnsampleGUI\\napari-threshold\\Unet_training\\data\\single_image.pt'  # Change to the path where you want to save the file\n",
    "\n",
    "# Save the image tensor to the .pt file\n",
    "torch.save(img_tensor, save_path)\n",
    "print(f\"Image saved to {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/best_model_complete.pth')  # Saves the entire model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `model` is an instance of your `Unet` model\n",
    "torch.save(model.state_dict(), 'model_weights.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1, 224, 224] doesn't match the broadcast shape [3, 224, 224]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 33\u001b[0m\n\u001b[0;32m     26\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     27\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)),  \u001b[38;5;66;03m# Resize the image to the same size the model was trained on\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),  \u001b[38;5;66;03m# Convert the image to a tensor\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m])  \u001b[38;5;66;03m# Normalize the image (adjust if needed)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m ])\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Apply the transformations to the input image\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m input_image \u001b[38;5;241m=\u001b[39m transform(image)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Add a batch dimension and move to the appropriate device\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Step 3: Make the prediction\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mnormalize(tensor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\functional.py:350\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mnormalize(tensor, mean\u001b[38;5;241m=\u001b[39mmean, std\u001b[38;5;241m=\u001b[39mstd, inplace\u001b[38;5;241m=\u001b[39minplace)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\_functional_tensor.py:928\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m std\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    927\u001b[0m     std \u001b[38;5;241m=\u001b[39m std\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 928\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39msub_(mean)\u001b[38;5;241m.\u001b[39mdiv_(std)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: output with shape [1, 224, 224] doesn't match the broadcast shape [3, 224, 224]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from models import Unet  # Import the custom Unet class (adjust import as needed)\n",
    "\n",
    "# Step 1: Load the trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize your Unet model\n",
    "model = Unet()\n",
    "\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load(r'C:\\Users\\avs20\\Documents\\GitHub\\DeepEnsampleGUI\\napari-threshold\\Unet_training\\model_weights.pth', map_location=device, weights_only=False))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Step 2: Load and preprocess the input image\n",
    "image_path = r'C:\\Users\\avs20\\Documents\\GitHub\\DeepEnsampleGUI\\napari-threshold\\Unet_training\\test_img.jpg'  # Replace with the path to your image\n",
    "\n",
    "# Open image using PIL\n",
    "# Open image using PIL and convert to grayscale\n",
    "image = Image.open(image_path)  # 'L' mode for grayscale\n",
    "\n",
    "# Define the necessary transformations for the input image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image to the same size the model was trained on\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image (adjust if needed)\n",
    "])\n",
    "\n",
    "# Apply the transformations to the input image\n",
    "input_image = transform(image).unsqueeze(0).to(device)  # Add a batch dimension and move to the appropriate device\n",
    "\n",
    "# Step 3: Make the prediction\n",
    "with torch.no_grad():\n",
    "    output = model(input_image)  # Forward pass through the model\n",
    "\n",
    "# Step 4: Post-process the output (e.g., if the output is a segmentation map)\n",
    "output = output.squeeze().cpu().numpy()  # Remove the batch dimension and move the output to CPU\n",
    "\n",
    "# Step 5: Display the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(output, cmap='gray')  # Assuming the output is a single-channel (grayscale) segmentation map\n",
    "plt.title('Model Output')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'squeeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 68\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Step 3: Run inference on a .jpg image\u001b[39;00m\n\u001b[0;32m     67\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mavs20\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGitHub\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDeepEnsampleGUI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mnapari-threshold\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUnet_training\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mframe_0002.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with the path to your .jpg image\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m load_and_infer(image_path, model, device)\n",
      "Cell \u001b[1;32mIn[26], line 38\u001b[0m, in \u001b[0;36mload_and_infer\u001b[1;34m(image_path, model, device)\u001b[0m\n\u001b[0;32m     35\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(image_tensor)  \u001b[38;5;66;03m# Forward pass through the model\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Step 4: Post-process the output\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Remove the batch dimension and move the output to CPU\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Step 5: Display the results\u001b[39;00m\n\u001b[0;32m     41\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'squeeze'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from models import Unet  # Import your custom Unet class\n",
    "\n",
    "# Function to load a .jpg image, apply necessary transformations, and run inference\n",
    "def load_and_infer(image_path, model, device):\n",
    "    # Step 1: Open the image\n",
    "    image = Image.open(image_path).convert('L')  # Convert to grayscale ('L' mode)\n",
    "\n",
    "    # Define the resize factor (same as used during dataset creation)\n",
    "    resize_factor = 0.2  # This is the resize factor you used in dataset creation\n",
    "    min_size = 32  # This is the minimum size you used to prevent the image from being too small\n",
    "\n",
    "    # Resize the image\n",
    "    new_width = max(int(image.width * resize_factor), min_size)\n",
    "    new_height = max(int(image.height * resize_factor), min_size)\n",
    "    new_width += new_width % 2  # Make width even\n",
    "    new_height += new_height % 2  # Make height even\n",
    "    image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Step 2: Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Convert image to tensor\n",
    "        #transforms.Normalize(mean=[0.485], std=[0.229]),  # Normalize based on the mean and std from training\n",
    "    ])\n",
    "\n",
    "    # Apply transformations\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\n",
    "    # Step 3: Make the prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)  # Forward pass through the model\n",
    "\n",
    "    # Step 4: Post-process the output\n",
    "    output = output.squeeze().cpu().numpy()  # Remove the batch dimension and move the output to CPU\n",
    "\n",
    "    # Step 5: Display the results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Display the original image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title('Original Image')\n",
    "\n",
    "    # Display the model's output (assuming it's a segmentation map)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(output, cmap='gray')\n",
    "    plt.title('Model Output')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Step 2: Load the trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the Unet model\n",
    "model = Unet()\n",
    "\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load(r'C:\\Users\\avs20\\Documents\\GitHub\\DeepEnsampleGUI\\napari-threshold\\Unet_training\\model_weights.pth', map_location=device))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Step 3: Run inference on a .jpg image\n",
    "image_path = r'C:\\Users\\avs20\\Documents\\GitHub\\DeepEnsampleGUI\\napari-threshold\\Unet_training\\frame_0002.jpg'  # Replace with the path to your .jpg image\n",
    "load_and_infer(image_path, model, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output is a tuple. Extracting the first element.\n",
      "Output shape: torch.Size([1, 1, 244, 388])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from models import Unet  # Import your custom Unet class\n",
    "\n",
    "# Function to load a .jpg image, apply necessary transformations, and run inference\n",
    "def load_and_infer(image_path, model, device):\n",
    "    # Step 1: Open the image\n",
    "    image = Image.open(image_path).convert('L')  # Convert to grayscale ('L' mode)\n",
    "\n",
    "    # Define the resize factor (same as used during dataset creation)\n",
    "    resize_factor = 0.2  # This is the resize factor you used in dataset creation\n",
    "    min_size = 32  # This is the minimum size you used to prevent the image from being too small\n",
    "\n",
    "    # Resize the image\n",
    "    new_width = max(int(image.width * resize_factor), min_size)\n",
    "    new_height = max(int(image.height * resize_factor), min_size)\n",
    "    new_width += new_width % 2  # Make width even\n",
    "    new_height += new_height % 2  # Make height even\n",
    "    image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Step 2: Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Convert image to tensor\n",
    "        transforms.Normalize(mean=[0.485], std=[0.229]),  # Normalize based on the mean and std from training\n",
    "    ])\n",
    "\n",
    "    # Apply transformations\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\n",
    "    # Step 3: Make the prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)  # Forward pass through the model\n",
    "\n",
    "    # Check if the output is a tuple (e.g., with auxiliary outputs)\n",
    "    if isinstance(output, tuple):\n",
    "        print(\"Model output is a tuple. Extracting the first element.\")\n",
    "        output = output[0]  # Extract the first element if it's a tuple\n",
    "    else:\n",
    "        print(\"Model output is not a tuple.\")\n",
    "\n",
    "    print(f\"Output shape: {output.shape}\")  # Check the shape of the output\n",
    "\n",
    "    # Step 4: Post-process the output\n",
    "    output = output.squeeze().cpu().numpy()  # Remove the batch dimension and move the output to CPU\n",
    "\n",
    "    # Step 5: Display the results\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Display the original image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title('Original Image')\n",
    "\n",
    "    # Display the model's output (assuming it's a segmentation map)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(output, cmap='gray')\n",
    "    plt.title('Model Output')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Step 2: Load the trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the Unet model\n",
    "model = Unet()\n",
    "\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load(r'C:\\Users\\avs20\\Documents\\GitHub\\DeepEnsampleGUI\\napari-threshold\\Unet_training\\model_weights.pth', map_location=device))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Step 3: Run inference on a .jpg image\n",
    "image_path = r'C:\\Users\\avs20\\Documents\\GitHub\\DeepEnsampleGUI\\napari-threshold\\Unet_training\\frame_0002.jpg'  # Replace with the path to your .jpg image\n",
    "load_and_infer(image_path, model, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
